{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "363732af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow_addons\n",
    "!pip install -q pyarrow\n",
    "!pip install -q wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66841318",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 23:38:10.680030: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-19 23:38:11.306820: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/tensorflow/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sn\n",
    "import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import sys\n",
    "import sklearn\n",
    "import scipy\n",
    "import io\n",
    "import json\n",
    "\n",
    "import wandb\n",
    "\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd110003",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdeanna-emery\u001b[0m (\u001b[33mw251-asl-fp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Setup Weights and Biases\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e1306e",
   "metadata": {
    "papermill": {
     "duration": 0.014594,
     "end_time": "2023-03-27T13:49:16.606639",
     "exception": false,
     "start_time": "2023-03-27T13:49:16.592045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0888b5b-c39b-48bb-aa59-b19410aa21cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \n",
    "    \"N_COLS0\": 543,\n",
    "    \"N_COLS\": 227,\n",
    "    \"N_ROWS\":543,\n",
    "    \"N_DIMS\": 2, \n",
    "    \"N_EPOCHS\": 100,\n",
    "    \"TRAIN_BATCH_SIZE\": 512, #128,\n",
    "    \"INPUT_SIZE\":38,\n",
    "    \"BATCH_ALL_SIGNS_N\": 4,\n",
    "    \"NUM_CLASSES\": 250,\n",
    "    \"BATCH_SIZE_VAL\": 512, #128,\n",
    "    \"WD_RATIO\":0.05,\n",
    "    \"LEARNING_RATE\": 0.0001, #0.00001,\n",
    "    \"WEIGHT_DECAY\": 0.0001, #0.00001,\n",
    "    \"N_WARMUP_EPOCHS\": 2,\n",
    "    \"MASK_VAL\": 4237,\n",
    "    'LAYER_NORM_EPS' : 1e-6,\n",
    "    'LANDMARK_UNITS' : 384,\n",
    "    'TOTAL_UNITS' : 512,\n",
    "    'NUM_BLOCKS' : 2,\n",
    "    'MLP_RATIO' : 2,\n",
    "    'NUM_HEADS' : 8,\n",
    "    'EMBEDDING_DROPOUT' : 0.00,\n",
    "    'MLP_DROPOUT_RATIO' : 0.10,\n",
    "    'CLASSIFIER_DROPOUT_RATIO' : 0.10\n",
    "}\n",
    "\n",
    "USE_VAL = True\n",
    "VERBOSE = True\n",
    "\n",
    "DIM_NAMES = ['x', 'y']\n",
    "SEED = 42\n",
    "\n",
    "TRANSFORMERV1 = True\n",
    "\n",
    "# Epsilon value for layer normalisation\n",
    "LAYER_NORM_EPS = config['LAYER_NORM_EPS']\n",
    "\n",
    "# Dense layer units for landmarks\n",
    "FACE_UNITS = config['LANDMARK_UNITS']\n",
    "HANDS_UNITS = config['LANDMARK_UNITS']\n",
    "POSE_UNITS = config['LANDMARK_UNITS']\n",
    "# final embedding and transformer embedding size\n",
    "UNITS = config['TOTAL_UNITS']\n",
    "\n",
    "# Transformer\n",
    "NUM_BLOCKS = config['NUM_BLOCKS']\n",
    "MLP_RATIO = config['MLP_RATIO']\n",
    "NUM_HEADS = config['NUM_HEADS']\n",
    "\n",
    "# Dropout\n",
    "EMBEDDING_DROPOUT = config['EMBEDDING_DROPOUT']\n",
    "MLP_DROPOUT_RATIO = config['MLP_DROPOUT_RATIO']\n",
    "CLASSIFIER_DROPOUT_RATIO = config['CLASSIFIER_DROPOUT_RATIO']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b15ec671",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ec2-user/isolated-sign-language-recognition/modeling/wandb/run-20230419_233814-9unm473t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/w251-asl-fp/w251-GISLR-Final/runs/9unm473t' target=\"_blank\">decent-plasma-11</a></strong> to <a href='https://wandb.ai/w251-asl-fp/w251-GISLR-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/w251-asl-fp/w251-GISLR-Final' target=\"_blank\">https://wandb.ai/w251-asl-fp/w251-GISLR-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/w251-asl-fp/w251-GISLR-Final/runs/9unm473t' target=\"_blank\">https://wandb.ai/w251-asl-fp/w251-GISLR-Final/runs/9unm473t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/w251-asl-fp/w251-GISLR-Final/runs/9unm473t?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f84d6ee96f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOG_DIR = './logs/fit'\n",
    "wandb.tensorboard.patch(root_logdir= LOG_DIR)\n",
    "wandb.init(project='w251-GISLR-Final', \n",
    "           config=config,\n",
    "          sync_tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f840f81b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/competitions/asl-signs/overview/evaluation\n",
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "#w251-asl-data/raw-data/train_landmark_files/28656/3311214787.parquet\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc095c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prints Shape and Dtype For List Of Variables\n",
    "def print_shape_dtype(l, names):\n",
    "    for e, n in zip(l, names):\n",
    "        print(f'{n} shape: {e.shape}, dtype: {e.dtype}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30d55e35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import numpy as np\n",
    "\n",
    "class PreprocessLayerV2(tf.keras.layers.Layer):\n",
    "    def __init__(self, INPUT_SIZE):\n",
    "        super(PreprocessLayerV2, self).__init__()\n",
    "        self.INPUT_SIZE = INPUT_SIZE\n",
    "        # Indicies in original data. \n",
    "        self.FACE_IDXS = tf.constant([0, 6, 7, 11, 12, 13, 14, 15, 17, 22, 23, 24, 25, 26, 30, 31, \n",
    "                     33, 37, 38, 39, 40, 41, 42, 56, 61, 62, 72, 73, 74, 76, 77, \n",
    "                     78, 80, 81, 82, 84, 86, 87, 88, 89, 90, 91, 95, 96, 110, 112, \n",
    "                     113, 122, 128, 130, 133, 144, 145, 146, 153, 154, 155, 157, 158, \n",
    "                     159, 160, 161, 163, 168, 173, 178, 179, 180, 181, 183, 184, 185, \n",
    "                     188, 189, 190, 191, 193, 196, 197, 232, 233, 243, 244, 245, 246, \n",
    "                     247, 249, 252, 253, 254, 255, 256, 259, 260, 263, 267, 268, 269, \n",
    "                     270, 271, 272, 286, 291, 292, 302, 303, 304, 306, 307, 308, 310, \n",
    "                     311, 312, 314, 316, 317, 318, 319, 320, 321, 324, 325, 339, 341, \n",
    "                     351, 357, 359, 362, 373, 374, 375, 380, 381, 382, 384, 385, 386, \n",
    "                     387, 388, 390, 398, 402, 403, 404, 405, 407, 408, 409, 412, 413, \n",
    "                     414, 415, 417, 419, 453, 463, 464, 465, 466, 467], dtype=tf.int32)\n",
    "        self.POSE_IDXS = tf.constant(tf.range(489, 514, delta=1, dtype=tf.int32))\n",
    "        self.LEFT_HAND_IDXS = tf.constant(tf.range(468, 489, delta=1, dtype=tf.int32))\n",
    "        self.RIGHT_HAND_IDXS = tf.constant(tf.range(522, 543, delta=1, dtype=tf.int32))\n",
    "        \n",
    "        self.HAND_IDXS = tf.constant(tf.concat([self.LEFT_HAND_IDXS, self.RIGHT_HAND_IDXS], 0), dtype=tf.int32)\n",
    "            \n",
    "        # All landmarks that are used for modeling. \n",
    "        self.LANDMARK_IDXS = tf.constant(tf.concat([self.FACE_IDXS, self.POSE_IDXS, self.LEFT_HAND_IDXS, self.RIGHT_HAND_IDXS], 0), dtype=tf.int32)\n",
    "        \n",
    "        # Indicies after landmarks have been filtered. \n",
    "        self.FACE_START = tf.constant(0, dtype=tf.int32)\n",
    "        self.LEFT_HAND_START = tf.constant(len(self.FACE_IDXS), dtype=tf.int32)\n",
    "        self.POSE_START = tf.constant(self.LEFT_HAND_START + len(self.LEFT_HAND_IDXS), dtype=tf.int32)\n",
    "        self.RIGHT_HAND_START = tf.constant(self.POSE_START + len(self.POSE_IDXS), dtype=tf.int32)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'INPUT_SIZE': self.INPUT_SIZE,\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    \n",
    "    @tf.function(input_signature=(tf.TensorSpec(shape=[None, 543, 2], dtype=tf.float32),),)\n",
    "    def call(self, data):\n",
    "        \n",
    "        # Filter Out Frames With Empty Hand Data\n",
    "        frames_hands_nansum = tf.experimental.numpy.nanmean(tf.gather(data, self.HAND_IDXS, axis=1), axis=[1,2])\n",
    "        non_empty_frames_idxs = tf.where(frames_hands_nansum > 0)\n",
    "        non_empty_frames_idxs = tf.squeeze(non_empty_frames_idxs, axis=1)\n",
    "        data = tf.gather(data, non_empty_frames_idxs, axis=0)\n",
    "        \n",
    "        # Cast Indices in float32 to be compatible with Tensorflow Lite\n",
    "        non_empty_frames_idxs = tf.cast(non_empty_frames_idxs, tf.float32) \n",
    "        \n",
    "        N_FRAMES = tf.shape(data)[0]\n",
    "        data = tf.gather(data, self.LANDMARK_IDXS, axis=1)\n",
    "        \n",
    "        # Slice out face indicies, normalize across batch.        \n",
    "        face = tf.slice(data, [0, self.FACE_START, 0], [N_FRAMES, self.LEFT_HAND_START, 2])\n",
    "        # face_mean, face_std = self.get_mean_std(self.FACE_IDXS, face)\n",
    "        xs = tf.reshape(tf.transpose(face, [2,0,1]), [2,tf.size(self.FACE_IDXS)*tf.shape(face)[0]])[0]\n",
    "        ys = tf.reshape(tf.transpose(face, [2,0,1]), [2,tf.size(self.FACE_IDXS)*tf.shape(face)[0]])[1]\n",
    "            \n",
    "        FACE_MEAN_X = tf.math.reduce_mean(xs)\n",
    "        FACE_STD_X = tf.math.reduce_std(xs)\n",
    "        FACE_MEAN_Y = tf.math.reduce_mean(ys)\n",
    "        FACE_STD_Y = tf.math.reduce_std(ys)\n",
    "\n",
    "        face_mean = tf.stack([FACE_MEAN_X, FACE_MEAN_Y])\n",
    "        face_std = tf.stack([FACE_STD_X, FACE_STD_Y])\n",
    "        face = tf.where(\n",
    "                    tf.math.equal(face, 0.0),\n",
    "                    0.0,\n",
    "                    (face - face_mean) / face_std,\n",
    "                )\n",
    "        \n",
    "#         # Slice out left_hand indicies, normalize across batch.\n",
    "        left_hand = tf.slice(data, [0, self.LEFT_HAND_START, 0], [N_FRAMES, self.POSE_START-self.LEFT_HAND_START, 2])\n",
    "        xs = tf.reshape(tf.transpose(left_hand, [2,0,1]), [2,tf.size(self.LEFT_HAND_IDXS)*tf.shape(left_hand)[0]])[0]\n",
    "        ys = tf.reshape(tf.transpose(left_hand, [2,0,1]), [2,tf.size(self.LEFT_HAND_IDXS)*tf.shape(left_hand)[0]])[1]\n",
    "            \n",
    "        LEFT_HAND_MEAN_X = tf.math.reduce_mean(xs)\n",
    "        LEFT_HAND_STD_X = tf.math.reduce_std(xs)\n",
    "        LEFT_HAND_MEAN_Y = tf.math.reduce_mean(ys)\n",
    "        LEFT_HAND_STD_Y = tf.math.reduce_std(ys)\n",
    "\n",
    "        left_hand_mean = tf.stack([LEFT_HAND_MEAN_X, LEFT_HAND_MEAN_Y])\n",
    "        left_hand_std = tf.stack([LEFT_HAND_STD_X, LEFT_HAND_STD_Y])\n",
    "        left_hand = tf.where(\n",
    "                    tf.math.equal(left_hand, 0.0),\n",
    "                    0.0,\n",
    "                    (left_hand - left_hand_mean) / left_hand_std,\n",
    "                )\n",
    "        \n",
    "#         # Slice out pose indicies, normalize across batch.\n",
    "        pose = tf.slice(data, [0, self.POSE_START, 0], [N_FRAMES, self.RIGHT_HAND_START-self.POSE_START, 2])\n",
    "        xs = tf.reshape(tf.transpose(pose, [2,0,1]), [2,tf.size(self.POSE_IDXS)*tf.shape(pose)[0]])[0]\n",
    "        ys = tf.reshape(tf.transpose(pose, [2,0,1]), [2,tf.size(self.POSE_IDXS)*tf.shape(pose)[0]])[1]\n",
    "            \n",
    "        POSE_MEAN_X = tf.math.reduce_mean(xs)\n",
    "        POSE_STD_X = tf.math.reduce_std(xs)\n",
    "        POSE_MEAN_Y = tf.math.reduce_mean(ys)\n",
    "        POSE_STD_Y = tf.math.reduce_std(ys)\n",
    "\n",
    "        pose_mean = tf.stack([POSE_MEAN_X, POSE_MEAN_Y])\n",
    "        pose_std = tf.stack([POSE_STD_X, POSE_STD_Y])\n",
    "        pose = tf.where(\n",
    "                    tf.math.equal(pose, 0.0),\n",
    "                    0.0,\n",
    "                    (pose - pose_mean) / pose_std,\n",
    "                )\n",
    "        \n",
    "         # Slice out right_hand indicies, normalize across batch.\n",
    "        right_hand = tf.slice(data, [0, self.RIGHT_HAND_START, 0], [N_FRAMES, tf.shape(data)[1] - self.RIGHT_HAND_START, 2])\n",
    "        xs = tf.reshape(tf.transpose(right_hand, [2,0,1]), [2,tf.size(self.LEFT_HAND_IDXS)*tf.shape(right_hand)[0]])[0]\n",
    "        ys = tf.reshape(tf.transpose(right_hand, [2,0,1]), [2,tf.size(self.LEFT_HAND_IDXS)*tf.shape(right_hand)[0]])[1]\n",
    "            \n",
    "        RIGHT_HAND_MEAN_X = tf.math.reduce_mean(xs)\n",
    "        RIGHT_HAND_STD_X = tf.math.reduce_std(xs)\n",
    "        RIGHT_HAND_MEAN_Y = tf.math.reduce_mean(ys)\n",
    "        RIGHT_HAND_STD_Y = tf.math.reduce_std(ys)\n",
    "\n",
    "        right_hand_mean = tf.stack([RIGHT_HAND_MEAN_X, RIGHT_HAND_MEAN_Y])\n",
    "        right_hand_std = tf.stack([RIGHT_HAND_STD_X, RIGHT_HAND_STD_Y])\n",
    "        right_hand = tf.where(\n",
    "                    tf.math.equal(right_hand, 0.0),\n",
    "                    0.0,\n",
    "                    (right_hand - right_hand_mean) / right_hand_std,\n",
    "                )\n",
    "        \n",
    "        \n",
    "        # Concat landmarks back into same frame.\n",
    "        data = tf.concat([face, left_hand, pose, right_hand], 1)\n",
    "        \n",
    "        \n",
    "        # Video fits in self.INPUT_SIZE\n",
    "        if N_FRAMES < self.INPUT_SIZE: # Number of frames we want\n",
    "            # Attention mask for frames that contain data. \n",
    "            \n",
    "            non_empty_frames_idxs = tf.pad(non_empty_frames_idxs, [[0, self.INPUT_SIZE-N_FRAMES]], constant_values=-1)\n",
    "            data = tf.pad(data, [[0, self.INPUT_SIZE-N_FRAMES], [0,0], [0,0]], constant_values=0)\n",
    "            # Fill NaN Values With 0\n",
    "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "            # Reshape into (Number of desired frames, (Number of landmarks * 2))\n",
    "            data = tf.reshape(data, [self.INPUT_SIZE, tf.shape(data)[1] * 2])\n",
    "            return data, non_empty_frames_idxs\n",
    "        # Video needs to be downsampled to INPUT_SIZE\n",
    "        else:\n",
    "            # Downsample video using nearest interpolation method. \n",
    "            data = tf.image.resize(data, size=(self.INPUT_SIZE, data.shape[1]), method='nearest')\n",
    "            # Fill NaN Values With 0\n",
    "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "            # Reshape into (Number of desired frames, (Number of landmarks * 2)).\n",
    "            data = tf.reshape(data, [self.INPUT_SIZE, tf.shape(data)[1] * 2])\n",
    "            # Create attention mask with all frames. \n",
    "            non_empty_frames_idxs = tf.range(0, self.INPUT_SIZE, 1, dtype=tf.float32)\n",
    "            return data, non_empty_frames_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d982f07e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_SAMPLES: 94477\n"
     ]
    }
   ],
   "source": [
    "train_metadata = pd.read_csv('train.csv')\n",
    "\n",
    "N_SAMPLES = len(train_metadata)\n",
    "print(f'N_SAMPLES: {N_SAMPLES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b8b57f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get complete file path to file\n",
    "def get_file_path(path):\n",
    "    return f'/kaggle/input/asl-signs/{path}'\n",
    "\n",
    "train_metadata['file_path'] = train_metadata['path'].apply(get_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c2926ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add ordinally Encoded Sign (assign number to each sign name)\n",
    "train_metadata['sign_ord'] = train_metadata['sign'].astype('category').cat.codes\n",
    "\n",
    "# Dictionaries to translate sign <-> ordinal encoded sign\n",
    "SIGN2ORD = train_metadata[['sign', 'sign_ord']].set_index('sign').squeeze().to_dict()\n",
    "ORD2SIGN = train_metadata[['sign_ord', 'sign']].set_index('sign_ord').squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e35f25f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 23:38:14.787601: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-19 23:38:14.807691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-19 23:38:14.809658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-19 23:38:14.812593: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-19 23:38:14.814534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-19 23:38:14.816298: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-19 23:38:15.332158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-19 23:38:15.333201: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-19 23:38:15.333954: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-19 23:38:15.334679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20561 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "preprocess_layer = PreprocessLayerV2(config[\"INPUT_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66850e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    face: 0:468\n",
    "    left_hand: 468:489\n",
    "    pose: 489:522\n",
    "    right_hand: 522:544\n",
    "        \n",
    "\"\"\"\n",
    "def get_data(file_path):\n",
    "    # Load Raw Data\n",
    "    data = load_relevant_data_subset(file_path)\n",
    "    # Process Data Using Tensorflow\n",
    "    data = preprocess_layer(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d43c6fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the full dataset\n",
    "def preprocess_dataset():\n",
    "    # Create arrays to save data\n",
    "    X = np.zeros([N_SAMPLES, config[\"INPUT_SIZE\"], config[\"N_COLS\"] * config[\"N_DIMS\"]], dtype=np.float32)\n",
    "    y = np.zeros([N_SAMPLES], dtype=np.int32)\n",
    "    NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, config[\"INPUT_SIZE\"]], -1, dtype=np.float32)\n",
    "\n",
    "    for row_idx, (file_path, sign_ord) in enumerate(tqdm(train_metadata[['file_path', 'sign_ord']].values)):\n",
    "        if row_idx % 5000 == 0:\n",
    "            print(f'Generated {row_idx}/{N_SAMPLES}')\n",
    "\n",
    "        data, non_empty_frame_idxs = get_data(file_path)\n",
    "        X[row_idx] = data\n",
    "        y[row_idx] = sign_ord\n",
    "        NON_EMPTY_FRAME_IDXS[row_idx] = non_empty_frame_idxs\n",
    "        if np.isnan(data).sum() > 0:\n",
    "            print(row_idx)\n",
    "            return data\n",
    "    \n",
    "    # Save X/y\n",
    "    np.save('X.npy', X)\n",
    "    np.save('y.npy', y)\n",
    "    np.save('NON_EMPTY_FRAME_IDXS.npy', NON_EMPTY_FRAME_IDXS)\n",
    "        \n",
    "    return X, y, NON_EMPTY_FRAME_IDXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5e191aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X, y, NON_EMPTY_FRAME_IDXS = preprocess_dataset()\n",
    "\n",
    "# print_shape_dtype([X, y, NON_EMPTY_FRAME_IDXS], ['X', 'y', 'NON_EMPTY_FRAME_IDXS'])\n",
    "# print(f'# NaN Values X: {np.isnan(X).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50d3d8db",
   "metadata": {
    "papermill": {
     "duration": 0.039339,
     "end_time": "2023-03-27T13:50:42.441202",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.401863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USE_VAL = True\n",
    "\n",
    "# DIM_NAMES = ['x', 'y']\n",
    "# SEED = 42\n",
    "\n",
    "# TRANSFORMERV1 = True\n",
    "\n",
    "# # Epsilon value for layer normalisation\n",
    "# LAYER_NORM_EPS = 1e-6\n",
    "\n",
    "# # Dense layer units for landmarks\n",
    "# FACE_UNITS = 384\n",
    "# HANDS_UNITS = 384\n",
    "# POSE_UNITS = 384\n",
    "# # final embedding and transformer embedding size\n",
    "# UNITS = 512\n",
    "\n",
    "# # Transformer\n",
    "# NUM_BLOCKS = 2\n",
    "# MLP_RATIO = 2\n",
    "# NUM_HEADS = 8\n",
    "\n",
    "# # Dropout\n",
    "# EMBEDDING_DROPOUT = 0.00\n",
    "# MLP_DROPOUT_RATIO = 0.30\n",
    "# CLASSIFIER_DROPOUT_RATIO = 0.10\n",
    "\n",
    "# Initiailizers\n",
    "# INIT_HE_UNIFORM = tf.keras.initializers.he_uniform\n",
    "INIT_GLOROT_UNIFORM = tf.keras.initializers.glorot_uniform\n",
    "# INIT_ZEROS = tf.keras.initializers.constant(0.0)\n",
    "# Activations\n",
    "ACTIVATION = tf.keras.activations.gelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec5d4732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FACE_IDXS = [0, 6, 7, 11, 12, 13, 14, 15, 17, 22, 23, 24, 25, 26, 30, 31, \n",
    "                     33, 37, 38, 39, 40, 41, 42, 56, 61, 62, 72, 73, 74, 76, 77, \n",
    "                     78, 80, 81, 82, 84, 86, 87, 88, 89, 90, 91, 95, 96, 110, 112, \n",
    "                     113, 122, 128, 130, 133, 144, 145, 146, 153, 154, 155, 157, 158, \n",
    "                     159, 160, 161, 163, 168, 173, 178, 179, 180, 181, 183, 184, 185, \n",
    "                     188, 189, 190, 191, 193, 196, 197, 232, 233, 243, 244, 245, 246, \n",
    "                     247, 249, 252, 253, 254, 255, 256, 259, 260, 263, 267, 268, 269, \n",
    "                     270, 271, 272, 286, 291, 292, 302, 303, 304, 306, 307, 308, 310, \n",
    "                     311, 312, 314, 316, 317, 318, 319, 320, 321, 324, 325, 339, 341, \n",
    "                     351, 357, 359, 362, 373, 374, 375, 380, 381, 382, 384, 385, 386, \n",
    "                     387, 388, 390, 398, 402, 403, 404, 405, 407, 408, 409, 412, 413, \n",
    "                     414, 415, 417, 419, 453, 463, 464, 465, 466, 467]\n",
    "POSE_IDXS = np.arange(489, 514)\n",
    "LEFT_HAND_IDXS = np.arange(468, 489)\n",
    "RIGHT_HAND_IDXS = np.arange(522, 543)\n",
    "\n",
    "# All landmarks that are used for modeling. \n",
    "LANDMARK_IDXS = np.concatenate((FACE_IDXS, POSE_IDXS, LEFT_HAND_IDXS, RIGHT_HAND_IDXS))\n",
    "\n",
    "# Indicies after landmarks have been filtered. \n",
    "FACE_START = 0\n",
    "LEFT_HAND_START = len(FACE_IDXS)\n",
    "POSE_START = LEFT_HAND_START + len(LEFT_HAND_IDXS)\n",
    "RIGHT_HAND_START = POSE_START + len(POSE_IDXS)\n",
    "\n",
    "# Length of landmarks.\n",
    "FACE_LEN = len(FACE_IDXS)\n",
    "POSE_LEN = POSE_IDXS.size\n",
    "LEFT_HAND_LEN = LEFT_HAND_IDXS.size\n",
    "RIGHT_HAND_LEN = RIGHT_HAND_IDXS.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7838ebb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LandmarkEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, name, activation):\n",
    "        super(LandmarkEmbedding, self).__init__(name=f'{name}_embedding')\n",
    "        self.UNITS = units\n",
    "        self.ACTIVATION = activation\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'UNITS': self.UNITS,\n",
    "            'ACTIVATION': self.ACTIVATION,\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Embedding for missing landmark in frame, initizlied with zeros\n",
    "        self.empty_embedding = self.add_weight(\n",
    "            name=f'{self.name}_empty_embedding',\n",
    "            shape=[self.UNITS],\n",
    "            initializer=tf.keras.initializers.constant(0.0),\n",
    "        )\n",
    "        # Embedding\n",
    "        self.dense = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.UNITS, name=f'{self.name}_dense_1', use_bias=False, \n",
    "                                  kernel_initializer=tf.keras.initializers.glorot_uniform, activation=self.ACTIVATION),\n",
    "            tf.keras.layers.Dense(self.UNITS, name=f'{self.name}_dense_2', use_bias=False, kernel_initializer=tf.keras.initializers.he_uniform),\n",
    "        ], name=f'{self.name}_dense')\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.where(\n",
    "                # Checks whether landmark is missing in frame\n",
    "                tf.reduce_sum(x, axis=2, keepdims=True) == 0,\n",
    "                # If so, the empty embedding is used\n",
    "                self.empty_embedding,\n",
    "                # Otherwise the landmark data is embedded\n",
    "                self.dense(x),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bb44e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Embedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_size, face_units, hands_units, pose_units, units, activation):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.INPUT_SIZE = input_size\n",
    "        self.FACE_UNITS = face_units\n",
    "        self.HANDS_UNITS = hands_units\n",
    "        self.POSE_UNITS = pose_units\n",
    "        self.UNITS = units\n",
    "        self.ACTIVATION = activation\n",
    "        \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'INPUT_SIZE': self.INPUT_SIZE,\n",
    "            'FACE_UNITS': self.FACE_UNITS,\n",
    "            'HANDS_UNITS': self.HANDS_UNITS,\n",
    "            'POSE_UNITS': self.POSE_UNITS,\n",
    "            'UNITS': self.UNITS,\n",
    "            'ACTIVATION': self.ACTIVATION,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Positional Embedding, initialized with zeros\n",
    "        self.positional_embedding = tf.keras.layers.Embedding(self.INPUT_SIZE+1, self.UNITS, embeddings_initializer=tf.keras.initializers.constant(0.0))\n",
    "        # Embedding layer for Landmarks\n",
    "        self.face_embedding = LandmarkEmbedding(self.FACE_UNITS, 'face', self.ACTIVATION)\n",
    "        self.left_hand_embedding = LandmarkEmbedding(self.HANDS_UNITS, 'left_hand', self.ACTIVATION)\n",
    "        self.right_hand_embedding = LandmarkEmbedding(self.HANDS_UNITS, 'right_hand', self.ACTIVATION)\n",
    "        self.pose_embedding = LandmarkEmbedding(self.POSE_UNITS, 'pose', self.ACTIVATION)\n",
    "        # Landmark Weights\n",
    "        self.landmark_weights = tf.Variable(tf.zeros([4], dtype=tf.float32), name='landmark_weights')\n",
    "        # Fully Connected Layers for combined landmarks\n",
    "        self.fc = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.UNITS, name='fully_connected_1', use_bias=False, \n",
    "                                  kernel_initializer=tf.keras.initializers.glorot_uniform, activation=self.ACTIVATION),\n",
    "            tf.keras.layers.Dense(self.UNITS, name='fully_connected_2', use_bias=False, kernel_initializer=tf.keras.initializers.he_uniform),\n",
    "        ], name='fc')\n",
    "\n",
    "\n",
    "    def call(self, face0, left_hand0, right_hand0, pose0, non_empty_frame_idxs,training=False):\n",
    "        # Face\n",
    "        face_embedding = self.face_embedding(face0)\n",
    "        # Left Hand\n",
    "        left_hand_embedding = self.left_hand_embedding(left_hand0)\n",
    "        # Right Hand\n",
    "        right_hand_embedding = self.right_hand_embedding(right_hand0)\n",
    "        # Pose\n",
    "        pose_embedding = self.pose_embedding(pose0)\n",
    "        # Merge Embeddings of all landmarks with mean pooling\n",
    "        x = tf.stack((face_embedding, left_hand_embedding, right_hand_embedding, pose_embedding), axis=3)\n",
    "        # Merge Landmarks with trainable attention weights\n",
    "        x = x * tf.nn.softmax(self.landmark_weights)\n",
    "        x = tf.reduce_sum(x, axis=3)\n",
    "        # Fully Connected Layers\n",
    "        x = self.fc(x)\n",
    "        # Add Positional Embedding\n",
    "        normalised_non_empty_frame_idxs = tf.where(\n",
    "            tf.math.equal(non_empty_frame_idxs, -1.0),\n",
    "            self.INPUT_SIZE,\n",
    "            tf.cast(\n",
    "                non_empty_frame_idxs / tf.reduce_max(non_empty_frame_idxs, axis=1, keepdims=True) * self.INPUT_SIZE,\n",
    "                tf.int32,\n",
    "            ),\n",
    "        )\n",
    "        x = x + self.positional_embedding(normalised_non_empty_frame_idxs)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4af24773",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# based on: https://stackoverflow.com/questions/67342988/verifying-the-implementation-of-multihead-attention-in-transformer\n",
    "# replaced softmax with softmax layer to support masked softmax\n",
    "def scaled_dot_product(q,k,v, softmax, attention_mask):\n",
    "    #calculates Q . K(transpose)\n",
    "    qkt = tf.matmul(q,k,transpose_b=True)\n",
    "    #caculates scaling factor\n",
    "    dk = tf.math.sqrt(tf.cast(q.shape[-1],dtype=tf.float32))\n",
    "    scaled_qkt = qkt/dk\n",
    "    softmax = softmax(scaled_qkt, mask=attention_mask)\n",
    "    \n",
    "    z = tf.matmul(softmax,v)\n",
    "    #shape: (m,Tx,depth), same shape as q,k,v\n",
    "    return z\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model,num_of_heads):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_of_heads = num_of_heads\n",
    "        self.depth = d_model//num_of_heads\n",
    "        self.wq = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wk = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wv = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wo = tf.keras.layers.Dense(d_model)\n",
    "        self.softmax = tf.keras.layers.Softmax()\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'd_model': self.d_model,\n",
    "            'num_of_heads': self.num_of_heads\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def call(self,x, attention_mask):\n",
    "        multi_attn = []\n",
    "        for i in range(self.num_of_heads):\n",
    "            Q = self.wq[i](x)\n",
    "            K = self.wk[i](x)\n",
    "            V = self.wv[i](x)\n",
    "            multi_attn.append(scaled_dot_product(Q,K,V, self.softmax, attention_mask))\n",
    "            \n",
    "        multi_head = tf.concat(multi_attn,axis=-1)\n",
    "        multi_head_attention = self.wo(multi_head)\n",
    "        return multi_head_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8bcc760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full Transformer\n",
    "class Transformer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_blocks, layer_norm_eps, units, mlp_ratio, mlp_dropout_ratio, activation):\n",
    "        super(Transformer, self).__init__(name='transformer')\n",
    "        self.NUM_BLOCKS = num_blocks\n",
    "        self.LAYER_NORM_EPS = layer_norm_eps\n",
    "        self.UNITS = units\n",
    "        self.MLP_RATIO = mlp_ratio\n",
    "        self.MLP_DROPOUT_RATIO = mlp_dropout_ratio\n",
    "        self.ACTIVATION = activation\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'NUM_BLOCKS': self.NUM_BLOCKS,\n",
    "            'LAYER_NORM_EPS': self.LAYER_NORM_EPS,\n",
    "            'MLP_RATIO': self.MLP_RATIO,\n",
    "            'MLP_DROPOUT_RATIO': self.MLP_DROPOUT_RATIO,\n",
    "            'UNITS': self.UNITS,\n",
    "            'ACTIVATION': self.ACTIVATION,\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.ln_1s = []\n",
    "        self.mhas = []\n",
    "        self.ln_2s = []\n",
    "        self.mlps = []\n",
    "        # Make Transformer Blocks\n",
    "        for i in range(self.NUM_BLOCKS):\n",
    "            # First Layer Normalisation\n",
    "            self.ln_1s.append(tf.keras.layers.LayerNormalization(epsilon=self.LAYER_NORM_EPS))\n",
    "            # Multi Head Attention\n",
    "            self.mhas.append(MultiHeadAttention(self.UNITS, 4))\n",
    "            # Second Layer Normalisation\n",
    "            self.ln_2s.append(tf.keras.layers.LayerNormalization(epsilon=self.LAYER_NORM_EPS))\n",
    "            # Multi Layer Perception\n",
    "            self.mlps.append(tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(self.UNITS * self.MLP_RATIO, activation=self.ACTIVATION, \n",
    "                                      kernel_initializer=tf.keras.initializers.glorot_uniform),\n",
    "                tf.keras.layers.Dropout(self.MLP_DROPOUT_RATIO),\n",
    "                tf.keras.layers.Dense(self.UNITS, kernel_initializer=tf.keras.initializers.he_uniform),\n",
    "            ]))\n",
    "        \n",
    "    def call(self, x, attention_mask):\n",
    "        # Iterate input over transformer blocks\n",
    "        for ln_1, mha, ln_2, mlp in zip(self.ln_1s, self.mhas, self.ln_2s, self.mlps):\n",
    "            x1 = ln_1(x)\n",
    "            attention_output = mha(x1, attention_mask)\n",
    "            x2 = x1 + attention_output\n",
    "            x3 = ln_2(x2)\n",
    "            x3 = mlp(x3)\n",
    "            x = x3 + x2\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec8d504c",
   "metadata": {
    "papermill": {
     "duration": 0.043124,
     "end_time": "2023-03-27T13:50:42.896486",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.853362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    # Inputs\n",
    "    frames = tf.keras.layers.Input([config[\"INPUT_SIZE\"], config[\"N_COLS\"] * config[\"N_DIMS\"]], dtype=tf.float32, name='FRAMES')\n",
    "    non_empty_frame_idxs = tf.keras.layers.Input([config[\"INPUT_SIZE\"]], dtype=tf.float32, name='NON_EMPTY_FRAME_IDXS')\n",
    "    \n",
    "    # Attention Mask\n",
    "    mask = tf.cast(tf.math.not_equal(non_empty_frame_idxs, -1), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=2)\n",
    "    \n",
    "    # Slice out face indicies       \n",
    "    face = tf.slice(frames, [0, 0, FACE_START], [-1, config[\"INPUT_SIZE\"], FACE_LEN * 2])\n",
    "    # face = tf.reshape(frames, [-1, config[\"INPUT_SIZE\"], FACE_LEN*2])\n",
    "    \n",
    "     # Slice out left_hand indicies\n",
    "    left_hand = tf.slice(frames, [0, 0, LEFT_HAND_START * 2], [-1, config[\"INPUT_SIZE\"], LEFT_HAND_LEN * 2])\n",
    "    # left_hand = tf.reshape(frames, [-1, config[\"INPUT_SIZE\"], len(LEFT_HAND_IDXS)*2])\n",
    "\n",
    "    # Slice out pose indicies\n",
    "    pose = tf.slice(frames, [0, 0, POSE_START * 2], [-1, config[\"INPUT_SIZE\"], POSE_LEN * 2])\n",
    "    # pose = tf.reshape(frames, [-1, config[\"INPUT_SIZE\"], len(POSE_IDXS)*2])\n",
    "\n",
    "    # Slice out right_hand indicies\n",
    "    right_hand = tf.slice(frames, [0, 0, RIGHT_HAND_START * 2], [-1, config[\"INPUT_SIZE\"], RIGHT_HAND_LEN * 2])\n",
    "    # right_hand = tf.reshape(frames, [-1, config[\"INPUT_SIZE\"], len(RIGHT_HAND_IDXS)*2])\n",
    "    \n",
    "    embedding_layer = Embedding(config[\"INPUT_SIZE\"], FACE_UNITS, HANDS_UNITS, POSE_UNITS, UNITS, ACTIVATION)\n",
    "    x = embedding_layer(face, left_hand, right_hand, pose, non_empty_frame_idxs)\n",
    "    transformer_input_shape = x.shape\n",
    "    \n",
    "    if (TRANSFORMERV1):\n",
    "        # Encoder Transformer Blocks\n",
    "        transformer_layer = Transformer(NUM_BLOCKS, LAYER_NORM_EPS, UNITS, MLP_RATIO, MLP_DROPOUT_RATIO, ACTIVATION)\n",
    "        x = transformer_layer(x, mask)\n",
    "    else:\n",
    "        encoder_input_shape = transformer_input_shape\n",
    "        for _ in range(NUM_BLOCKS):\n",
    "            x = TransformerV2(encoder_input_shape, NUM_HEADS, UNITS, MLP_DROPOUT_RATIO, LAYER_NORM_EPS)(x)\n",
    "            encoder_input_shape = x.shape[1:]  # Update the input shape for the next encoder\n",
    "    \n",
    "    # Pooling\n",
    "    x = tf.reduce_sum(x * mask, axis=1) / tf.reduce_sum(mask, axis=1)\n",
    "    # Classifier Dropout\n",
    "    x = tf.keras.layers.Dropout(CLASSIFIER_DROPOUT_RATIO)(x)\n",
    "    # Classification Layer\n",
    "    x = tf.keras.layers.Dense(config[\"NUM_CLASSES\"], activation=tf.keras.activations.softmax, kernel_initializer=INIT_GLOROT_UNIFORM)(x)\n",
    "    \n",
    "    outputs = x\n",
    "    \n",
    "    # Create Tensorflow Model\n",
    "    model = tf.keras.models.Model(inputs=[frames, non_empty_frame_idxs], outputs=outputs)\n",
    "    \n",
    "    # Simple Categorical Crossentropy Loss\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    \n",
    "    # Adam Optimizer with weight decay\n",
    "    optimizer = tfa.optimizers.AdamW(learning_rate=config[\"LEARNING_RATE\"], weight_decay=config[\"WEIGHT_DECAY\"])\n",
    "    \n",
    "    # TopK Metrics\n",
    "    metrics = [\n",
    "        tf.keras.metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top_5_acc'),\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=10, name='top_10_acc'),\n",
    "    ]\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics, run_eagerly=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c752db8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.load('X.npy')\n",
    "y = np.load('y.npy')\n",
    "NON_EMPTY_FRAME_IDXS = np.load('NON_EMPTY_FRAME_IDXS.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fdb97b-7489-40f4-a69e-be79c359c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "with tf.device('CPU'):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(({\"FRAMES\": X, \"NON_EMPTY_FRAME_IDXS\": NON_EMPTY_FRAME_IDXS}, y))\n",
    "    \n",
    "train, validation, test = get_dataset_partitions_tf(dataset, X.shape[0], train_split=0.8, val_split=0.1, \n",
    "                                                test_split=0.1, shuffle=True, shuffle_size=10000, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "841f78e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom sampler to get a batch containing N times all signs\n",
    "def get_train_batch(X, y, NON_EMPTY_FRAME_IDXS, batch_size=128):\n",
    "    # Arrays to store batch in\n",
    "    X_batch = np.zeros([batch_size, config['INPUT_SIZE'], config['N_COLS'] * config['N_DIMS']], dtype=np.float32)\n",
    "    y_batch = np.arange(0, batch_size, step=1/batch_size, dtype=np.float32).astype(np.int64)\n",
    "    non_empty_frame_idxs_batch = np.zeros([batch_size, config['INPUT_SIZE']], dtype=np.float32)\n",
    "    \n",
    "    samples = X.shape[0]\n",
    "    n_batches = samples // batch_size\n",
    "    \n",
    "    while True:\n",
    "        for index in range(n_batches):\n",
    "\n",
    "            X_batch = X[(index*batch_size):((index+1)*batch_size)]\n",
    "            y_batch = y[(index*batch_size):((index+1)*batch_size)]\n",
    "            NON_EMPTY_FRAME_IDXS_batch = NON_EMPTY_FRAME_IDXS[(index*batch_size):((index+1)*batch_size)]\n",
    "\n",
    "        yield { 'FRAMES': X_batch, 'NON_EMPTY_FRAME_IDXS': NON_EMPTY_FRAME_IDXS_batch }, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "494d2293-9bf9-4b42-9fc7-03eaed798c11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "NON_EMPTY_FRAME_IDXS_train, NON_EMPTY_FRAME_IDXS_val = train_test_split(NON_EMPTY_FRAME_IDXS, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779db5cb",
   "metadata": {
    "papermill": {
     "duration": 0.038802,
     "end_time": "2023-03-27T13:51:03.381634",
     "exception": false,
     "start_time": "2023-03-27T13:51:03.342832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83ff9425",
   "metadata": {
    "papermill": {
     "duration": 0.049275,
     "end_time": "2023-03-27T13:51:03.469275",
     "exception": false,
     "start_time": "2023-03-27T13:51:03.420000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=config[\"N_EPOCHS\"], warm_method='log'):\n",
    "    \n",
    "    if current_step < num_warmup_steps:\n",
    "        if warm_method == 'log':\n",
    "            return lr_max * 0.10 ** (num_warmup_steps - current_step)\n",
    "        else:\n",
    "            return lr_max * 2 ** -(num_warmup_steps - current_step)\n",
    "    else:\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "\n",
    "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efbb6b24",
   "metadata": {
    "papermill": {
     "duration": 0.738209,
     "end_time": "2023-03-27T13:51:04.245805",
     "exception": false,
     "start_time": "2023-03-27T13:51:03.507596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Learning rate for encoder\n",
    "LR_SCHEDULE = [lrfn(step, num_warmup_steps=config[\"N_WARMUP_EPOCHS\"], \n",
    "                    lr_max=config[\"LEARNING_RATE\"], num_cycles=0.50) for step in range(config[\"N_EPOCHS\"])]\n",
    "\n",
    "# Learning Rate Callback\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2f49ca",
   "metadata": {
    "papermill": {
     "duration": 0.040725,
     "end_time": "2023-03-27T13:51:04.330003",
     "exception": false,
     "start_time": "2023-03-27T13:51:04.289278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weight Decay Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef2cbe2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom callback to update weight decay with learning rate\n",
    "class WeightDecayCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, wd_ratio=config['WD_RATIO']):\n",
    "        self.step_counter = 0\n",
    "        self.wd_ratio = wd_ratio\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n",
    "        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac727612",
   "metadata": {
    "papermill": {
     "duration": 0.040685,
     "end_time": "2023-03-27T13:51:11.352812",
     "exception": false,
     "start_time": "2023-03-27T13:51:11.312127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f26154-c87a-4609-b10e-63e93175b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all models in GPU\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Get new fresh model\n",
    "model = get_model()\n",
    "\n",
    "# Sanity Check\n",
    "model.summary()\n",
    "\n",
    "log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "# Actual Training\n",
    "history = model.fit(\n",
    "        train.batch(config['TRAIN_BATCH_SIZE']),\n",
    "        epochs=config[\"N_EPOCHS\"],\n",
    "        validation_data=validation.batch(config[\"BATCH_SIZE_VAL\"]),\n",
    "        callbacks=[\n",
    "            lr_callback,\n",
    "            WeightDecayCallback(config[\"WD_RATIO\"]),\n",
    "            tensorboard_callback\n",
    "          ],\n",
    "        verbose = VERBOSE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570bca04-9d51-4ebb-9e2d-7b25fe63d6c3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " NON_EMPTY_FRAME_IDXS (InputLay  [(None, 38)]        0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " FRAMES (InputLayer)            [(None, 38, 454)]    0           []                               \n",
      "                                                                                                  \n",
      " tf.math.not_equal (TFOpLambda)  (None, 38)          0           ['NON_EMPTY_FRAME_IDXS[0][0]']   \n",
      "                                                                                                  \n",
      " tf.slice (TFOpLambda)          (None, 38, 320)      0           ['FRAMES[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.slice_1 (TFOpLambda)        (None, 38, 42)       0           ['FRAMES[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.slice_3 (TFOpLambda)        (None, 38, 42)       0           ['FRAMES[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.slice_2 (TFOpLambda)        (None, 38, 50)       0           ['FRAMES[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)           (None, 38)           0           ['tf.math.not_equal[0][0]']      \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 38, 512)      1244420     ['tf.slice[0][0]',               \n",
      "                                                                  'tf.slice_1[0][0]',             \n",
      "                                                                  'tf.slice_3[0][0]',             \n",
      "                                                                  'tf.slice_2[0][0]',             \n",
      "                                                                  'NON_EMPTY_FRAME_IDXS[0][0]']   \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 38, 1)        0           ['tf.cast[0][0]']                \n",
      "                                                                                                  \n",
      " transformer (Transformer)      (None, 38, 512)      4205568     ['embedding[0][0]',              \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 38, 512)      0           ['transformer[0][0]',            \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None, 512)         0           ['tf.math.multiply[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOpLamb  (None, 1)           0           ['tf.expand_dims[0][0]']         \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 512)          0           ['tf.math.reduce_sum[0][0]',     \n",
      "                                                                  'tf.math.reduce_sum_1[0][0]']   \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['tf.math.truediv[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 250)          128250      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,578,238\n",
      "Trainable params: 5,578,238\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 23:38:18.848356: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5867681232 exceeds 10% of free system memory.\n",
      "2023-04-19 23:38:21.309760: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5867681232 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0001.\n",
      "learning rate: 1.00e-04, weight decay: 5.00e-06\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 23:38:24.038734: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-04-19 23:38:24.197854: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 35s 203ms/step - loss: 4.8849 - acc: 0.0658 - top_5_acc: 0.1846 - top_10_acc: 0.2682 - val_loss: 3.4318 - val_acc: 0.2373 - val_top_5_acc: 0.5135 - val_top_10_acc: 0.6378 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 9.997532801828658e-05.\n",
      "learning rate: 1.00e-04, weight decay: 5.00e-06\n",
      "Epoch 2/100\n",
      "167/167 [==============================] - 33s 200ms/step - loss: 2.9056 - acc: 0.3325 - top_5_acc: 0.6207 - top_10_acc: 0.7292 - val_loss: 2.3826 - val_acc: 0.4449 - val_top_5_acc: 0.7221 - val_top_10_acc: 0.8090 - lr: 9.9975e-05\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 9.990133642141359e-05.\n",
      "learning rate: 9.99e-05, weight decay: 5.00e-06\n",
      "Epoch 3/100\n",
      "167/167 [==============================] - 33s 200ms/step - loss: 2.1724 - acc: 0.4842 - top_5_acc: 0.7528 - top_10_acc: 0.8302 - val_loss: 1.9315 - val_acc: 0.5500 - val_top_5_acc: 0.7883 - val_top_10_acc: 0.8525 - lr: 9.9901e-05\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 9.977809823015401e-05.\n",
      "learning rate: 9.98e-05, weight decay: 4.99e-06\n",
      "Epoch 4/100\n",
      "167/167 [==============================] - 34s 201ms/step - loss: 1.8098 - acc: 0.5612 - top_5_acc: 0.8077 - top_10_acc: 0.8687 - val_loss: 1.8030 - val_acc: 0.5731 - val_top_5_acc: 0.8061 - val_top_10_acc: 0.8667 - lr: 9.9778e-05\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 9.96057350657239e-05.\n",
      "learning rate: 9.96e-05, weight decay: 4.98e-06\n",
      "Epoch 5/100\n",
      "167/167 [==============================] - 34s 201ms/step - loss: 1.5772 - acc: 0.6155 - top_5_acc: 0.8388 - top_10_acc: 0.8899 - val_loss: 1.6289 - val_acc: 0.6097 - val_top_5_acc: 0.8299 - val_top_10_acc: 0.8818 - lr: 9.9606e-05\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 9.938441702975689e-05.\n",
      "learning rate: 9.94e-05, weight decay: 4.97e-06\n",
      "Epoch 6/100\n",
      "167/167 [==============================] - 34s 201ms/step - loss: 1.4133 - acc: 0.6517 - top_5_acc: 0.8604 - top_10_acc: 0.9043 - val_loss: 1.5069 - val_acc: 0.6435 - val_top_5_acc: 0.8456 - val_top_10_acc: 0.8934 - lr: 9.9384e-05\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 9.911436253643445e-05.\n",
      "learning rate: 9.91e-05, weight decay: 4.96e-06\n",
      "Epoch 7/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 1.2815 - acc: 0.6828 - top_5_acc: 0.8764 - top_10_acc: 0.9154 - val_loss: 1.4492 - val_acc: 0.6577 - val_top_5_acc: 0.8545 - val_top_10_acc: 0.8962 - lr: 9.9114e-05\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 9.879583809693738e-05.\n",
      "learning rate: 9.88e-05, weight decay: 4.94e-06\n",
      "Epoch 8/100\n",
      "167/167 [==============================] - 34s 201ms/step - loss: 1.1760 - acc: 0.7056 - top_5_acc: 0.8895 - top_10_acc: 0.9247 - val_loss: 1.3861 - val_acc: 0.6715 - val_top_5_acc: 0.8595 - val_top_10_acc: 0.8982 - lr: 9.8796e-05\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 9.842915805643155e-05.\n",
      "learning rate: 9.84e-05, weight decay: 4.92e-06\n",
      "Epoch 9/100\n",
      "167/167 [==============================] - 34s 201ms/step - loss: 1.0834 - acc: 0.7290 - top_5_acc: 0.9002 - top_10_acc: 0.9310 - val_loss: 1.3487 - val_acc: 0.6791 - val_top_5_acc: 0.8635 - val_top_10_acc: 0.9027 - lr: 9.8429e-05\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 9.801468428384716e-05.\n",
      "learning rate: 9.80e-05, weight decay: 4.90e-06\n",
      "Epoch 10/100\n",
      "167/167 [==============================] - 34s 201ms/step - loss: 1.0045 - acc: 0.7470 - top_5_acc: 0.9092 - top_10_acc: 0.9385 - val_loss: 1.3280 - val_acc: 0.6880 - val_top_5_acc: 0.8666 - val_top_10_acc: 0.9063 - lr: 9.8015e-05\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 9.755282581475769e-05.\n",
      "learning rate: 9.76e-05, weight decay: 4.88e-06\n",
      "Epoch 11/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.9252 - acc: 0.7667 - top_5_acc: 0.9174 - top_10_acc: 0.9443 - val_loss: 1.2563 - val_acc: 0.7037 - val_top_5_acc: 0.8775 - val_top_10_acc: 0.9136 - lr: 9.7553e-05\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 9.704403844771128e-05.\n",
      "learning rate: 9.70e-05, weight decay: 4.85e-06\n",
      "Epoch 12/100\n",
      "167/167 [==============================] - 34s 201ms/step - loss: 0.8584 - acc: 0.7817 - top_5_acc: 0.9252 - top_10_acc: 0.9503 - val_loss: 1.2858 - val_acc: 0.6949 - val_top_5_acc: 0.8739 - val_top_10_acc: 0.9102 - lr: 9.7044e-05\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 9.648882429441257e-05.\n",
      "learning rate: 9.65e-05, weight decay: 4.82e-06\n",
      "Epoch 13/100\n",
      "167/167 [==============================] - 34s 201ms/step - loss: 0.8085 - acc: 0.7935 - top_5_acc: 0.9313 - top_10_acc: 0.9539 - val_loss: 1.2401 - val_acc: 0.7052 - val_top_5_acc: 0.8790 - val_top_10_acc: 0.9145 - lr: 9.6489e-05\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 9.588773128419906e-05.\n",
      "learning rate: 9.59e-05, weight decay: 4.79e-06\n",
      "Epoch 14/100\n",
      "167/167 [==============================] - 34s 201ms/step - loss: 0.7498 - acc: 0.8062 - top_5_acc: 0.9383 - top_10_acc: 0.9588 - val_loss: 1.2231 - val_acc: 0.7152 - val_top_5_acc: 0.8821 - val_top_10_acc: 0.9159 - lr: 9.5888e-05\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 9.524135262330098e-05.\n",
      "learning rate: 9.52e-05, weight decay: 4.76e-06\n",
      "Epoch 15/100\n",
      "167/167 [==============================] - 34s 201ms/step - loss: 0.6985 - acc: 0.8202 - top_5_acc: 0.9436 - top_10_acc: 0.9626 - val_loss: 1.2336 - val_acc: 0.7132 - val_top_5_acc: 0.8801 - val_top_10_acc: 0.9129 - lr: 9.5241e-05\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 9.45503262094184e-05.\n",
      "learning rate: 9.46e-05, weight decay: 4.73e-06\n",
      "Epoch 16/100\n",
      "167/167 [==============================] - 34s 201ms/step - loss: 0.6588 - acc: 0.8305 - top_5_acc: 0.9486 - top_10_acc: 0.9664 - val_loss: 1.2516 - val_acc: 0.7097 - val_top_5_acc: 0.8797 - val_top_10_acc: 0.9122 - lr: 9.4550e-05\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 9.381533400219318e-05.\n",
      "learning rate: 9.38e-05, weight decay: 4.69e-06\n",
      "Epoch 17/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.6145 - acc: 0.8403 - top_5_acc: 0.9534 - top_10_acc: 0.9698 - val_loss: 1.2115 - val_acc: 0.7213 - val_top_5_acc: 0.8837 - val_top_10_acc: 0.9154 - lr: 9.3815e-05\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 9.30371013501972e-05.\n",
      "learning rate: 9.30e-05, weight decay: 4.65e-06\n",
      "Epoch 18/100\n",
      "167/167 [==============================] - 34s 201ms/step - loss: 0.5649 - acc: 0.8543 - top_5_acc: 0.9580 - top_10_acc: 0.9733 - val_loss: 1.2097 - val_acc: 0.7213 - val_top_5_acc: 0.8838 - val_top_10_acc: 0.9187 - lr: 9.3037e-05\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 9.221639627510076e-05.\n",
      "learning rate: 9.22e-05, weight decay: 4.61e-06\n",
      "Epoch 19/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.5299 - acc: 0.8623 - top_5_acc: 0.9615 - top_10_acc: 0.9758 - val_loss: 1.2065 - val_acc: 0.7239 - val_top_5_acc: 0.8859 - val_top_10_acc: 0.9178 - lr: 9.2216e-05\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 9.135402871372808e-05.\n",
      "learning rate: 9.14e-05, weight decay: 4.57e-06\n",
      "Epoch 20/100\n",
      "167/167 [==============================] - 34s 201ms/step - loss: 0.4904 - acc: 0.8728 - top_5_acc: 0.9657 - top_10_acc: 0.9783 - val_loss: 1.2628 - val_acc: 0.7105 - val_top_5_acc: 0.8847 - val_top_10_acc: 0.9166 - lr: 9.1354e-05\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 9.045084971874738e-05.\n",
      "learning rate: 9.05e-05, weight decay: 4.52e-06\n",
      "Epoch 21/100\n",
      "167/167 [==============================] - 34s 201ms/step - loss: 0.4472 - acc: 0.8842 - top_5_acc: 0.9694 - top_10_acc: 0.9811 - val_loss: 1.2216 - val_acc: 0.7263 - val_top_5_acc: 0.8873 - val_top_10_acc: 0.9198 - lr: 9.0451e-05\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 8.950775061878453e-05.\n",
      "learning rate: 8.95e-05, weight decay: 4.48e-06\n",
      "Epoch 22/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.4141 - acc: 0.8923 - top_5_acc: 0.9734 - top_10_acc: 0.9837 - val_loss: 1.2409 - val_acc: 0.7220 - val_top_5_acc: 0.8879 - val_top_10_acc: 0.9213 - lr: 8.9508e-05\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 8.852566213878947e-05.\n",
      "learning rate: 8.85e-05, weight decay: 4.43e-06\n",
      "Epoch 23/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.3851 - acc: 0.8990 - top_5_acc: 0.9765 - top_10_acc: 0.9860 - val_loss: 1.2778 - val_acc: 0.7229 - val_top_5_acc: 0.8817 - val_top_10_acc: 0.9148 - lr: 8.8526e-05\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 8.750555348152298e-05.\n",
      "learning rate: 8.75e-05, weight decay: 4.38e-06\n",
      "Epoch 24/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.3557 - acc: 0.9066 - top_5_acc: 0.9793 - top_10_acc: 0.9882 - val_loss: 1.3372 - val_acc: 0.7086 - val_top_5_acc: 0.8802 - val_top_10_acc: 0.9126 - lr: 8.7506e-05\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 8.644843137107059e-05.\n",
      "learning rate: 8.64e-05, weight decay: 4.32e-06\n",
      "Epoch 25/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.3321 - acc: 0.9126 - top_5_acc: 0.9812 - top_10_acc: 0.9891 - val_loss: 1.2365 - val_acc: 0.7294 - val_top_5_acc: 0.8861 - val_top_10_acc: 0.9183 - lr: 8.6448e-05\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 8.535533905932738e-05.\n",
      "learning rate: 8.54e-05, weight decay: 4.27e-06\n",
      "Epoch 26/100\n",
      "167/167 [==============================] - 34s 204ms/step - loss: 0.2979 - acc: 0.9224 - top_5_acc: 0.9845 - top_10_acc: 0.9913 - val_loss: 1.2658 - val_acc: 0.7270 - val_top_5_acc: 0.8845 - val_top_10_acc: 0.9186 - lr: 8.5355e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 8.422735529643444e-05.\n",
      "learning rate: 8.42e-05, weight decay: 4.21e-06\n",
      "Epoch 27/100\n",
      "167/167 [==============================] - 34s 203ms/step - loss: 0.2692 - acc: 0.9306 - top_5_acc: 0.9869 - top_10_acc: 0.9927 - val_loss: 1.2693 - val_acc: 0.7291 - val_top_5_acc: 0.8861 - val_top_10_acc: 0.9181 - lr: 8.4227e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 8.306559326618259e-05.\n",
      "learning rate: 8.31e-05, weight decay: 4.15e-06\n",
      "Epoch 28/100\n",
      "167/167 [==============================] - 34s 203ms/step - loss: 0.2481 - acc: 0.9352 - top_5_acc: 0.9891 - top_10_acc: 0.9939 - val_loss: 1.2780 - val_acc: 0.7285 - val_top_5_acc: 0.8884 - val_top_10_acc: 0.9171 - lr: 8.3066e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 8.18711994874345e-05.\n",
      "learning rate: 8.19e-05, weight decay: 4.09e-06\n",
      "Epoch 29/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.2292 - acc: 0.9410 - top_5_acc: 0.9906 - top_10_acc: 0.9950 - val_loss: 1.3078 - val_acc: 0.7285 - val_top_5_acc: 0.8881 - val_top_10_acc: 0.9183 - lr: 8.1871e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 8.064535268264883e-05.\n",
      "learning rate: 8.06e-05, weight decay: 4.03e-06\n",
      "Epoch 30/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.2047 - acc: 0.9479 - top_5_acc: 0.9922 - top_10_acc: 0.9960 - val_loss: 1.2877 - val_acc: 0.7357 - val_top_5_acc: 0.8896 - val_top_10_acc: 0.9188 - lr: 8.0645e-05\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 7.938926261462366e-05.\n",
      "learning rate: 7.94e-05, weight decay: 3.97e-06\n",
      "Epoch 31/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.1805 - acc: 0.9557 - top_5_acc: 0.9937 - top_10_acc: 0.9968 - val_loss: 1.3371 - val_acc: 0.7288 - val_top_5_acc: 0.8864 - val_top_10_acc: 0.9169 - lr: 7.9389e-05\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 7.810416889260653e-05.\n",
      "learning rate: 7.81e-05, weight decay: 3.91e-06\n",
      "Epoch 32/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.1737 - acc: 0.9568 - top_5_acc: 0.9947 - top_10_acc: 0.9973 - val_loss: 1.3487 - val_acc: 0.7290 - val_top_5_acc: 0.8837 - val_top_10_acc: 0.9172 - lr: 7.8104e-05\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 7.679133974894983e-05.\n",
      "learning rate: 7.68e-05, weight decay: 3.84e-06\n",
      "Epoch 33/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.1676 - acc: 0.9569 - top_5_acc: 0.9955 - top_10_acc: 0.9980 - val_loss: 1.3577 - val_acc: 0.7315 - val_top_5_acc: 0.8881 - val_top_10_acc: 0.9168 - lr: 7.6791e-05\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 7.545207078751857e-05.\n",
      "learning rate: 7.55e-05, weight decay: 3.77e-06\n",
      "Epoch 34/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.1473 - acc: 0.9642 - top_5_acc: 0.9962 - top_10_acc: 0.9982 - val_loss: 1.3624 - val_acc: 0.7329 - val_top_5_acc: 0.8869 - val_top_10_acc: 0.9178 - lr: 7.5452e-05\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 7.408768370508576e-05.\n",
      "learning rate: 7.41e-05, weight decay: 3.70e-06\n",
      "Epoch 35/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.1278 - acc: 0.9690 - top_5_acc: 0.9971 - top_10_acc: 0.9988 - val_loss: 1.3635 - val_acc: 0.7341 - val_top_5_acc: 0.8878 - val_top_10_acc: 0.9178 - lr: 7.4088e-05\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 7.269952498697734e-05.\n",
      "learning rate: 7.27e-05, weight decay: 3.63e-06\n",
      "Epoch 36/100\n",
      "167/167 [==============================] - 34s 203ms/step - loss: 0.1181 - acc: 0.9718 - top_5_acc: 0.9978 - top_10_acc: 0.9991 - val_loss: 1.3807 - val_acc: 0.7336 - val_top_5_acc: 0.8863 - val_top_10_acc: 0.9170 - lr: 7.2700e-05\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 7.128896457825364e-05.\n",
      "learning rate: 7.13e-05, weight decay: 3.56e-06\n",
      "Epoch 37/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.1107 - acc: 0.9735 - top_5_acc: 0.9980 - top_10_acc: 0.9991 - val_loss: 1.4090 - val_acc: 0.7315 - val_top_5_acc: 0.8873 - val_top_10_acc: 0.9171 - lr: 7.1289e-05\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 6.985739453173903e-05.\n",
      "learning rate: 6.99e-05, weight decay: 3.49e-06\n",
      "Epoch 38/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.1029 - acc: 0.9763 - top_5_acc: 0.9983 - top_10_acc: 0.9994 - val_loss: 1.4162 - val_acc: 0.7323 - val_top_5_acc: 0.8874 - val_top_10_acc: 0.9185 - lr: 6.9857e-05\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 6.840622763423391e-05.\n",
      "learning rate: 6.84e-05, weight decay: 3.42e-06\n",
      "Epoch 39/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.0930 - acc: 0.9787 - top_5_acc: 0.9988 - top_10_acc: 0.9995 - val_loss: 1.4227 - val_acc: 0.7325 - val_top_5_acc: 0.8894 - val_top_10_acc: 0.9187 - lr: 6.8406e-05\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 6.693689601226458e-05.\n",
      "learning rate: 6.69e-05, weight decay: 3.35e-06\n",
      "Epoch 40/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.0823 - acc: 0.9824 - top_5_acc: 0.9991 - top_10_acc: 0.9997 - val_loss: 1.4351 - val_acc: 0.7345 - val_top_5_acc: 0.8871 - val_top_10_acc: 0.9183 - lr: 6.6937e-05\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 6.545084971874738e-05.\n",
      "learning rate: 6.55e-05, weight decay: 3.27e-06\n",
      "Epoch 41/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.0782 - acc: 0.9831 - top_5_acc: 0.9994 - top_10_acc: 0.9998 - val_loss: 1.4432 - val_acc: 0.7374 - val_top_5_acc: 0.8849 - val_top_10_acc: 0.9188 - lr: 6.5451e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 6.394955530196147e-05.\n",
      "learning rate: 6.39e-05, weight decay: 3.20e-06\n",
      "Epoch 42/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.0716 - acc: 0.9851 - top_5_acc: 0.9994 - top_10_acc: 0.9998 - val_loss: 1.4834 - val_acc: 0.7313 - val_top_5_acc: 0.8855 - val_top_10_acc: 0.9171 - lr: 6.3950e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 6.243449435824276e-05.\n",
      "learning rate: 6.24e-05, weight decay: 3.12e-06\n",
      "Epoch 43/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.0646 - acc: 0.9869 - top_5_acc: 0.9995 - top_10_acc: 0.9998 - val_loss: 1.4670 - val_acc: 0.7358 - val_top_5_acc: 0.8873 - val_top_10_acc: 0.9200 - lr: 6.2434e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 6.090716206982714e-05.\n",
      "learning rate: 6.09e-05, weight decay: 3.05e-06\n",
      "Epoch 44/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.0613 - acc: 0.9873 - top_5_acc: 0.9996 - top_10_acc: 0.9999 - val_loss: 1.4771 - val_acc: 0.7379 - val_top_5_acc: 0.8848 - val_top_10_acc: 0.9205 - lr: 6.0907e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 5.9369065729286245e-05.\n",
      "learning rate: 5.94e-05, weight decay: 2.97e-06\n",
      "Epoch 45/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.0520 - acc: 0.9897 - top_5_acc: 0.9997 - top_10_acc: 1.0000 - val_loss: 1.5005 - val_acc: 0.7337 - val_top_5_acc: 0.8821 - val_top_10_acc: 0.9159 - lr: 5.9369e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 5.782172325201155e-05.\n",
      "learning rate: 5.78e-05, weight decay: 2.89e-06\n",
      "Epoch 46/100\n",
      "167/167 [==============================] - 34s 203ms/step - loss: 0.0611 - acc: 0.9871 - top_5_acc: 0.9996 - top_10_acc: 0.9999 - val_loss: 1.5026 - val_acc: 0.7334 - val_top_5_acc: 0.8866 - val_top_10_acc: 0.9188 - lr: 5.7822e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 5.6266661678215216e-05.\n",
      "learning rate: 5.63e-05, weight decay: 2.81e-06\n",
      "Epoch 47/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.0474 - acc: 0.9908 - top_5_acc: 0.9998 - top_10_acc: 1.0000 - val_loss: 1.5018 - val_acc: 0.7369 - val_top_5_acc: 0.8874 - val_top_10_acc: 0.9190 - lr: 5.6267e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 5.470541566592573e-05.\n",
      "learning rate: 5.47e-05, weight decay: 2.74e-06\n",
      "Epoch 48/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.0390 - acc: 0.9935 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 1.5044 - val_acc: 0.7385 - val_top_5_acc: 0.8882 - val_top_10_acc: 0.9175 - lr: 5.4705e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 5.313952597646568e-05.\n",
      "learning rate: 5.31e-05, weight decay: 2.66e-06\n",
      "Epoch 49/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.0349 - acc: 0.9942 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 1.5214 - val_acc: 0.7387 - val_top_5_acc: 0.8888 - val_top_10_acc: 0.9182 - lr: 5.3140e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 5.157053795390642e-05.\n",
      "learning rate: 5.16e-05, weight decay: 2.58e-06\n",
      "Epoch 50/100\n",
      "167/167 [==============================] - 34s 203ms/step - loss: 0.0381 - acc: 0.9932 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 1.5298 - val_acc: 0.7326 - val_top_5_acc: 0.8887 - val_top_10_acc: 0.9193 - lr: 5.1571e-05\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 5e-05.\n",
      "learning rate: 5.00e-05, weight decay: 2.50e-06\n",
      "Epoch 51/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.0327 - acc: 0.9947 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 1.5287 - val_acc: 0.7391 - val_top_5_acc: 0.8865 - val_top_10_acc: 0.9189 - lr: 5.0000e-05\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 4.8429462046093585e-05.\n",
      "learning rate: 4.84e-05, weight decay: 2.42e-06\n",
      "Epoch 52/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.0304 - acc: 0.9954 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 1.5355 - val_acc: 0.7411 - val_top_5_acc: 0.8871 - val_top_10_acc: 0.9202 - lr: 4.8429e-05\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 4.6860474023534335e-05.\n",
      "learning rate: 4.69e-05, weight decay: 2.34e-06\n",
      "Epoch 53/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.0277 - acc: 0.9958 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 1.5579 - val_acc: 0.7404 - val_top_5_acc: 0.8859 - val_top_10_acc: 0.9187 - lr: 4.6860e-05\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 4.529458433407429e-05.\n",
      "learning rate: 4.53e-05, weight decay: 2.26e-06\n",
      "Epoch 54/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.0260 - acc: 0.9961 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 1.5667 - val_acc: 0.7380 - val_top_5_acc: 0.8862 - val_top_10_acc: 0.9183 - lr: 4.5295e-05\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 4.373333832178478e-05.\n",
      "learning rate: 4.37e-05, weight decay: 2.19e-06\n",
      "Epoch 55/100\n",
      "167/167 [==============================] - 34s 204ms/step - loss: 0.0242 - acc: 0.9965 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 1.5703 - val_acc: 0.7379 - val_top_5_acc: 0.8883 - val_top_10_acc: 0.9191 - lr: 4.3733e-05\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 4.2178276747988446e-05.\n",
      "learning rate: 4.22e-05, weight decay: 2.11e-06\n",
      "Epoch 56/100\n",
      "167/167 [==============================] - 34s 203ms/step - loss: 0.0221 - acc: 0.9968 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 1.5828 - val_acc: 0.7374 - val_top_5_acc: 0.8860 - val_top_10_acc: 0.9175 - lr: 4.2178e-05\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 4.063093427071376e-05.\n",
      "learning rate: 4.06e-05, weight decay: 2.03e-06\n",
      "Epoch 57/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.0213 - acc: 0.9971 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 1.6002 - val_acc: 0.7386 - val_top_5_acc: 0.8878 - val_top_10_acc: 0.9178 - lr: 4.0631e-05\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 3.9092837930172884e-05.\n",
      "learning rate: 3.91e-05, weight decay: 1.95e-06\n",
      "Epoch 58/100\n",
      "167/167 [==============================] - 34s 203ms/step - loss: 0.0184 - acc: 0.9979 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 1.5979 - val_acc: 0.7374 - val_top_5_acc: 0.8871 - val_top_10_acc: 0.9174 - lr: 3.9093e-05\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 3.756550564175727e-05.\n",
      "learning rate: 3.76e-05, weight decay: 1.88e-06\n",
      "Epoch 59/100\n",
      "167/167 [==============================] - 34s 204ms/step - loss: 0.0177 - acc: 0.9978 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 1.5942 - val_acc: 0.7394 - val_top_5_acc: 0.8867 - val_top_10_acc: 0.9168 - lr: 3.7566e-05\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 3.605044469803854e-05.\n",
      "learning rate: 3.61e-05, weight decay: 1.80e-06\n",
      "Epoch 60/100\n",
      "167/167 [==============================] - 34s 203ms/step - loss: 0.0197 - acc: 0.9974 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 1.6113 - val_acc: 0.7383 - val_top_5_acc: 0.8877 - val_top_10_acc: 0.9187 - lr: 3.6050e-05\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 3.4549150281252636e-05.\n",
      "learning rate: 3.45e-05, weight decay: 1.73e-06\n",
      "Epoch 61/100\n",
      "167/167 [==============================] - 34s 203ms/step - loss: 0.0173 - acc: 0.9978 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 1.6076 - val_acc: 0.7420 - val_top_5_acc: 0.8874 - val_top_10_acc: 0.9199 - lr: 3.4549e-05\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 3.3063103987735433e-05.\n",
      "learning rate: 3.31e-05, weight decay: 1.65e-06\n",
      "Epoch 62/100\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 0.0141 - acc: 0.9987 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 1.6106 - val_acc: 0.7419 - val_top_5_acc: 0.8893 - val_top_10_acc: 0.9198 - lr: 3.3063e-05\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 3.1593772365766105e-05.\n",
      "learning rate: 3.16e-05, weight decay: 1.58e-06\n",
      "Epoch 63/100\n",
      " 58/167 [=========>....................] - ETA: 20s - loss: 0.0143 - acc: 0.9983 - top_5_acc: 1.0000 - top_10_acc: 1.0000"
     ]
    }
   ],
   "source": [
    "# Clear all models in GPU\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Get new fresh model\n",
    "model = get_model()\n",
    "\n",
    "# Sanity Check\n",
    "model.summary()\n",
    "\n",
    "log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "# Actual Training\n",
    "\n",
    "history = model.fit(\n",
    "    x=({ 'FRAMES': X, 'NON_EMPTY_FRAME_IDXS': NON_EMPTY_FRAME_IDXS }),\n",
    "    y=y,\n",
    "    batch_size=config['TRAIN_BATCH_SIZE'],\n",
    "    epochs=config['N_EPOCHS'],\n",
    "    verbose=VERBOSE,\n",
    "    callbacks=[\n",
    "            lr_callback,\n",
    "            WeightDecayCallback(config[\"WD_RATIO\"]),\n",
    "            tensorboard_callback\n",
    "          ],\n",
    "    validation_split=0.1,\n",
    "    # shuffle=True,\n",
    "    # steps_per_epoch=None,\n",
    "    # validation_steps=None,\n",
    "    # validation_batch_size=None,\n",
    "    # validation_freq=1,\n",
    "    # max_queue_size=10,\n",
    "    # workers=1,\n",
    "    # use_multiprocessing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb34e2f",
   "metadata": {
    "papermill": {
     "duration": 2852.852405,
     "end_time": "2023-03-27T14:38:44.682355",
     "exception": false,
     "start_time": "2023-03-27T13:51:11.829950",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish... (success).\n"
     ]
    }
   ],
   "source": [
    "# # Clear all models in GPU\n",
    "# tf.keras.backend.clear_session()\n",
    "\n",
    "# # Get new fresh model\n",
    "# model = get_model()\n",
    "\n",
    "# # Sanity Check\n",
    "# model.summary()\n",
    "\n",
    "# log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# # stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "# # Actual Training\n",
    "# history = model.fit(\n",
    "#         x=get_train_batch(X_train, y_train, NON_EMPTY_FRAME_IDXS_train, batch_size=config['TRAIN_BATCH_SIZE']),\n",
    "#         steps_per_epoch= len(X_train) // config['TRAIN_BATCH_SIZE'],\n",
    "#         epochs=config[\"N_EPOCHS\"],\n",
    "#         validation_data= ({ 'FRAMES': X_val, 'NON_EMPTY_FRAME_IDXS': NON_EMPTY_FRAME_IDXS_val }, y_val),\n",
    "#         batch_size=config[\"BATCH_SIZE_VAL\"],\n",
    "#         callbacks=[\n",
    "#             lr_callback,\n",
    "#             WeightDecayCallback(config[\"WD_RATIO\"]),\n",
    "# #             tensorboard_callback\n",
    "#           ],\n",
    "#         verbose = VERBOSE,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78674927",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-19T05:50:20.628656Z",
     "iopub.status.idle": "2023-04-19T05:50:20.629604Z",
     "shell.execute_reply": "2023-04-19T05:50:20.629353Z",
     "shell.execute_reply.started": "2023-04-19T05:50:20.629322Z"
    },
    "papermill": {
     "duration": 0.204275,
     "end_time": "2023-03-27T14:38:44.950811",
     "exception": false,
     "start_time": "2023-03-27T14:38:44.746536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save Model Weights\n",
    "model.save_weights(f'model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf980c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-19T05:50:20.631264Z",
     "iopub.status.idle": "2023-04-19T05:50:20.631765Z",
     "shell.execute_reply": "2023-04-19T05:50:20.631531Z",
     "shell.execute_reply.started": "2023-04-19T05:50:20.631505Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = get_model()\n",
    "# model.load_weights('tf_models/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c0df4e",
   "metadata": {
    "papermill": {
     "duration": 0.065813,
     "end_time": "2023-03-27T14:38:48.284324",
     "exception": false,
     "start_time": "2023-03-27T14:38:48.218511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission\n",
    "\n",
    "Submission code loosley based on [this notebook](https://www.kaggle.com/code/dschettler8845/gislr-learn-eda-baseline#baseline) by [Darien Schettler\n",
    "](https://www.kaggle.com/dschettler8845)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ce3fe",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-19T05:50:20.633657Z",
     "iopub.status.idle": "2023-04-19T05:50:20.634182Z",
     "shell.execute_reply": "2023-04-19T05:50:20.633929Z",
     "shell.execute_reply.started": "2023-04-19T05:50:20.633901Z"
    },
    "papermill": {
     "duration": 1.644953,
     "end_time": "2023-03-27T14:38:49.995113",
     "exception": false,
     "start_time": "2023-03-27T14:38:48.350160",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TFLite model for submission\n",
    "class TFLiteModel(tf.keras.Model):\n",
    "    def __init__(self, model):\n",
    "        super(TFLiteModel, self).__init__()\n",
    "\n",
    "        # Load the feature generation and main models\n",
    "        self.preprocess_layer = preprocess_layer\n",
    "        self.model = model\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, config[\"N_ROWS\"], config[\"N_DIMS\"]], dtype=tf.float32, name='inputs')])\n",
    "    def call(self, inputs):\n",
    "        # Preprocess Data\n",
    "        x, non_empty_frame_idxs = self.preprocess_layer(inputs)\n",
    "        # Add Batch Dimension\n",
    "        x = tf.expand_dims(x, axis=0)\n",
    "        non_empty_frame_idxs = tf.expand_dims(non_empty_frame_idxs, axis=0)\n",
    "        # Make Prediction\n",
    "        outputs = self.model({'FRAMES': x, 'NON_EMPTY_FRAME_IDXS': non_empty_frame_idxs })\n",
    "        # Squeeze Output 1x250 -> 250\n",
    "        outputs = tf.squeeze(outputs, axis=0)\n",
    "\n",
    "        # Return a dictionary with the output tensor\n",
    "        return {'outputs': outputs}\n",
    "\n",
    "# Define TF Lite Model\n",
    "tflite_keras_model = TFLiteModel(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9cf4b6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-19T05:50:20.635956Z",
     "iopub.status.idle": "2023-04-19T05:50:20.636481Z",
     "shell.execute_reply": "2023-04-19T05:50:20.636246Z",
     "shell.execute_reply.started": "2023-04-19T05:50:20.636210Z"
    },
    "papermill": {
     "duration": 32.570402,
     "end_time": "2023-03-27T14:39:22.633212",
     "exception": false,
     "start_time": "2023-03-27T14:38:50.062810",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Model Converter\n",
    "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflite_keras_model)\n",
    "keras_model_converter.experimental_new_converter = True\n",
    "\n",
    "# Convert Model\n",
    "tflite_model = keras_model_converter.convert()\n",
    "# Write Model\n",
    "with open(f'model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "    \n",
    "# Zip Model\n",
    "!zip submission.zip /kaggle/working/model.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15fede1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-19T05:50:20.638302Z",
     "iopub.status.idle": "2023-04-19T05:50:20.638805Z",
     "shell.execute_reply": "2023-04-19T05:50:20.638569Z",
     "shell.execute_reply.started": "2023-04-19T05:50:20.638543Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "demo_raw_data = load_relevant_data_subset(train_metadata['file_path'].values[2])\n",
    "print(f'demo_raw_data shape: {demo_raw_data.shape}, dtype: {demo_raw_data.dtype}')\n",
    "demo_output = tflite_keras_model(demo_raw_data)[\"outputs\"]\n",
    "print(f'demo_output shape: {demo_output.shape}, dtype: {demo_output.dtype}')\n",
    "demo_prediction = demo_output.numpy().argmax()\n",
    "print(f'demo_prediction: {demo_prediction}, correct: {train_metadata.iloc[0][\"sign_ord\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b01c0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-19T05:50:20.640611Z",
     "iopub.status.idle": "2023-04-19T05:50:20.641138Z",
     "shell.execute_reply": "2023-04-19T05:50:20.640885Z",
     "shell.execute_reply.started": "2023-04-19T05:50:20.640857Z"
    },
    "papermill": {
     "duration": 11.438209,
     "end_time": "2023-03-27T14:39:34.137659",
     "exception": false,
     "start_time": "2023-03-27T14:39:22.699450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify TFLite model can be loaded and used for prediction\n",
    "# !pip install tflite-runtime\n",
    "# import tf.lite.interpreter as tflite\n",
    "\n",
    "interpreter = tf.lite.Interpreter(\"/kaggle/working/model.tflite\")\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "output = prediction_fn(inputs=demo_raw_data)\n",
    "sign = output['outputs'].argmax()\n",
    "\n",
    "print(\"PRED : \", ORD2SIGN.get(sign), f'[{sign}]')\n",
    "print(\"TRUE : \", train_metadata.sign.values[0], f'[{train_metadata.sign_ord.values[0]}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346b1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3038.388613,
   "end_time": "2023-03-27T14:39:37.370611",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-27T13:48:58.981998",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03d6f570ff764870bb73ccfb8c6887af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_49350bdfb80d4f00a698d195ad6cc3e3",
       "placeholder": "",
       "style": "IPY_MODEL_6114b828351443dead1df1f805e5cfd7",
       "value": "100%"
      }
     },
     "07287dd36a6b457bab873107ef3a9a74": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a3cb9fa235b4d3b9fe4729d0488ab41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0b6a231f62a24aae9fa0cbc3fb92820f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0bdd95bee39a4c0fba0d526a76e11ed7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5809fb0e32f44de489c4ffd133aed91d",
       "placeholder": "",
       "style": "IPY_MODEL_ac638cb770cd4789a3ad5944574c0685",
       "value": " 1000/1000 [00:23&lt;00:00, 37.18it/s]"
      }
     },
     "0f47d306ae4c4968ae9578b5d3f96717": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1c0862516d904ef7a8308a72e5ae9f91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28320ac6793c47f69b05122f608c2d44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d0ef2e7de83043f5a1e56b8cbfdceb42",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0b6a231f62a24aae9fa0cbc3fb92820f",
       "value": 1000
      }
     },
     "37eb2c935499475c89e659645e41c052": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3a30e5dd2b7e4e58b5f796dc56795f9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "43441f82927941c183c36d4ba42c6839": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49104b8e9766498997f1c107709166cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49350bdfb80d4f00a698d195ad6cc3e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4fb37e6c0a6849b0ae4fca96c98079d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "50b095287b764b40bc01eecfb8e226ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "549182ad731149e196c24e0c65368459": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "54d833de2b3e4368a09e8f2832ae582a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_43441f82927941c183c36d4ba42c6839",
       "placeholder": "",
       "style": "IPY_MODEL_549182ad731149e196c24e0c65368459",
       "value": " 42/42 [00:06&lt;00:00,  6.63it/s]"
      }
     },
     "5809fb0e32f44de489c4ffd133aed91d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b6ddc597476439b98e2a8572db415ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5f60bd20e6054b8d9990b2b2804e19a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6114b828351443dead1df1f805e5cfd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7a008f4929ca442296cb2159b02d1206": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "873e173a1a48496183ab1a8b2425b3f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89aab12028bb44f0a421c39e5407e2c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a757d761f004d7faf0e86f35c7cc2ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d56ea444a554a8d86255febcfa438ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5f60bd20e6054b8d9990b2b2804e19a1",
       "placeholder": "",
       "style": "IPY_MODEL_37eb2c935499475c89e659645e41c052",
       "value": "100%"
      }
     },
     "8e1a02523adf4a51928bd01fe6a016a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a1b2e1be36c74ff5802bee0472d05a8c",
        "IPY_MODEL_974821174ce548f7ab78f2eb280a36bc",
        "IPY_MODEL_54d833de2b3e4368a09e8f2832ae582a"
       ],
       "layout": "IPY_MODEL_49104b8e9766498997f1c107709166cd"
      }
     },
     "974821174ce548f7ab78f2eb280a36bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4fb37e6c0a6849b0ae4fca96c98079d3",
       "max": 42,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0a3cb9fa235b4d3b9fe4729d0488ab41",
       "value": 42
      }
     },
     "97ebc5f11183491097eaa468c8f8d6ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9fdf9f1a806d45d8afc6aa7674799d7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8d56ea444a554a8d86255febcfa438ef",
        "IPY_MODEL_bc93196873734683876ec5f8b4b4c62c",
        "IPY_MODEL_d34a43c029834695b633aa4d4d941930"
       ],
       "layout": "IPY_MODEL_873e173a1a48496183ab1a8b2425b3f1"
      }
     },
     "a1b2e1be36c74ff5802bee0472d05a8c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_07287dd36a6b457bab873107ef3a9a74",
       "placeholder": "",
       "style": "IPY_MODEL_fc0e155d7357432c9976cb2ac7c68b3a",
       "value": "100%"
      }
     },
     "ac638cb770cd4789a3ad5944574c0685": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b0ba62ab3b254a6897d45bb7a753f044": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b5005dde82d843e7a0b50cdf2669d881": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d7996506467449ad9ba51cfb1e6db002",
        "IPY_MODEL_d0ff43d2109d482884de8add17da97e7",
        "IPY_MODEL_f9647d54b313481eaa72a3093a5dbc0a"
       ],
       "layout": "IPY_MODEL_1c0862516d904ef7a8308a72e5ae9f91"
      }
     },
     "bc93196873734683876ec5f8b4b4c62c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fa12da626fe2424eb7a18e996ed1fb96",
       "max": 10,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5b6ddc597476439b98e2a8572db415ee",
       "value": 10
      }
     },
     "d0ef2e7de83043f5a1e56b8cbfdceb42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0ff43d2109d482884de8add17da97e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3a30e5dd2b7e4e58b5f796dc56795f9d",
       "max": 40,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_97ebc5f11183491097eaa468c8f8d6ba",
       "value": 40
      }
     },
     "d34a43c029834695b633aa4d4d941930": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_50b095287b764b40bc01eecfb8e226ce",
       "placeholder": "",
       "style": "IPY_MODEL_7a008f4929ca442296cb2159b02d1206",
       "value": " 10/10 [00:02&lt;00:00,  5.02it/s]"
      }
     },
     "d7996506467449ad9ba51cfb1e6db002": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e8ec2cab76c64079add86c4cd9e47463",
       "placeholder": "",
       "style": "IPY_MODEL_0f47d306ae4c4968ae9578b5d3f96717",
       "value": "100%"
      }
     },
     "e8ec2cab76c64079add86c4cd9e47463": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "edea63966eb74395b1ccf14ba9265099": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_03d6f570ff764870bb73ccfb8c6887af",
        "IPY_MODEL_28320ac6793c47f69b05122f608c2d44",
        "IPY_MODEL_0bdd95bee39a4c0fba0d526a76e11ed7"
       ],
       "layout": "IPY_MODEL_89aab12028bb44f0a421c39e5407e2c2"
      }
     },
     "f9647d54b313481eaa72a3093a5dbc0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8a757d761f004d7faf0e86f35c7cc2ef",
       "placeholder": "",
       "style": "IPY_MODEL_b0ba62ab3b254a6897d45bb7a753f044",
       "value": " 40/40 [00:07&lt;00:00,  4.48it/s]"
      }
     },
     "fa12da626fe2424eb7a18e996ed1fb96": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc0e155d7357432c9976cb2ac7c68b3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
