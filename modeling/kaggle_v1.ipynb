{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf87375-3103-443d-9e2c-dacd6b4b35a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow_addons\n",
    "!pip install -q pyarrow\n",
    "!pip install -q fastparquet\n",
    "!pip install -q wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a3ae15-2917-4b25-8720-7a06c9b2529b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 17:54:54.313714: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-16 17:54:54.946556: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/tensorflow/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sn\n",
    "import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import sys\n",
    "import sklearn\n",
    "import scipy\n",
    "import io\n",
    "import wandb\n",
    "import json\n",
    "\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775d7831-7725-4929-8ec3-635d3fe06ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6783996",
   "metadata": {
    "papermill": {
     "duration": 0.014594,
     "end_time": "2023-03-27T13:49:16.606639",
     "exception": false,
     "start_time": "2023-03-27T13:49:16.592045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdb3a65-55b9-40d5-b6c5-28144c027589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"DATA_VERSION\": 6,\n",
    "    \"MODEL_VERSION\": 3,\n",
    "    \"N_COLS0\": 543,\n",
    "    \"N_COLS\": 227,\n",
    "    \"N_ROWS\":543,\n",
    "    \"N_DIMS\": 2, \n",
    "    \"N_EPOCHS\": 150,\n",
    "    \"TRAIN_BATCH_SIZE\": 512,\n",
    "    \"INPUT_SIZE\":38,\n",
    "    \"BATCH_ALL_SIGNS_N\": 4,\n",
    "    \"NUM_CLASSES\": 250,\n",
    "    \"BATCH_SIZE_VAL\":512,\n",
    "    \"WD_RATIO\":0.05,\n",
    "    \"LEARNING_RATE\": 0.0001,\n",
    "    \"WEIGHT_DECAY\": 0.0001,\n",
    "    \"N_WARMUP_EPOCHS\": 0,\n",
    "    \"MASK_VAL\": 4237\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef0f9e50-16f8-4391-b3b5-acbac321d24b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_SAMPLES: 94477\n"
     ]
    }
   ],
   "source": [
    "train_metadata = pd.read_csv(train_file.get(\"Body\"))\n",
    "\n",
    "N_SAMPLES = len(train_metadata)\n",
    "print(f'N_SAMPLES: {N_SAMPLES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66223025-c989-49dd-b662-a487c27d9bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get complete file path to file\n",
    "def get_file_path(path):\n",
    "    return f'/kaggle/input/asl-signs/{path}'\n",
    "\n",
    "train_metadata['file_path'] = train_metadata['path'].apply(get_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e70a14b-8be1-496c-a1ad-88aeb640d814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add ordinally Encoded Sign (assign number to each sign name)\n",
    "train_metadata['sign_ord'] = train_metadata['sign'].astype('category').cat.codes\n",
    "\n",
    "# Dictionaries to translate sign <-> ordinal encoded sign\n",
    "SIGN2ORD = train_metadata[['sign', 'sign_ord']].set_index('sign').squeeze().to_dict()\n",
    "ORD2SIGN = train_metadata[['sign_ord', 'sign']].set_index('sign_ord').squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b319f3f4-dac7-43aa-8972-ba5bbbf7b475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/competitions/asl-signs/overview/evaluation\n",
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "#w251-asl-data/raw-data/train_landmark_files/28656/3311214787.parquet\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c319d84-7646-4a42-b4ce-8e2e1c9d3f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 17:54:57.086409: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:54:57.106514: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:54:57.108373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:54:57.111270: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:54:57.113208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:54:57.114983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:54:57.626084: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:54:57.627091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:54:57.627867: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:54:57.628610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20561 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "preprocess_layer = PreprocessLayerV2(config[\"INPUT_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aae5f2ac-9674-4aac-9fb3-bc623a4ce9df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    face: 0:468\n",
    "    left_hand: 468:489\n",
    "    pose: 489:522\n",
    "    right_hand: 522:544\n",
    "        \n",
    "\"\"\"\n",
    "def get_data(file_path):\n",
    "    # Load Raw Data\n",
    "    data = load_relevant_data_subset(file_path)\n",
    "    # Process Data Using Tensorflow\n",
    "    data = preprocess_layer(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ee2a897-3852-4f3b-9823-88be2b3977ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "version = config[\"DATA_VERSION\"]\n",
    "\n",
    "# Get the full dataset\n",
    "def preprocess_dataset():\n",
    "    # Create arrays to save data\n",
    "    X = np.zeros([N_SAMPLES, config[\"INPUT_SIZE\"], config[\"N_COLS\"] * config[\"N_DIMS\"]], dtype=np.float32)\n",
    "    y = np.zeros([N_SAMPLES], dtype=np.int32)\n",
    "    NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, config[\"INPUT_SIZE\"]], -1, dtype=np.float32)\n",
    "\n",
    "    for row_idx, (file_path, sign_ord) in enumerate(tqdm(train_metadata[['path', 'sign_ord']].values)):\n",
    "        if row_idx % 5000 == 0:\n",
    "            print(f'Generated {row_idx}/{N_SAMPLES}')\n",
    "\n",
    "        data, non_empty_frame_idxs = get_data(file_path)\n",
    "        X[row_idx] = data\n",
    "        y[row_idx] = sign_ord\n",
    "        NON_EMPTY_FRAME_IDXS[row_idx] = non_empty_frame_idxs\n",
    "        if np.isnan(data).sum() > 0:\n",
    "            print(row_idx)\n",
    "            return data\n",
    "    \n",
    "    # Save X/y\n",
    "    np.save('X.npy', X)\n",
    "    np.save('y.npy', y)\n",
    "    np.save('NON_EMPTY_FRAME_IDXS.npy', NON_EMPTY_FRAME_IDXS)\n",
    "        \n",
    "    return X, y, NON_EMPTY_FRAME_IDXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceb4a87a-890c-4985-9840-d45ca9e91569",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351fddac34ca4db4970e468d2091993b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94477 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0/94477\n",
      "Generated 5000/94477\n",
      "Generated 10000/94477\n",
      "Generated 15000/94477\n",
      "Generated 20000/94477\n",
      "Generated 25000/94477\n",
      "Generated 30000/94477\n",
      "Generated 35000/94477\n",
      "Generated 40000/94477\n",
      "Generated 45000/94477\n",
      "Generated 50000/94477\n",
      "Generated 55000/94477\n",
      "Generated 60000/94477\n",
      "Generated 65000/94477\n",
      "Generated 70000/94477\n",
      "Generated 75000/94477\n",
      "Generated 80000/94477\n",
      "Generated 85000/94477\n",
      "Generated 90000/94477\n",
      "X shape: (94477, 38, 454), dtype: float32\n",
      "y shape: (94477,), dtype: int32\n",
      "NON_EMPTY_FRAME_IDXS shape: (94477, 38), dtype: float32\n",
      "# NaN Values X: 0\n"
     ]
    }
   ],
   "source": [
    "X, y, NON_EMPTY_FRAME_IDXS = preprocess_dataset()\n",
    "\n",
    "print_shape_dtype([X, y, NON_EMPTY_FRAME_IDXS], ['X', 'y', 'NON_EMPTY_FRAME_IDXS'])\n",
    "print(f'# NaN Values X: {np.isnan(X).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dae86eb-ccd4-4ec3-8e94-6594a055918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partitions_tf(ds, ds_size, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000, seed=42):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "    \n",
    "    if shuffle:\n",
    "        # Specify seed to always have the same split distribution between runs\n",
    "        ds = ds.shuffle(shuffle_size, seed=seed)\n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf792f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdeanna-emery\u001b[0m (\u001b[33mw251-asl-fp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Weights and Biases\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "100e9f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f2820ddbff44e1ae6d72c76a5ed354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669213583372765, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ec2-user/isolated-sign-language-recognition/modeling/wandb/run-20230416_220933-9hoj8usk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/w251-asl-fp/w251-demery1/runs/9hoj8usk' target=\"_blank\">divine-hill-2</a></strong> to <a href='https://wandb.ai/w251-asl-fp/w251-demery1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/w251-asl-fp/w251-demery1' target=\"_blank\">https://wandb.ai/w251-asl-fp/w251-demery1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/w251-asl-fp/w251-demery1/runs/9hoj8usk' target=\"_blank\">https://wandb.ai/w251-asl-fp/w251-demery1/runs/9hoj8usk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/w251-asl-fp/w251-demery1/runs/9hoj8usk?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fc2d1b0aa40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOG_DIR = './logs/fit'\n",
    "wandb.tensorboard.patch(root_logdir= LOG_DIR)\n",
    "wandb.init(project='w251-GISLR-Final', \n",
    "           config=config,\n",
    "          sync_tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c09a2354",
   "metadata": {
    "papermill": {
     "duration": 0.024174,
     "end_time": "2023-03-27T13:49:16.646131",
     "exception": false,
     "start_time": "2023-03-27T13:49:16.621957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_VAL = True\n",
    "\n",
    "DIM_NAMES = ['x', 'y']\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f6a97b",
   "metadata": {
    "papermill": {
     "duration": 0.023506,
     "end_time": "2023-03-27T13:50:42.146814",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.123308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2186561-d31f-45f2-b48d-5a6e669bb71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import numpy as np\n",
    "\n",
    "class PreprocessLayerV2(tf.keras.layers.Layer):\n",
    "    def __init__(self, INPUT_SIZE):\n",
    "        super(PreprocessLayerV2, self).__init__()\n",
    "        self.INPUT_SIZE = INPUT_SIZE\n",
    "        # Indicies in original data. \n",
    "        self.FACE_IDXS = tf.constant([0, 6, 7, 11, 12, 13, 14, 15, 17, 22, 23, 24, 25, 26, 30, 31, \n",
    "                     33, 37, 38, 39, 40, 41, 42, 56, 61, 62, 72, 73, 74, 76, 77, \n",
    "                     78, 80, 81, 82, 84, 86, 87, 88, 89, 90, 91, 95, 96, 110, 112, \n",
    "                     113, 122, 128, 130, 133, 144, 145, 146, 153, 154, 155, 157, 158, \n",
    "                     159, 160, 161, 163, 168, 173, 178, 179, 180, 181, 183, 184, 185, \n",
    "                     188, 189, 190, 191, 193, 196, 197, 232, 233, 243, 244, 245, 246, \n",
    "                     247, 249, 252, 253, 254, 255, 256, 259, 260, 263, 267, 268, 269, \n",
    "                     270, 271, 272, 286, 291, 292, 302, 303, 304, 306, 307, 308, 310, \n",
    "                     311, 312, 314, 316, 317, 318, 319, 320, 321, 324, 325, 339, 341, \n",
    "                     351, 357, 359, 362, 373, 374, 375, 380, 381, 382, 384, 385, 386, \n",
    "                     387, 388, 390, 398, 402, 403, 404, 405, 407, 408, 409, 412, 413, \n",
    "                     414, 415, 417, 419, 453, 463, 464, 465, 466, 467], dtype=tf.int32)\n",
    "        self.POSE_IDXS = tf.constant(tf.range(489, 514, delta=1, dtype=tf.int32))\n",
    "        self.LEFT_HAND_IDXS = tf.constant(tf.range(468, 489, delta=1, dtype=tf.int32))\n",
    "        self.RIGHT_HAND_IDXS = tf.constant(tf.range(522, 543, delta=1, dtype=tf.int32))\n",
    "        \n",
    "        self.HAND_IDXS = tf.constant(tf.concat([self.LEFT_HAND_IDXS, self.RIGHT_HAND_IDXS], 0), dtype=tf.int32)\n",
    "            \n",
    "        # All landmarks that are used for modeling. \n",
    "        self.LANDMARK_IDXS = tf.constant(tf.concat([self.FACE_IDXS, self.POSE_IDXS, self.LEFT_HAND_IDXS, self.RIGHT_HAND_IDXS], 0), dtype=tf.int32)\n",
    "        \n",
    "        # Indicies after landmarks have been filtered. \n",
    "        self.FACE_START = tf.constant(0, dtype=tf.int32)\n",
    "        self.LEFT_HAND_START = tf.constant(len(self.FACE_IDXS), dtype=tf.int32)\n",
    "        self.POSE_START = tf.constant(self.LEFT_HAND_START + len(self.LEFT_HAND_IDXS), dtype=tf.int32)\n",
    "        self.RIGHT_HAND_START = tf.constant(self.POSE_START + len(self.POSE_IDXS), dtype=tf.int32)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'INPUT_SIZE': self.INPUT_SIZE,\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    \n",
    "    @tf.function(input_signature=(tf.TensorSpec(shape=[None, 543, 2], dtype=tf.float32),),)\n",
    "    def call(self, data):\n",
    "        \n",
    "        # Filter Out Frames With Empty Hand Data\n",
    "        frames_hands_nansum = tf.experimental.numpy.nanmean(tf.gather(data, self.HAND_IDXS, axis=1), axis=[1,2])\n",
    "        non_empty_frames_idxs = tf.where(frames_hands_nansum > 0)\n",
    "        non_empty_frames_idxs = tf.squeeze(non_empty_frames_idxs, axis=1)\n",
    "        data = tf.gather(data, non_empty_frames_idxs, axis=0)\n",
    "        \n",
    "        # Cast Indices in float32 to be compatible with Tensorflow Lite\n",
    "        non_empty_frames_idxs = tf.cast(non_empty_frames_idxs, tf.float32) \n",
    "        \n",
    "        N_FRAMES = tf.shape(data)[0]\n",
    "        data = tf.gather(data, self.LANDMARK_IDXS, axis=1)\n",
    "        \n",
    "        # Slice out face indicies, normalize across batch.        \n",
    "        face = tf.slice(data, [0, self.FACE_START, 0], [N_FRAMES, self.LEFT_HAND_START, 2])\n",
    "        # face_mean, face_std = self.get_mean_std(self.FACE_IDXS, face)\n",
    "        xs = tf.reshape(tf.transpose(face, [2,0,1]), [2,tf.size(self.FACE_IDXS)*tf.shape(face)[0]])[0]\n",
    "        ys = tf.reshape(tf.transpose(face, [2,0,1]), [2,tf.size(self.FACE_IDXS)*tf.shape(face)[0]])[1]\n",
    "            \n",
    "        FACE_MEAN_X = tf.math.reduce_mean(xs)\n",
    "        FACE_STD_X = tf.math.reduce_std(xs)\n",
    "        FACE_MEAN_Y = tf.math.reduce_mean(ys)\n",
    "        FACE_STD_Y = tf.math.reduce_std(ys)\n",
    "\n",
    "        face_mean = tf.stack([FACE_MEAN_X, FACE_MEAN_Y])\n",
    "        face_std = tf.stack([FACE_STD_X, FACE_STD_Y])\n",
    "        face = tf.where(\n",
    "                    tf.math.equal(face, 0.0),\n",
    "                    0.0,\n",
    "                    (face - face_mean) / face_std,\n",
    "                )\n",
    "        \n",
    "#         # Slice out left_hand indicies, normalize across batch.\n",
    "        left_hand = tf.slice(data, [0, self.LEFT_HAND_START, 0], [N_FRAMES, self.POSE_START-self.LEFT_HAND_START, 2])\n",
    "        xs = tf.reshape(tf.transpose(left_hand, [2,0,1]), [2,tf.size(self.LEFT_HAND_IDXS)*tf.shape(left_hand)[0]])[0]\n",
    "        ys = tf.reshape(tf.transpose(left_hand, [2,0,1]), [2,tf.size(self.LEFT_HAND_IDXS)*tf.shape(left_hand)[0]])[1]\n",
    "            \n",
    "        LEFT_HAND_MEAN_X = tf.math.reduce_mean(xs)\n",
    "        LEFT_HAND_STD_X = tf.math.reduce_std(xs)\n",
    "        LEFT_HAND_MEAN_Y = tf.math.reduce_mean(ys)\n",
    "        LEFT_HAND_STD_Y = tf.math.reduce_std(ys)\n",
    "\n",
    "        left_hand_mean = tf.stack([LEFT_HAND_MEAN_X, LEFT_HAND_MEAN_Y])\n",
    "        left_hand_std = tf.stack([LEFT_HAND_STD_X, LEFT_HAND_STD_Y])\n",
    "        left_hand = tf.where(\n",
    "                    tf.math.equal(left_hand, 0.0),\n",
    "                    0.0,\n",
    "                    (left_hand - left_hand_mean) / left_hand_std,\n",
    "                )\n",
    "        \n",
    "#         # Slice out pose indicies, normalize across batch.\n",
    "        pose = tf.slice(data, [0, self.POSE_START, 0], [N_FRAMES, self.RIGHT_HAND_START-self.POSE_START, 2])\n",
    "        xs = tf.reshape(tf.transpose(pose, [2,0,1]), [2,tf.size(self.POSE_IDXS)*tf.shape(pose)[0]])[0]\n",
    "        ys = tf.reshape(tf.transpose(pose, [2,0,1]), [2,tf.size(self.POSE_IDXS)*tf.shape(pose)[0]])[1]\n",
    "            \n",
    "        POSE_MEAN_X = tf.math.reduce_mean(xs)\n",
    "        POSE_STD_X = tf.math.reduce_std(xs)\n",
    "        POSE_MEAN_Y = tf.math.reduce_mean(ys)\n",
    "        POSE_STD_Y = tf.math.reduce_std(ys)\n",
    "\n",
    "        pose_mean = tf.stack([POSE_MEAN_X, POSE_MEAN_Y])\n",
    "        pose_std = tf.stack([POSE_STD_X, POSE_STD_Y])\n",
    "        pose = tf.where(\n",
    "                    tf.math.equal(pose, 0.0),\n",
    "                    0.0,\n",
    "                    (pose - pose_mean) / pose_std,\n",
    "                )\n",
    "        \n",
    "         # Slice out right_hand indicies, normalize across batch.\n",
    "        right_hand = tf.slice(data, [0, self.RIGHT_HAND_START, 0], [N_FRAMES, tf.shape(data)[1] - self.RIGHT_HAND_START, 2])\n",
    "        xs = tf.reshape(tf.transpose(right_hand, [2,0,1]), [2,tf.size(self.LEFT_HAND_IDXS)*tf.shape(right_hand)[0]])[0]\n",
    "        ys = tf.reshape(tf.transpose(right_hand, [2,0,1]), [2,tf.size(self.LEFT_HAND_IDXS)*tf.shape(right_hand)[0]])[1]\n",
    "            \n",
    "        RIGHT_HAND_MEAN_X = tf.math.reduce_mean(xs)\n",
    "        RIGHT_HAND_STD_X = tf.math.reduce_std(xs)\n",
    "        RIGHT_HAND_MEAN_Y = tf.math.reduce_mean(ys)\n",
    "        RIGHT_HAND_STD_Y = tf.math.reduce_std(ys)\n",
    "\n",
    "        right_hand_mean = tf.stack([RIGHT_HAND_MEAN_X, RIGHT_HAND_MEAN_Y])\n",
    "        right_hand_std = tf.stack([RIGHT_HAND_STD_X, RIGHT_HAND_STD_Y])\n",
    "        right_hand = tf.where(\n",
    "                    tf.math.equal(right_hand, 0.0),\n",
    "                    0.0,\n",
    "                    (right_hand - right_hand_mean) / right_hand_std,\n",
    "                )\n",
    "        \n",
    "        \n",
    "        # Concat landmarks back into same frame.\n",
    "        data = tf.concat([face, left_hand, pose, right_hand], 1)\n",
    "        \n",
    "        \n",
    "        # Video fits in self.INPUT_SIZE\n",
    "        if N_FRAMES < self.INPUT_SIZE: # Number of frames we want\n",
    "            # Attention mask for frames that contain data. \n",
    "            \n",
    "            non_empty_frames_idxs = tf.pad(non_empty_frames_idxs, [[0, self.INPUT_SIZE-N_FRAMES]], constant_values=-1)\n",
    "            data = tf.pad(data, [[0, self.INPUT_SIZE-N_FRAMES], [0,0], [0,0]], constant_values=0)\n",
    "            # Fill NaN Values With 0\n",
    "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "            # Reshape into (Number of desired frames, (Number of landmarks * 2))\n",
    "            data = tf.reshape(data, [self.INPUT_SIZE, tf.shape(data)[1] * 2])\n",
    "            return data, non_empty_frames_idxs\n",
    "        # Video needs to be downsampled to INPUT_SIZE\n",
    "        else:\n",
    "            # Downsample video using nearest interpolation method. \n",
    "            data = tf.image.resize(data, size=(self.INPUT_SIZE, data.shape[1]), method='nearest')\n",
    "            # Fill NaN Values With 0\n",
    "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "            # Reshape into (Number of desired frames, (Number of landmarks * 2)).\n",
    "            data = tf.reshape(data, [self.INPUT_SIZE, tf.shape(data)[1] * 2])\n",
    "            # Create attention mask with all frames. \n",
    "            non_empty_frames_idxs = tf.range(0, self.INPUT_SIZE, 1, dtype=tf.float32)\n",
    "            return data, non_empty_frames_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db809f",
   "metadata": {
    "papermill": {
     "duration": 0.027558,
     "end_time": "2023-03-27T13:50:42.374837",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.347279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad349c1a",
   "metadata": {
    "papermill": {
     "duration": 0.039339,
     "end_time": "2023-03-27T13:50:42.441202",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.401863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRANSFORMERV1 = True\n",
    "\n",
    "# Epsilon value for layer normalisation\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "\n",
    "# Dense layer units for landmarks\n",
    "FACE_UNITS = 384\n",
    "HANDS_UNITS = 384\n",
    "POSE_UNITS = 384\n",
    "# final embedding and transformer embedding size\n",
    "UNITS = 512\n",
    "\n",
    "# Transformer\n",
    "NUM_BLOCKS = 2\n",
    "MLP_RATIO = 2\n",
    "NUM_HEADS = 4\n",
    "\n",
    "# Dropout\n",
    "EMBEDDING_DROPOUT = 0.0\n",
    "MLP_DROPOUT_RATIO = 0.05\n",
    "CLASSIFIER_DROPOUT_RATIO = 0.1\n",
    "\n",
    "# Initiailizers\n",
    "# INIT_HE_UNIFORM = tf.keras.initializers.he_uniform\n",
    "INIT_GLOROT_UNIFORM = tf.keras.initializers.glorot_uniform\n",
    "# INIT_ZEROS = tf.keras.initializers.constant(0.0)\n",
    "# Activations\n",
    "ACTIVATION = tf.keras.activations.gelu\n",
    "\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a522f03-d5fb-4a49-a45d-936f38ab8021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FACE_IDXS = [0, 6, 7, 11, 12, 13, 14, 15, 17, 22, 23, 24, 25, 26, 30, 31, \n",
    "                     33, 37, 38, 39, 40, 41, 42, 56, 61, 62, 72, 73, 74, 76, 77, \n",
    "                     78, 80, 81, 82, 84, 86, 87, 88, 89, 90, 91, 95, 96, 110, 112, \n",
    "                     113, 122, 128, 130, 133, 144, 145, 146, 153, 154, 155, 157, 158, \n",
    "                     159, 160, 161, 163, 168, 173, 178, 179, 180, 181, 183, 184, 185, \n",
    "                     188, 189, 190, 191, 193, 196, 197, 232, 233, 243, 244, 245, 246, \n",
    "                     247, 249, 252, 253, 254, 255, 256, 259, 260, 263, 267, 268, 269, \n",
    "                     270, 271, 272, 286, 291, 292, 302, 303, 304, 306, 307, 308, 310, \n",
    "                     311, 312, 314, 316, 317, 318, 319, 320, 321, 324, 325, 339, 341, \n",
    "                     351, 357, 359, 362, 373, 374, 375, 380, 381, 382, 384, 385, 386, \n",
    "                     387, 388, 390, 398, 402, 403, 404, 405, 407, 408, 409, 412, 413, \n",
    "                     414, 415, 417, 419, 453, 463, 464, 465, 466, 467]\n",
    "POSE_IDXS = np.arange(489, 514)\n",
    "LEFT_HAND_IDXS = np.arange(468, 489)\n",
    "RIGHT_HAND_IDXS = np.arange(522, 543)\n",
    "\n",
    "# All landmarks that are used for modeling. \n",
    "LANDMARK_IDXS = np.concatenate((FACE_IDXS, POSE_IDXS, LEFT_HAND_IDXS, RIGHT_HAND_IDXS))\n",
    "\n",
    "# Indicies after landmarks have been filtered. \n",
    "FACE_START = 0\n",
    "LEFT_HAND_START = len(FACE_IDXS)\n",
    "POSE_START = LEFT_HAND_START + len(LEFT_HAND_IDXS)\n",
    "RIGHT_HAND_START = POSE_START + len(POSE_IDXS)\n",
    "\n",
    "# Length of landmarks.\n",
    "FACE_LEN = len(FACE_IDXS)\n",
    "POSE_LEN = POSE_IDXS.size\n",
    "LEFT_HAND_LEN = LEFT_HAND_IDXS.size\n",
    "RIGHT_HAND_LEN = RIGHT_HAND_IDXS.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad908f5-3746-435a-8806-044b3ea5217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class LandmarkEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, name, activation):\n",
    "        super(LandmarkEmbedding, self).__init__(name=f'{name}_embedding')\n",
    "        self.UNITS = units\n",
    "        self.ACTIVATION = activation\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'UNITS': self.UNITS,\n",
    "            'ACTIVATION': self.ACTIVATION,\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Embedding for missing landmark in frame, initizlied with zeros\n",
    "        self.empty_embedding = self.add_weight(\n",
    "            name=f'{self.name}_empty_embedding',\n",
    "            shape=[self.UNITS],\n",
    "            initializer=tf.keras.initializers.constant(0.0),\n",
    "        )\n",
    "        # Embedding\n",
    "        self.dense = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.UNITS, name=f'{self.name}_dense_1', use_bias=False, \n",
    "                                  kernel_initializer=tf.keras.initializers.glorot_uniform, activation=self.ACTIVATION),\n",
    "            tf.keras.layers.Dense(self.UNITS, name=f'{self.name}_dense_2', use_bias=False, kernel_initializer=tf.keras.initializers.he_uniform),\n",
    "        ], name=f'{self.name}_dense')\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.where(\n",
    "                # Checks whether landmark is missing in frame\n",
    "                tf.reduce_sum(x, axis=2, keepdims=True) == 0,\n",
    "                # If so, the empty embedding is used\n",
    "                self.empty_embedding,\n",
    "                # Otherwise the landmark data is embedded\n",
    "                self.dense(x),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea2056-d7a9-4e43-876b-5dc17fb4037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from layers.LandmarkEmbedding import LandmarkEmbedding\n",
    "\n",
    "class Embedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_size, face_units, hands_units, pose_units, units, activation):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.INPUT_SIZE = input_size\n",
    "        self.FACE_UNITS = face_units\n",
    "        self.HANDS_UNITS = hands_units\n",
    "        self.POSE_UNITS = pose_units\n",
    "        self.UNITS = units\n",
    "        self.ACTIVATION = activation\n",
    "        \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'INPUT_SIZE': self.INPUT_SIZE,\n",
    "            'FACE_UNITS': self.FACE_UNITS,\n",
    "            'HANDS_UNITS': self.HANDS_UNITS,\n",
    "            'POSE_UNITS': self.POSE_UNITS,\n",
    "            'UNITS': self.UNITS,\n",
    "            'ACTIVATION': self.ACTIVATION,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Positional Embedding, initialized with zeros\n",
    "        self.positional_embedding = tf.keras.layers.Embedding(self.INPUT_SIZE+1, self.UNITS, embeddings_initializer=tf.keras.initializers.constant(0.0))\n",
    "        # Embedding layer for Landmarks\n",
    "        self.face_embedding = LandmarkEmbedding(self.FACE_UNITS, 'face', self.ACTIVATION)\n",
    "        self.left_hand_embedding = LandmarkEmbedding(self.HANDS_UNITS, 'left_hand', self.ACTIVATION)\n",
    "        self.right_hand_embedding = LandmarkEmbedding(self.HANDS_UNITS, 'right_hand', self.ACTIVATION)\n",
    "        self.pose_embedding = LandmarkEmbedding(self.POSE_UNITS, 'pose', self.ACTIVATION)\n",
    "        # Landmark Weights\n",
    "        self.landmark_weights = tf.Variable(tf.zeros([4], dtype=tf.float32), name='landmark_weights')\n",
    "        # Fully Connected Layers for combined landmarks\n",
    "        self.fc = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.UNITS, name='fully_connected_1', use_bias=False, \n",
    "                                  kernel_initializer=tf.keras.initializers.glorot_uniform, activation=self.ACTIVATION),\n",
    "            tf.keras.layers.Dense(self.UNITS, name='fully_connected_2', use_bias=False, kernel_initializer=tf.keras.initializers.he_uniform),\n",
    "        ], name='fc')\n",
    "\n",
    "\n",
    "    def call(self, face0, left_hand0, right_hand0, pose0, non_empty_frame_idxs,training=False):\n",
    "        # Face\n",
    "        face_embedding = self.face_embedding(face0)\n",
    "        # Left Hand\n",
    "        left_hand_embedding = self.left_hand_embedding(left_hand0)\n",
    "        # Right Hand\n",
    "        right_hand_embedding = self.right_hand_embedding(right_hand0)\n",
    "        # Pose\n",
    "        pose_embedding = self.pose_embedding(pose0)\n",
    "        # Merge Embeddings of all landmarks with mean pooling\n",
    "        x = tf.stack((face_embedding, left_hand_embedding, right_hand_embedding, pose_embedding), axis=3)\n",
    "        # Merge Landmarks with trainable attention weights\n",
    "        x = x * tf.nn.softmax(self.landmark_weights)\n",
    "        x = tf.reduce_sum(x, axis=3)\n",
    "        # Fully Connected Layers\n",
    "        x = self.fc(x)\n",
    "        # Add Positional Embedding\n",
    "        normalised_non_empty_frame_idxs = tf.where(\n",
    "            tf.math.equal(non_empty_frame_idxs, -1.0),\n",
    "            self.INPUT_SIZE,\n",
    "            tf.cast(\n",
    "                non_empty_frame_idxs / tf.reduce_max(non_empty_frame_idxs, axis=1, keepdims=True) * self.INPUT_SIZE,\n",
    "                tf.int32,\n",
    "            ),\n",
    "        )\n",
    "        x = x + self.positional_embedding(normalised_non_empty_frame_idxs)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5879453d-ee23-4d69-bbca-10bfbe2fe2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# based on: https://stackoverflow.com/questions/67342988/verifying-the-implementation-of-multihead-attention-in-transformer\n",
    "# replaced softmax with softmax layer to support masked softmax\n",
    "def scaled_dot_product(q,k,v, softmax, attention_mask):\n",
    "    #calculates Q . K(transpose)\n",
    "    qkt = tf.matmul(q,k,transpose_b=True)\n",
    "    #caculates scaling factor\n",
    "    dk = tf.math.sqrt(tf.cast(q.shape[-1],dtype=tf.float32))\n",
    "    scaled_qkt = qkt/dk\n",
    "    softmax = softmax(scaled_qkt, mask=attention_mask)\n",
    "    \n",
    "    z = tf.matmul(softmax,v)\n",
    "    #shape: (m,Tx,depth), same shape as q,k,v\n",
    "    return z\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model,num_of_heads):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_of_heads = num_of_heads\n",
    "        self.depth = d_model//num_of_heads\n",
    "        self.wq = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wk = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wv = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wo = tf.keras.layers.Dense(d_model)\n",
    "        self.softmax = tf.keras.layers.Softmax()\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'd_model': self.d_model,\n",
    "            'num_of_heads': self.num_of_heads\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def call(self,x, attention_mask):\n",
    "        multi_attn = []\n",
    "        for i in range(self.num_of_heads):\n",
    "            Q = self.wq[i](x)\n",
    "            K = self.wk[i](x)\n",
    "            V = self.wv[i](x)\n",
    "            multi_attn.append(scaled_dot_product(Q,K,V, self.softmax, attention_mask))\n",
    "            \n",
    "        multi_head = tf.concat(multi_attn,axis=-1)\n",
    "        multi_head_attention = self.wo(multi_head)\n",
    "        return multi_head_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef60882-2a99-4ffa-a2f6-1d01167089e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from layers.MultiHeadAttention import MultiHeadAttention\n",
    "\n",
    "\n",
    "# Full Transformer\n",
    "class Transformer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_blocks, layer_norm_eps, units, mlp_ratio, mlp_dropout_ratio, activation):\n",
    "        super(Transformer, self).__init__(name='transformer')\n",
    "        self.NUM_BLOCKS = num_blocks\n",
    "        self.LAYER_NORM_EPS = layer_norm_eps\n",
    "        self.UNITS = units\n",
    "        self.MLP_RATIO = mlp_ratio\n",
    "        self.MLP_DROPOUT_RATIO = mlp_dropout_ratio\n",
    "        self.ACTIVATION = activation\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'NUM_BLOCKS': self.NUM_BLOCKS,\n",
    "            'LAYER_NORM_EPS': self.LAYER_NORM_EPS,\n",
    "            'MLP_RATIO': self.MLP_RATIO,\n",
    "            'MLP_DROPOUT_RATIO': self.MLP_DROPOUT_RATIO,\n",
    "            'UNITS': self.UNITS,\n",
    "            'ACTIVATION': self.ACTIVATION,\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.ln_1s = []\n",
    "        self.mhas = []\n",
    "        self.ln_2s = []\n",
    "        self.mlps = []\n",
    "        # Make Transformer Blocks\n",
    "        for i in range(self.NUM_BLOCKS):\n",
    "            # First Layer Normalisation\n",
    "            self.ln_1s.append(tf.keras.layers.LayerNormalization(epsilon=self.LAYER_NORM_EPS))\n",
    "            # Multi Head Attention\n",
    "            self.mhas.append(MultiHeadAttention(self.UNITS, 4))\n",
    "            # Second Layer Normalisation\n",
    "            self.ln_2s.append(tf.keras.layers.LayerNormalization(epsilon=self.LAYER_NORM_EPS))\n",
    "            # Multi Layer Perception\n",
    "            self.mlps.append(tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(self.UNITS * self.MLP_RATIO, activation=self.ACTIVATION, \n",
    "                                      kernel_initializer=tf.keras.initializers.glorot_uniform),\n",
    "                tf.keras.layers.Dropout(self.MLP_DROPOUT_RATIO),\n",
    "                tf.keras.layers.Dense(self.UNITS, kernel_initializer=tf.keras.initializers.he_uniform),\n",
    "            ]))\n",
    "        \n",
    "    def call(self, x, attention_mask):\n",
    "        # Iterate input over transformer blocks\n",
    "        for ln_1, mha, ln_2, mlp in zip(self.ln_1s, self.mhas, self.ln_2s, self.mlps):\n",
    "            x1 = ln_1(x)\n",
    "            attention_output = mha(x1, attention_mask)\n",
    "            x2 = x1 + attention_output\n",
    "            x3 = ln_2(x2)\n",
    "            x3 = mlp(x3)\n",
    "            x = x3 + x2\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12ca5c18",
   "metadata": {
    "papermill": {
     "duration": 0.043124,
     "end_time": "2023-03-27T13:50:42.896486",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.853362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    # Inputs\n",
    "    frames = tf.keras.layers.Input([config[\"INPUT_SIZE\"], config[\"N_COLS\"] * config[\"N_DIMS\"]], dtype=tf.float32, name='FRAMES')\n",
    "    non_empty_frame_idxs = tf.keras.layers.Input([config[\"INPUT_SIZE\"]], dtype=tf.float32, name='NON_EMPTY_FRAME_IDXS')\n",
    "    \n",
    "    # Attention Mask\n",
    "    mask = tf.cast(tf.math.not_equal(non_empty_frame_idxs, -1), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=2)\n",
    "    \n",
    "    # Slice out face indicies       \n",
    "    face = tf.slice(frames, [0, 0, FACE_START], [-1, config[\"INPUT_SIZE\"], FACE_LEN * 2])\n",
    "    # face = tf.reshape(frames, [-1, config[\"INPUT_SIZE\"], FACE_LEN*2])\n",
    "    \n",
    "     # Slice out left_hand indicies\n",
    "    left_hand = tf.slice(frames, [0, 0, LEFT_HAND_START * 2], [-1, config[\"INPUT_SIZE\"], LEFT_HAND_LEN * 2])\n",
    "    # left_hand = tf.reshape(frames, [-1, config[\"INPUT_SIZE\"], len(LEFT_HAND_IDXS)*2])\n",
    "\n",
    "    # Slice out pose indicies\n",
    "    pose = tf.slice(frames, [0, 0, POSE_START * 2], [-1, config[\"INPUT_SIZE\"], POSE_LEN * 2])\n",
    "    # pose = tf.reshape(frames, [-1, config[\"INPUT_SIZE\"], len(POSE_IDXS)*2])\n",
    "\n",
    "    # Slice out right_hand indicies\n",
    "    right_hand = tf.slice(frames, [0, 0, RIGHT_HAND_START * 2], [-1, config[\"INPUT_SIZE\"], RIGHT_HAND_LEN * 2])\n",
    "    # right_hand = tf.reshape(frames, [-1, config[\"INPUT_SIZE\"], len(RIGHT_HAND_IDXS)*2])\n",
    "    \n",
    "    embedding_layer = layers.Embedding(config[\"INPUT_SIZE\"], FACE_UNITS, HANDS_UNITS, POSE_UNITS, UNITS, ACTIVATION)\n",
    "    x = embedding_layer(face, left_hand, right_hand, pose, non_empty_frame_idxs)\n",
    "    transformer_input_shape = x.shape\n",
    "    \n",
    "    if (TRANSFORMERV1):\n",
    "        # Encoder Transformer Blocks\n",
    "        transformer_layer = layers.Transformer(NUM_BLOCKS, LAYER_NORM_EPS, UNITS, MLP_RATIO, MLP_DROPOUT_RATIO, ACTIVATION)\n",
    "        x = transformer_layer(x, mask)\n",
    "    else:\n",
    "        encoder_input_shape = transformer_input_shape\n",
    "        for _ in range(NUM_BLOCKS):\n",
    "            x = layers.TransformerV2(encoder_input_shape, NUM_HEADS, UNITS, MLP_DROPOUT_RATIO, LAYER_NORM_EPS)(x)\n",
    "            encoder_input_shape = x.shape[1:]  # Update the input shape for the next encoder\n",
    "    \n",
    "    # Pooling\n",
    "    x = tf.reduce_sum(x * mask, axis=1) / tf.reduce_sum(mask, axis=1)\n",
    "    # Classifier Dropout\n",
    "    x = tf.keras.layers.Dropout(CLASSIFIER_DROPOUT_RATIO)(x)\n",
    "    # Classification Layer\n",
    "    x = tf.keras.layers.Dense(config[\"NUM_CLASSES\"], activation=tf.keras.activations.softmax, kernel_initializer=INIT_GLOROT_UNIFORM)(x)\n",
    "    \n",
    "    outputs = x\n",
    "    \n",
    "    # Create Tensorflow Model\n",
    "    model = tf.keras.models.Model(inputs=[frames, non_empty_frame_idxs], outputs=outputs)\n",
    "    \n",
    "    # Simple Categorical Crossentropy Loss\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    \n",
    "    # Adam Optimizer with weight decay\n",
    "    optimizer = tfa.optimizers.AdamW(learning_rate=config[\"LEARNING_RATE\"], weight_decay=config[\"WEIGHT_DECAY\"])\n",
    "    \n",
    "    # TopK Metrics\n",
    "    metrics = [\n",
    "        tf.keras.metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top_5_acc'),\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=10, name='top_10_acc'),\n",
    "    ]\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics, run_eagerly=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5fab16c-ad10-4575-bf6e-ccf907827ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 01:47:57.758564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:47:57.779789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:47:57.781779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:47:57.785677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:47:57.787596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:47:57.789335: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:47:58.295074: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:47:58.296061: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:47:58.296814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:47:58.297515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20561 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n",
      "2023-04-18 01:47:58.299650: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6519668816 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "with tf.device('CPU'):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(({\"FRAMES\": X, \"NON_EMPTY_FRAME_IDXS\": NON_EMPTY_FRAME_IDXS}, y))\n",
    "    \n",
    "# with tf.device('CPU'):\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices(({\"FRAMES\": X[:100], \"NON_EMPTY_FRAME_IDXS\": NON_EMPTY_FRAME_IDXS[:100]}, y[:100]))\n",
    "\n",
    "train, validation, test = get_dataset_partitions_tf(dataset, X.shape[0], train_split=0.8, val_split=0.1, \n",
    "                                                test_split=0.1, shuffle=True, shuffle_size=10000, seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a9779f",
   "metadata": {
    "papermill": {
     "duration": 0.038802,
     "end_time": "2023-03-27T13:51:03.381634",
     "exception": false,
     "start_time": "2023-03-27T13:51:03.342832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "490cdcb6",
   "metadata": {
    "papermill": {
     "duration": 0.049275,
     "end_time": "2023-03-27T13:51:03.469275",
     "exception": false,
     "start_time": "2023-03-27T13:51:03.420000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=config[\"N_EPOCHS\"], warm_method='log'):\n",
    "    \n",
    "    if current_step < num_warmup_steps:\n",
    "        if warm_method == 'log':\n",
    "            return lr_max * 0.10 ** (num_warmup_steps - current_step)\n",
    "        else:\n",
    "            return lr_max * 2 ** -(num_warmup_steps - current_step)\n",
    "    else:\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "\n",
    "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6401784",
   "metadata": {
    "papermill": {
     "duration": 0.738209,
     "end_time": "2023-03-27T13:51:04.245805",
     "exception": false,
     "start_time": "2023-03-27T13:51:03.507596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Learning rate for encoder\n",
    "LR_SCHEDULE = [lrfn(step, num_warmup_steps=config[\"N_WARMUP_EPOCHS\"], \n",
    "                    lr_max=config[\"LEARNING_RATE\"], num_cycles=0.50) for step in range(config[\"N_EPOCHS\"])]\n",
    "\n",
    "# Learning Rate Callback\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e550a63",
   "metadata": {
    "papermill": {
     "duration": 0.040725,
     "end_time": "2023-03-27T13:51:04.330003",
     "exception": false,
     "start_time": "2023-03-27T13:51:04.289278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weight Decay Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bded92c-bc32-4ffc-b79d-e3bd8029d177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom callback to update weight decay with learning rate\n",
    "class WeightDecayCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, wd_ratio=config['WD_RATIO']):\n",
    "        self.step_counter = 0\n",
    "        self.wd_ratio = wd_ratio\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n",
    "        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97185a5",
   "metadata": {
    "papermill": {
     "duration": 0.040685,
     "end_time": "2023-03-27T13:51:11.352812",
     "exception": false,
     "start_time": "2023-03-27T13:51:11.312127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd83cf56",
   "metadata": {
    "papermill": {
     "duration": 2852.852405,
     "end_time": "2023-03-27T14:38:44.682355",
     "exception": false,
     "start_time": "2023-03-27T13:51:11.829950",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " NON_EMPTY_FRAME_IDXS (InputLay  [(None, 38)]        0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " FRAMES (InputLayer)            [(None, 38, 454)]    0           []                               \n",
      "                                                                                                  \n",
      " tf.math.not_equal (TFOpLambda)  (None, 38)          0           ['NON_EMPTY_FRAME_IDXS[0][0]']   \n",
      "                                                                                                  \n",
      " tf.slice (TFOpLambda)          (None, 38, 320)      0           ['FRAMES[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.slice_1 (TFOpLambda)        (None, 38, 42)       0           ['FRAMES[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.slice_3 (TFOpLambda)        (None, 38, 42)       0           ['FRAMES[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.slice_2 (TFOpLambda)        (None, 38, 50)       0           ['FRAMES[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)           (None, 38)           0           ['tf.math.not_equal[0][0]']      \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 38, 512)      1244420     ['tf.slice[0][0]',               \n",
      "                                                                  'tf.slice_1[0][0]',             \n",
      "                                                                  'tf.slice_3[0][0]',             \n",
      "                                                                  'tf.slice_2[0][0]',             \n",
      "                                                                  'NON_EMPTY_FRAME_IDXS[0][0]']   \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 38, 1)        0           ['tf.cast[0][0]']                \n",
      "                                                                                                  \n",
      " transformer (Transformer)      (None, 38, 512)      4205568     ['embedding[0][0]',              \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 38, 512)      0           ['transformer[0][0]',            \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None, 512)         0           ['tf.math.multiply[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOpLamb  (None, 1)           0           ['tf.expand_dims[0][0]']         \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 512)          0           ['tf.math.reduce_sum[0][0]',     \n",
      "                                                                  'tf.math.reduce_sum_1[0][0]']   \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['tf.math.truediv[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 250)          128250      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,578,238\n",
      "Trainable params: 5,578,238\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 22:11:22.472479: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6519668816 exceeds 10% of free system memory.\n",
      "2023-04-16 22:11:23.416890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-04-16 22:11:25.991129: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [94477,38]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0001.\n",
      "learning rate: 1.00e-04, weight decay: 5.00e-06\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 22:11:27.083142: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - ETA: 0s - loss: 5.1806 - acc: 0.0394 - top_5_acc: 0.1252 - top_10_acc: 0.1931"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 22:11:55.685621: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6519668816 exceeds 10% of free system memory.\n",
      "2023-04-16 22:11:59.153339: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype int32 and shape [94477]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 36s 237ms/step - loss: 5.1806 - acc: 0.0394 - top_5_acc: 0.1252 - top_10_acc: 0.1931 - val_loss: 3.8708 - val_acc: 0.1648 - val_top_5_acc: 0.4054 - val_top_10_acc: 0.5355 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 9.998903417374228e-05.\n",
      "learning rate: 1.00e-04, weight decay: 5.00e-06\n",
      "Epoch 2/150\n",
      "148/148 [==============================] - 31s 212ms/step - loss: 3.2153 - acc: 0.2759 - top_5_acc: 0.5555 - top_10_acc: 0.6738 - val_loss: 2.4596 - val_acc: 0.4366 - val_top_5_acc: 0.7117 - val_top_10_acc: 0.7995 - lr: 9.9989e-05\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 9.995614150494293e-05.\n",
      "learning rate: 1.00e-04, weight decay: 5.00e-06\n",
      "Epoch 3/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 2.3532 - acc: 0.4451 - top_5_acc: 0.7256 - top_10_acc: 0.8104 - val_loss: 1.9618 - val_acc: 0.5433 - val_top_5_acc: 0.7890 - val_top_10_acc: 0.8543 - lr: 9.9956e-05\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 9.990133642141359e-05.\n",
      "learning rate: 9.99e-05, weight decay: 5.00e-06\n",
      "Epoch 4/150\n",
      "148/148 [==============================] - 32s 212ms/step - loss: 1.9524 - acc: 0.5301 - top_5_acc: 0.7897 - top_10_acc: 0.8570 - val_loss: 1.7126 - val_acc: 0.5953 - val_top_5_acc: 0.8243 - val_top_10_acc: 0.8786 - lr: 9.9901e-05\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 9.982464296247522e-05.\n",
      "learning rate: 9.98e-05, weight decay: 4.99e-06\n",
      "Epoch 5/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 1.7040 - acc: 0.5853 - top_5_acc: 0.8243 - top_10_acc: 0.8797 - val_loss: 1.6034 - val_acc: 0.6169 - val_top_5_acc: 0.8352 - val_top_10_acc: 0.8894 - lr: 9.9825e-05\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 9.972609476841367e-05.\n",
      "learning rate: 9.97e-05, weight decay: 4.99e-06\n",
      "Epoch 6/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 1.5178 - acc: 0.6285 - top_5_acc: 0.8484 - top_10_acc: 0.8972 - val_loss: 1.4511 - val_acc: 0.6503 - val_top_5_acc: 0.8556 - val_top_10_acc: 0.8998 - lr: 9.9726e-05\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 9.96057350657239e-05.\n",
      "learning rate: 9.96e-05, weight decay: 4.98e-06\n",
      "Epoch 7/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 1.3732 - acc: 0.6590 - top_5_acc: 0.8671 - top_10_acc: 0.9092 - val_loss: 1.3704 - val_acc: 0.6737 - val_top_5_acc: 0.8637 - val_top_10_acc: 0.9059 - lr: 9.9606e-05\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 9.946361664814943e-05.\n",
      "learning rate: 9.95e-05, weight decay: 4.97e-06\n",
      "Epoch 8/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 1.2582 - acc: 0.6837 - top_5_acc: 0.8797 - top_10_acc: 0.9184 - val_loss: 1.2373 - val_acc: 0.7005 - val_top_5_acc: 0.8841 - val_top_10_acc: 0.9172 - lr: 9.9464e-05\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 9.929980185352526e-05.\n",
      "learning rate: 9.93e-05, weight decay: 4.96e-06\n",
      "Epoch 9/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 1.1567 - acc: 0.7084 - top_5_acc: 0.8926 - top_10_acc: 0.9275 - val_loss: 1.2107 - val_acc: 0.7075 - val_top_5_acc: 0.8859 - val_top_10_acc: 0.9206 - lr: 9.9300e-05\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 9.911436253643445e-05.\n",
      "learning rate: 9.91e-05, weight decay: 4.96e-06\n",
      "Epoch 10/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 1.0718 - acc: 0.7290 - top_5_acc: 0.9021 - top_10_acc: 0.9346 - val_loss: 1.1485 - val_acc: 0.7286 - val_top_5_acc: 0.8879 - val_top_10_acc: 0.9236 - lr: 9.9114e-05\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 9.890738003669029e-05.\n",
      "learning rate: 9.89e-05, weight decay: 4.95e-06\n",
      "Epoch 11/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.9934 - acc: 0.7483 - top_5_acc: 0.9121 - top_10_acc: 0.9411 - val_loss: 1.1066 - val_acc: 0.7280 - val_top_5_acc: 0.8962 - val_top_10_acc: 0.9271 - lr: 9.8907e-05\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 9.867894514365802e-05.\n",
      "learning rate: 9.87e-05, weight decay: 4.93e-06\n",
      "Epoch 12/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.9249 - acc: 0.7632 - top_5_acc: 0.9196 - top_10_acc: 0.9466 - val_loss: 1.0654 - val_acc: 0.7442 - val_top_5_acc: 0.9016 - val_top_10_acc: 0.9329 - lr: 9.8679e-05\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 9.842915805643155e-05.\n",
      "learning rate: 9.84e-05, weight decay: 4.92e-06\n",
      "Epoch 13/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.8563 - acc: 0.7800 - top_5_acc: 0.9275 - top_10_acc: 0.9518 - val_loss: 1.0266 - val_acc: 0.7508 - val_top_5_acc: 0.9048 - val_top_10_acc: 0.9344 - lr: 9.8429e-05\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 9.815812833988291e-05.\n",
      "learning rate: 9.82e-05, weight decay: 4.91e-06\n",
      "Epoch 14/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.7995 - acc: 0.7958 - top_5_acc: 0.9338 - top_10_acc: 0.9561 - val_loss: 0.9592 - val_acc: 0.7670 - val_top_5_acc: 0.9158 - val_top_10_acc: 0.9402 - lr: 9.8158e-05\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 9.786597487660337e-05.\n",
      "learning rate: 9.79e-05, weight decay: 4.89e-06\n",
      "Epoch 15/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.7357 - acc: 0.8113 - top_5_acc: 0.9406 - top_10_acc: 0.9614 - val_loss: 0.9479 - val_acc: 0.7738 - val_top_5_acc: 0.9145 - val_top_10_acc: 0.9426 - lr: 9.7866e-05\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 9.755282581475769e-05.\n",
      "learning rate: 9.76e-05, weight decay: 4.88e-06\n",
      "Epoch 16/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.6953 - acc: 0.8202 - top_5_acc: 0.9445 - top_10_acc: 0.9642 - val_loss: 0.9716 - val_acc: 0.7707 - val_top_5_acc: 0.9103 - val_top_10_acc: 0.9372 - lr: 9.7553e-05\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 9.721881851187406e-05.\n",
      "learning rate: 9.72e-05, weight decay: 4.86e-06\n",
      "Epoch 17/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.6498 - acc: 0.8330 - top_5_acc: 0.9499 - top_10_acc: 0.9680 - val_loss: 0.9457 - val_acc: 0.7799 - val_top_5_acc: 0.9143 - val_top_10_acc: 0.9371 - lr: 9.7219e-05\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 9.686409947459458e-05.\n",
      "learning rate: 9.69e-05, weight decay: 4.84e-06\n",
      "Epoch 18/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.6051 - acc: 0.8424 - top_5_acc: 0.9546 - top_10_acc: 0.9713 - val_loss: 0.9244 - val_acc: 0.7825 - val_top_5_acc: 0.9164 - val_top_10_acc: 0.9413 - lr: 9.6864e-05\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 9.648882429441257e-05.\n",
      "learning rate: 9.65e-05, weight decay: 4.82e-06\n",
      "Epoch 19/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.5630 - acc: 0.8533 - top_5_acc: 0.9595 - top_10_acc: 0.9746 - val_loss: 0.8894 - val_acc: 0.7849 - val_top_5_acc: 0.9200 - val_top_10_acc: 0.9465 - lr: 9.6489e-05\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 9.609315757942503e-05.\n",
      "learning rate: 9.61e-05, weight decay: 4.80e-06\n",
      "Epoch 20/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.5167 - acc: 0.8666 - top_5_acc: 0.9635 - top_10_acc: 0.9774 - val_loss: 0.8627 - val_acc: 0.8000 - val_top_5_acc: 0.9236 - val_top_10_acc: 0.9466 - lr: 9.6093e-05\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 9.567727288213005e-05.\n",
      "learning rate: 9.57e-05, weight decay: 4.78e-06\n",
      "Epoch 21/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.4830 - acc: 0.8731 - top_5_acc: 0.9679 - top_10_acc: 0.9798 - val_loss: 0.8241 - val_acc: 0.8009 - val_top_5_acc: 0.9297 - val_top_10_acc: 0.9499 - lr: 9.5677e-05\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 9.524135262330098e-05.\n",
      "learning rate: 9.52e-05, weight decay: 4.76e-06\n",
      "Epoch 22/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.4484 - acc: 0.8825 - top_5_acc: 0.9714 - top_10_acc: 0.9829 - val_loss: 0.8190 - val_acc: 0.8112 - val_top_5_acc: 0.9279 - val_top_10_acc: 0.9478 - lr: 9.5241e-05\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 9.478558801197065e-05.\n",
      "learning rate: 9.48e-05, weight decay: 4.74e-06\n",
      "Epoch 23/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.4149 - acc: 0.8926 - top_5_acc: 0.9746 - top_10_acc: 0.9843 - val_loss: 0.8306 - val_acc: 0.8064 - val_top_5_acc: 0.9292 - val_top_10_acc: 0.9501 - lr: 9.4786e-05\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 9.431017896156074e-05.\n",
      "learning rate: 9.43e-05, weight decay: 4.72e-06\n",
      "Epoch 24/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.3835 - acc: 0.9003 - top_5_acc: 0.9775 - top_10_acc: 0.9867 - val_loss: 0.8233 - val_acc: 0.8087 - val_top_5_acc: 0.9288 - val_top_10_acc: 0.9515 - lr: 9.4310e-05\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 9.381533400219318e-05.\n",
      "learning rate: 9.38e-05, weight decay: 4.69e-06\n",
      "Epoch 25/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.3596 - acc: 0.9062 - top_5_acc: 0.9799 - top_10_acc: 0.9885 - val_loss: 0.8025 - val_acc: 0.8174 - val_top_5_acc: 0.9320 - val_top_10_acc: 0.9524 - lr: 9.3815e-05\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 9.330127018922194e-05.\n",
      "learning rate: 9.33e-05, weight decay: 4.67e-06\n",
      "Epoch 26/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.3299 - acc: 0.9143 - top_5_acc: 0.9832 - top_10_acc: 0.9904 - val_loss: 0.7981 - val_acc: 0.8216 - val_top_5_acc: 0.9330 - val_top_10_acc: 0.9528 - lr: 9.3301e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.276821300802534e-05.\n",
      "learning rate: 9.28e-05, weight decay: 4.64e-06\n",
      "Epoch 27/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.3063 - acc: 0.9209 - top_5_acc: 0.9848 - top_10_acc: 0.9909 - val_loss: 0.8019 - val_acc: 0.8207 - val_top_5_acc: 0.9319 - val_top_10_acc: 0.9517 - lr: 9.2768e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.221639627510076e-05.\n",
      "learning rate: 9.22e-05, weight decay: 4.61e-06\n",
      "Epoch 28/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.2776 - acc: 0.9286 - top_5_acc: 0.9871 - top_10_acc: 0.9927 - val_loss: 0.7638 - val_acc: 0.8355 - val_top_5_acc: 0.9359 - val_top_10_acc: 0.9567 - lr: 9.2216e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.164606203550497e-05.\n",
      "learning rate: 9.16e-05, weight decay: 4.58e-06\n",
      "Epoch 29/150\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 0.2626 - acc: 0.9323 - top_5_acc: 0.9887 - top_10_acc: 0.9937 - val_loss: 0.7910 - val_acc: 0.8246 - val_top_5_acc: 0.9373 - val_top_10_acc: 0.9567 - lr: 9.1646e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 9.105746045668521e-05.\n",
      "learning rate: 9.11e-05, weight decay: 4.55e-06\n",
      "Epoch 30/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.2341 - acc: 0.9392 - top_5_acc: 0.9910 - top_10_acc: 0.9956 - val_loss: 0.7409 - val_acc: 0.8394 - val_top_5_acc: 0.9377 - val_top_10_acc: 0.9573 - lr: 9.1057e-05\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 9.045084971874738e-05.\n",
      "learning rate: 9.05e-05, weight decay: 4.52e-06\n",
      "Epoch 31/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.2114 - acc: 0.9469 - top_5_acc: 0.9920 - top_10_acc: 0.9960 - val_loss: 0.7609 - val_acc: 0.8350 - val_top_5_acc: 0.9378 - val_top_10_acc: 0.9587 - lr: 9.0451e-05\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 8.982649590120982e-05.\n",
      "learning rate: 8.98e-05, weight decay: 4.49e-06\n",
      "Epoch 32/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.2018 - acc: 0.9494 - top_5_acc: 0.9934 - top_10_acc: 0.9965 - val_loss: 0.7818 - val_acc: 0.8310 - val_top_5_acc: 0.9365 - val_top_10_acc: 0.9570 - lr: 8.9826e-05\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 8.9184672866292e-05.\n",
      "learning rate: 8.92e-05, weight decay: 4.46e-06\n",
      "Epoch 33/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.1823 - acc: 0.9542 - top_5_acc: 0.9944 - top_10_acc: 0.9972 - val_loss: 0.7321 - val_acc: 0.8482 - val_top_5_acc: 0.9425 - val_top_10_acc: 0.9591 - lr: 8.9185e-05\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 8.852566213878947e-05.\n",
      "learning rate: 8.85e-05, weight decay: 4.43e-06\n",
      "Epoch 34/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.1636 - acc: 0.9600 - top_5_acc: 0.9955 - top_10_acc: 0.9977 - val_loss: 0.7091 - val_acc: 0.8514 - val_top_5_acc: 0.9402 - val_top_10_acc: 0.9587 - lr: 8.8526e-05\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 8.784975278258783e-05.\n",
      "learning rate: 8.78e-05, weight decay: 4.39e-06\n",
      "Epoch 35/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.1541 - acc: 0.9623 - top_5_acc: 0.9961 - top_10_acc: 0.9981 - val_loss: 0.7147 - val_acc: 0.8537 - val_top_5_acc: 0.9422 - val_top_10_acc: 0.9626 - lr: 8.7850e-05\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 8.715724127386972e-05.\n",
      "learning rate: 8.72e-05, weight decay: 4.36e-06\n",
      "Epoch 36/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.1371 - acc: 0.9670 - top_5_acc: 0.9969 - top_10_acc: 0.9984 - val_loss: 0.7268 - val_acc: 0.8527 - val_top_5_acc: 0.9443 - val_top_10_acc: 0.9603 - lr: 8.7157e-05\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 8.644843137107059e-05.\n",
      "learning rate: 8.64e-05, weight decay: 4.32e-06\n",
      "Epoch 37/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.1340 - acc: 0.9672 - top_5_acc: 0.9971 - top_10_acc: 0.9987 - val_loss: 0.7456 - val_acc: 0.8491 - val_top_5_acc: 0.9409 - val_top_10_acc: 0.9588 - lr: 8.6448e-05\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 8.572363398164017e-05.\n",
      "learning rate: 8.57e-05, weight decay: 4.29e-06\n",
      "Epoch 38/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.1184 - acc: 0.9720 - top_5_acc: 0.9979 - top_10_acc: 0.9990 - val_loss: 0.7251 - val_acc: 0.8531 - val_top_5_acc: 0.9413 - val_top_10_acc: 0.9578 - lr: 8.5724e-05\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 8.498316702566828e-05.\n",
      "learning rate: 8.50e-05, weight decay: 4.25e-06\n",
      "Epoch 39/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.1099 - acc: 0.9744 - top_5_acc: 0.9983 - top_10_acc: 0.9991 - val_loss: 0.7090 - val_acc: 0.8570 - val_top_5_acc: 0.9447 - val_top_10_acc: 0.9616 - lr: 8.4983e-05\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 8.422735529643444e-05.\n",
      "learning rate: 8.42e-05, weight decay: 4.21e-06\n",
      "Epoch 40/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.1023 - acc: 0.9759 - top_5_acc: 0.9984 - top_10_acc: 0.9993 - val_loss: 0.7108 - val_acc: 0.8555 - val_top_5_acc: 0.9442 - val_top_10_acc: 0.9620 - lr: 8.4227e-05\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 8.345653031794292e-05.\n",
      "learning rate: 8.35e-05, weight decay: 4.17e-06\n",
      "Epoch 41/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0938 - acc: 0.9785 - top_5_acc: 0.9988 - top_10_acc: 0.9995 - val_loss: 0.7069 - val_acc: 0.8609 - val_top_5_acc: 0.9470 - val_top_10_acc: 0.9604 - lr: 8.3457e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 8.267103019950529e-05.\n",
      "learning rate: 8.27e-05, weight decay: 4.13e-06\n",
      "Epoch 42/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0827 - acc: 0.9819 - top_5_acc: 0.9989 - top_10_acc: 0.9994 - val_loss: 0.6872 - val_acc: 0.8655 - val_top_5_acc: 0.9486 - val_top_10_acc: 0.9620 - lr: 8.2671e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 8.18711994874345e-05.\n",
      "learning rate: 8.19e-05, weight decay: 4.09e-06\n",
      "Epoch 43/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0812 - acc: 0.9821 - top_5_acc: 0.9989 - top_10_acc: 0.9995 - val_loss: 0.7278 - val_acc: 0.8623 - val_top_5_acc: 0.9428 - val_top_10_acc: 0.9595 - lr: 8.1871e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 8.105738901391552e-05.\n",
      "learning rate: 8.11e-05, weight decay: 4.05e-06\n",
      "Epoch 44/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0786 - acc: 0.9825 - top_5_acc: 0.9991 - top_10_acc: 0.9995 - val_loss: 0.7038 - val_acc: 0.8621 - val_top_5_acc: 0.9461 - val_top_10_acc: 0.9616 - lr: 8.1057e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 8.022995574311876e-05.\n",
      "learning rate: 8.02e-05, weight decay: 4.01e-06\n",
      "Epoch 45/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0746 - acc: 0.9834 - top_5_acc: 0.9992 - top_10_acc: 0.9995 - val_loss: 0.7065 - val_acc: 0.8643 - val_top_5_acc: 0.9473 - val_top_10_acc: 0.9622 - lr: 8.0230e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 7.938926261462366e-05.\n",
      "learning rate: 7.94e-05, weight decay: 3.97e-06\n",
      "Epoch 46/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0722 - acc: 0.9834 - top_5_acc: 0.9993 - top_10_acc: 0.9997 - val_loss: 0.7216 - val_acc: 0.8668 - val_top_5_acc: 0.9478 - val_top_10_acc: 0.9620 - lr: 7.9389e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 7.85356783842216e-05.\n",
      "learning rate: 7.85e-05, weight decay: 3.93e-06\n",
      "Epoch 47/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0634 - acc: 0.9861 - top_5_acc: 0.9994 - top_10_acc: 0.9997 - val_loss: 0.7031 - val_acc: 0.8710 - val_top_5_acc: 0.9475 - val_top_10_acc: 0.9621 - lr: 7.8536e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 7.766957746216721e-05.\n",
      "learning rate: 7.77e-05, weight decay: 3.88e-06\n",
      "Epoch 48/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0608 - acc: 0.9868 - top_5_acc: 0.9995 - top_10_acc: 0.9998 - val_loss: 0.7039 - val_acc: 0.8709 - val_top_5_acc: 0.9471 - val_top_10_acc: 0.9628 - lr: 7.7670e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 7.679133974894983e-05.\n",
      "learning rate: 7.68e-05, weight decay: 3.84e-06\n",
      "Epoch 49/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0570 - acc: 0.9879 - top_5_acc: 0.9995 - top_10_acc: 0.9998 - val_loss: 0.7030 - val_acc: 0.8694 - val_top_5_acc: 0.9493 - val_top_10_acc: 0.9626 - lr: 7.6791e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 7.590135046865651e-05.\n",
      "learning rate: 7.59e-05, weight decay: 3.80e-06\n",
      "Epoch 50/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0543 - acc: 0.9884 - top_5_acc: 0.9997 - top_10_acc: 0.9999 - val_loss: 0.6899 - val_acc: 0.8772 - val_top_5_acc: 0.9500 - val_top_10_acc: 0.9639 - lr: 7.5901e-05\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 7.500000000000001e-05.\n",
      "learning rate: 7.50e-05, weight decay: 3.75e-06\n",
      "Epoch 51/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0484 - acc: 0.9900 - top_5_acc: 0.9996 - top_10_acc: 0.9998 - val_loss: 0.7066 - val_acc: 0.8769 - val_top_5_acc: 0.9490 - val_top_10_acc: 0.9623 - lr: 7.5000e-05\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 7.408768370508576e-05.\n",
      "learning rate: 7.41e-05, weight decay: 3.70e-06\n",
      "Epoch 52/150\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 0.0476 - acc: 0.9898 - top_5_acc: 0.9996 - top_10_acc: 0.9997 - val_loss: 0.6925 - val_acc: 0.8751 - val_top_5_acc: 0.9496 - val_top_10_acc: 0.9627 - lr: 7.4088e-05\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 7.316480175599309e-05.\n",
      "learning rate: 7.32e-05, weight decay: 3.66e-06\n",
      "Epoch 53/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0536 - acc: 0.9875 - top_5_acc: 0.9996 - top_10_acc: 0.9998 - val_loss: 0.6821 - val_acc: 0.8787 - val_top_5_acc: 0.9517 - val_top_10_acc: 0.9642 - lr: 7.3165e-05\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 7.223175895924638e-05.\n",
      "learning rate: 7.22e-05, weight decay: 3.61e-06\n",
      "Epoch 54/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0433 - acc: 0.9911 - top_5_acc: 0.9997 - top_10_acc: 0.9999 - val_loss: 0.6735 - val_acc: 0.8799 - val_top_5_acc: 0.9524 - val_top_10_acc: 0.9649 - lr: 7.2232e-05\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 7.128896457825364e-05.\n",
      "learning rate: 7.13e-05, weight decay: 3.56e-06\n",
      "Epoch 55/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0385 - acc: 0.9922 - top_5_acc: 0.9998 - top_10_acc: 0.9999 - val_loss: 0.6560 - val_acc: 0.8825 - val_top_5_acc: 0.9540 - val_top_10_acc: 0.9683 - lr: 7.1289e-05\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 7.033683215379002e-05.\n",
      "learning rate: 7.03e-05, weight decay: 3.52e-06\n",
      "Epoch 56/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0400 - acc: 0.9920 - top_5_acc: 0.9997 - top_10_acc: 0.9998 - val_loss: 0.6815 - val_acc: 0.8818 - val_top_5_acc: 0.9528 - val_top_10_acc: 0.9654 - lr: 7.0337e-05\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 6.937577932260515e-05.\n",
      "learning rate: 6.94e-05, weight decay: 3.47e-06\n",
      "Epoch 57/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0352 - acc: 0.9933 - top_5_acc: 0.9998 - top_10_acc: 0.9999 - val_loss: 0.6785 - val_acc: 0.8823 - val_top_5_acc: 0.9537 - val_top_10_acc: 0.9664 - lr: 6.9376e-05\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 6.840622763423391e-05.\n",
      "learning rate: 6.84e-05, weight decay: 3.42e-06\n",
      "Epoch 58/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0325 - acc: 0.9936 - top_5_acc: 0.9998 - top_10_acc: 0.9999 - val_loss: 0.6452 - val_acc: 0.8899 - val_top_5_acc: 0.9558 - val_top_10_acc: 0.9676 - lr: 6.8406e-05\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 6.742860236609077e-05.\n",
      "learning rate: 6.74e-05, weight decay: 3.37e-06\n",
      "Epoch 59/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0302 - acc: 0.9943 - top_5_acc: 0.9998 - top_10_acc: 0.9999 - val_loss: 0.6855 - val_acc: 0.8833 - val_top_5_acc: 0.9502 - val_top_10_acc: 0.9648 - lr: 6.7429e-05\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 6.644333233692916e-05.\n",
      "learning rate: 6.64e-05, weight decay: 3.32e-06\n",
      "Epoch 60/150\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 0.0381 - acc: 0.9919 - top_5_acc: 0.9998 - top_10_acc: 0.9999 - val_loss: 0.6918 - val_acc: 0.8830 - val_top_5_acc: 0.9518 - val_top_10_acc: 0.9673 - lr: 6.6443e-05\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 6.545084971874738e-05.\n",
      "learning rate: 6.55e-05, weight decay: 3.27e-06\n",
      "Epoch 61/150\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 0.0357 - acc: 0.9925 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.6680 - val_acc: 0.8849 - val_top_5_acc: 0.9542 - val_top_10_acc: 0.9663 - lr: 6.5451e-05\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 6.445158984722358e-05.\n",
      "learning rate: 6.45e-05, weight decay: 3.22e-06\n",
      "Epoch 62/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0345 - acc: 0.9924 - top_5_acc: 0.9997 - top_10_acc: 0.9999 - val_loss: 0.6907 - val_acc: 0.8807 - val_top_5_acc: 0.9548 - val_top_10_acc: 0.9671 - lr: 6.4452e-05\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 6.344599103076329e-05.\n",
      "learning rate: 6.34e-05, weight decay: 3.17e-06\n",
      "Epoch 63/150\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 0.0294 - acc: 0.9943 - top_5_acc: 0.9998 - top_10_acc: 0.9999 - val_loss: 0.6709 - val_acc: 0.8876 - val_top_5_acc: 0.9529 - val_top_10_acc: 0.9661 - lr: 6.3446e-05\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 6.243449435824276e-05.\n",
      "learning rate: 6.24e-05, weight decay: 3.12e-06\n",
      "Epoch 64/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0318 - acc: 0.9936 - top_5_acc: 0.9997 - top_10_acc: 0.9998 - val_loss: 0.6951 - val_acc: 0.8842 - val_top_5_acc: 0.9516 - val_top_10_acc: 0.9644 - lr: 6.2434e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 6.141754350553279e-05.\n",
      "learning rate: 6.14e-05, weight decay: 3.07e-06\n",
      "Epoch 65/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0248 - acc: 0.9954 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.6611 - val_acc: 0.8886 - val_top_5_acc: 0.9558 - val_top_10_acc: 0.9686 - lr: 6.1418e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 6.0395584540887963e-05.\n",
      "learning rate: 6.04e-05, weight decay: 3.02e-06\n",
      "Epoch 66/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0263 - acc: 0.9946 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6769 - val_acc: 0.8896 - val_top_5_acc: 0.9536 - val_top_10_acc: 0.9660 - lr: 6.0396e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 5.9369065729286245e-05.\n",
      "learning rate: 5.94e-05, weight decay: 2.97e-06\n",
      "Epoch 67/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0242 - acc: 0.9953 - top_5_acc: 0.9998 - top_10_acc: 0.9999 - val_loss: 0.6602 - val_acc: 0.8914 - val_top_5_acc: 0.9558 - val_top_10_acc: 0.9690 - lr: 5.9369e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 5.833843733580512e-05.\n",
      "learning rate: 5.83e-05, weight decay: 2.92e-06\n",
      "Epoch 68/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0230 - acc: 0.9954 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.6995 - val_acc: 0.8853 - val_top_5_acc: 0.9536 - val_top_10_acc: 0.9668 - lr: 5.8338e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.730415142812059e-05.\n",
      "learning rate: 5.73e-05, weight decay: 2.87e-06\n",
      "Epoch 69/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0246 - acc: 0.9947 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6825 - val_acc: 0.8895 - val_top_5_acc: 0.9529 - val_top_10_acc: 0.9667 - lr: 5.7304e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.6266661678215216e-05.\n",
      "learning rate: 5.63e-05, weight decay: 2.81e-06\n",
      "Epoch 70/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0233 - acc: 0.9951 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.7234 - val_acc: 0.8845 - val_top_5_acc: 0.9511 - val_top_10_acc: 0.9659 - lr: 5.6267e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 5.522642316338268e-05.\n",
      "learning rate: 5.52e-05, weight decay: 2.76e-06\n",
      "Epoch 71/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0191 - acc: 0.9963 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6695 - val_acc: 0.8923 - val_top_5_acc: 0.9554 - val_top_10_acc: 0.9676 - lr: 5.5226e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 5.418389216661579e-05.\n",
      "learning rate: 5.42e-05, weight decay: 2.71e-06\n",
      "Epoch 72/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0156 - acc: 0.9976 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6781 - val_acc: 0.8929 - val_top_5_acc: 0.9560 - val_top_10_acc: 0.9660 - lr: 5.4184e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 5.313952597646568e-05.\n",
      "learning rate: 5.31e-05, weight decay: 2.66e-06\n",
      "Epoch 73/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0160 - acc: 0.9973 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6435 - val_acc: 0.8954 - val_top_5_acc: 0.9570 - val_top_10_acc: 0.9703 - lr: 5.3140e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 5.209378268645998e-05.\n",
      "learning rate: 5.21e-05, weight decay: 2.60e-06\n",
      "Epoch 74/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0138 - acc: 0.9981 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.6613 - val_acc: 0.8985 - val_top_5_acc: 0.9563 - val_top_10_acc: 0.9676 - lr: 5.2094e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 5.104712099416785e-05.\n",
      "learning rate: 5.10e-05, weight decay: 2.55e-06\n",
      "Epoch 75/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0150 - acc: 0.9974 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6483 - val_acc: 0.8961 - val_top_5_acc: 0.9569 - val_top_10_acc: 0.9690 - lr: 5.1047e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 5e-05.\n",
      "learning rate: 5.00e-05, weight decay: 2.50e-06\n",
      "Epoch 76/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0155 - acc: 0.9974 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6792 - val_acc: 0.8918 - val_top_5_acc: 0.9548 - val_top_10_acc: 0.9678 - lr: 5.0000e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 4.895287900583216e-05.\n",
      "learning rate: 4.90e-05, weight decay: 2.45e-06\n",
      "Epoch 77/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0161 - acc: 0.9970 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.6445 - val_acc: 0.8995 - val_top_5_acc: 0.9578 - val_top_10_acc: 0.9701 - lr: 4.8953e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 4.790621731354003e-05.\n",
      "learning rate: 4.79e-05, weight decay: 2.40e-06\n",
      "Epoch 78/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0138 - acc: 0.9979 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.7033 - val_acc: 0.8919 - val_top_5_acc: 0.9543 - val_top_10_acc: 0.9657 - lr: 4.7906e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 4.6860474023534335e-05.\n",
      "learning rate: 4.69e-05, weight decay: 2.34e-06\n",
      "Epoch 79/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0185 - acc: 0.9966 - top_5_acc: 0.9998 - top_10_acc: 0.9999 - val_loss: 0.7221 - val_acc: 0.8862 - val_top_5_acc: 0.9512 - val_top_10_acc: 0.9650 - lr: 4.6860e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 4.5816107833384234e-05.\n",
      "learning rate: 4.58e-05, weight decay: 2.29e-06\n",
      "Epoch 80/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0156 - acc: 0.9971 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6437 - val_acc: 0.8974 - val_top_5_acc: 0.9600 - val_top_10_acc: 0.9694 - lr: 4.5816e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 4.477357683661734e-05.\n",
      "learning rate: 4.48e-05, weight decay: 2.24e-06\n",
      "Epoch 81/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0123 - acc: 0.9979 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6814 - val_acc: 0.8989 - val_top_5_acc: 0.9543 - val_top_10_acc: 0.9661 - lr: 4.4774e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 4.373333832178478e-05.\n",
      "learning rate: 4.37e-05, weight decay: 2.19e-06\n",
      "Epoch 82/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0137 - acc: 0.9976 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6875 - val_acc: 0.8970 - val_top_5_acc: 0.9543 - val_top_10_acc: 0.9677 - lr: 4.3733e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 4.269584857187943e-05.\n",
      "learning rate: 4.27e-05, weight decay: 2.13e-06\n",
      "Epoch 83/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0103 - acc: 0.9987 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6554 - val_acc: 0.9023 - val_top_5_acc: 0.9580 - val_top_10_acc: 0.9687 - lr: 4.2696e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 4.166156266419489e-05.\n",
      "learning rate: 4.17e-05, weight decay: 2.08e-06\n",
      "Epoch 84/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0099 - acc: 0.9984 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6644 - val_acc: 0.8972 - val_top_5_acc: 0.9559 - val_top_10_acc: 0.9667 - lr: 4.1662e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 4.063093427071376e-05.\n",
      "learning rate: 4.06e-05, weight decay: 2.03e-06\n",
      "Epoch 85/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0075 - acc: 0.9992 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6578 - val_acc: 0.9017 - val_top_5_acc: 0.9574 - val_top_10_acc: 0.9681 - lr: 4.0631e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 3.960441545911204e-05.\n",
      "learning rate: 3.96e-05, weight decay: 1.98e-06\n",
      "Epoch 86/150\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 0.0085 - acc: 0.9988 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6690 - val_acc: 0.8980 - val_top_5_acc: 0.9566 - val_top_10_acc: 0.9678 - lr: 3.9604e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 3.858245649446721e-05.\n",
      "learning rate: 3.86e-05, weight decay: 1.93e-06\n",
      "Epoch 87/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0090 - acc: 0.9987 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6944 - val_acc: 0.8934 - val_top_5_acc: 0.9537 - val_top_10_acc: 0.9663 - lr: 3.8582e-05\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 3.756550564175727e-05.\n",
      "learning rate: 3.76e-05, weight decay: 1.88e-06\n",
      "Epoch 88/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0126 - acc: 0.9979 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.7016 - val_acc: 0.8966 - val_top_5_acc: 0.9555 - val_top_10_acc: 0.9658 - lr: 3.7566e-05\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 3.655400896923672e-05.\n",
      "learning rate: 3.66e-05, weight decay: 1.83e-06\n",
      "Epoch 89/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0127 - acc: 0.9978 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.6621 - val_acc: 0.9013 - val_top_5_acc: 0.9570 - val_top_10_acc: 0.9682 - lr: 3.6554e-05\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 3.554841015277641e-05.\n",
      "learning rate: 3.55e-05, weight decay: 1.78e-06\n",
      "Epoch 90/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0072 - acc: 0.9990 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6493 - val_acc: 0.9004 - val_top_5_acc: 0.9579 - val_top_10_acc: 0.9691 - lr: 3.5548e-05\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 3.4549150281252636e-05.\n",
      "learning rate: 3.45e-05, weight decay: 1.73e-06\n",
      "Epoch 91/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0058 - acc: 0.9995 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.6619 - val_acc: 0.9001 - val_top_5_acc: 0.9581 - val_top_10_acc: 0.9695 - lr: 3.4549e-05\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 3.355666766307084e-05.\n",
      "learning rate: 3.36e-05, weight decay: 1.68e-06\n",
      "Epoch 92/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0055 - acc: 0.9994 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6506 - val_acc: 0.9032 - val_top_5_acc: 0.9581 - val_top_10_acc: 0.9677 - lr: 3.3557e-05\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 3.257139763390925e-05.\n",
      "learning rate: 3.26e-05, weight decay: 1.63e-06\n",
      "Epoch 93/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0045 - acc: 0.9996 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6584 - val_acc: 0.9018 - val_top_5_acc: 0.9582 - val_top_10_acc: 0.9701 - lr: 3.2571e-05\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 3.1593772365766105e-05.\n",
      "learning rate: 3.16e-05, weight decay: 1.58e-06\n",
      "Epoch 94/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0047 - acc: 0.9996 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6414 - val_acc: 0.9048 - val_top_5_acc: 0.9584 - val_top_10_acc: 0.9714 - lr: 3.1594e-05\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 3.062422067739485e-05.\n",
      "learning rate: 3.06e-05, weight decay: 1.53e-06\n",
      "Epoch 95/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0045 - acc: 0.9997 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6603 - val_acc: 0.9019 - val_top_5_acc: 0.9564 - val_top_10_acc: 0.9688 - lr: 3.0624e-05\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 2.9663167846209998e-05.\n",
      "learning rate: 2.97e-05, weight decay: 1.48e-06\n",
      "Epoch 96/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0046 - acc: 0.9996 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6593 - val_acc: 0.9042 - val_top_5_acc: 0.9574 - val_top_10_acc: 0.9691 - lr: 2.9663e-05\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 2.8711035421746367e-05.\n",
      "learning rate: 2.87e-05, weight decay: 1.44e-06\n",
      "Epoch 97/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0041 - acc: 0.9997 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6436 - val_acc: 0.9036 - val_top_5_acc: 0.9579 - val_top_10_acc: 0.9701 - lr: 2.8711e-05\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 2.776824104075364e-05.\n",
      "learning rate: 2.78e-05, weight decay: 1.39e-06\n",
      "Epoch 98/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0041 - acc: 0.9996 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6508 - val_acc: 0.9042 - val_top_5_acc: 0.9579 - val_top_10_acc: 0.9704 - lr: 2.7768e-05\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.6835198244006927e-05.\n",
      "learning rate: 2.68e-05, weight decay: 1.34e-06\n",
      "Epoch 99/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0034 - acc: 0.9998 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6623 - val_acc: 0.9036 - val_top_5_acc: 0.9558 - val_top_10_acc: 0.9694 - lr: 2.6835e-05\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.591231629491423e-05.\n",
      "learning rate: 2.59e-05, weight decay: 1.30e-06\n",
      "Epoch 100/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0034 - acc: 0.9997 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6284 - val_acc: 0.9077 - val_top_5_acc: 0.9612 - val_top_10_acc: 0.9715 - lr: 2.5912e-05\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 2.500000000000001e-05.\n",
      "learning rate: 2.50e-05, weight decay: 1.25e-06\n",
      "Epoch 101/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0043 - acc: 0.9996 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6723 - val_acc: 0.9026 - val_top_5_acc: 0.9582 - val_top_10_acc: 0.9694 - lr: 2.5000e-05\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 2.4098649531343497e-05.\n",
      "learning rate: 2.41e-05, weight decay: 1.20e-06\n",
      "Epoch 102/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0036 - acc: 0.9997 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6628 - val_acc: 0.9042 - val_top_5_acc: 0.9581 - val_top_10_acc: 0.9682 - lr: 2.4099e-05\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 2.3208660251050158e-05.\n",
      "learning rate: 2.32e-05, weight decay: 1.16e-06\n",
      "Epoch 103/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0033 - acc: 0.9997 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6687 - val_acc: 0.9030 - val_top_5_acc: 0.9580 - val_top_10_acc: 0.9701 - lr: 2.3209e-05\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 2.23304225378328e-05.\n",
      "learning rate: 2.23e-05, weight decay: 1.12e-06\n",
      "Epoch 104/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0041 - acc: 0.9996 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6655 - val_acc: 0.9016 - val_top_5_acc: 0.9574 - val_top_10_acc: 0.9698 - lr: 2.2330e-05\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 2.1464321615778422e-05.\n",
      "learning rate: 2.15e-05, weight decay: 1.07e-06\n",
      "Epoch 105/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0034 - acc: 0.9997 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6428 - val_acc: 0.9049 - val_top_5_acc: 0.9586 - val_top_10_acc: 0.9706 - lr: 2.1464e-05\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 2.061073738537635e-05.\n",
      "learning rate: 2.06e-05, weight decay: 1.03e-06\n",
      "Epoch 106/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0051 - acc: 0.9993 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6920 - val_acc: 0.9029 - val_top_5_acc: 0.9576 - val_top_10_acc: 0.9674 - lr: 2.0611e-05\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 1.977004425688126e-05.\n",
      "learning rate: 1.98e-05, weight decay: 9.89e-07\n",
      "Epoch 107/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0049 - acc: 0.9994 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6196 - val_acc: 0.9058 - val_top_5_acc: 0.9598 - val_top_10_acc: 0.9722 - lr: 1.9770e-05\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 1.8942610986084486e-05.\n",
      "learning rate: 1.89e-05, weight decay: 9.47e-07\n",
      "Epoch 108/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0035 - acc: 0.9997 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6394 - val_acc: 0.9081 - val_top_5_acc: 0.9591 - val_top_10_acc: 0.9709 - lr: 1.8943e-05\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 1.8128800512565513e-05.\n",
      "learning rate: 1.81e-05, weight decay: 9.06e-07\n",
      "Epoch 109/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0034 - acc: 0.9997 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.7000 - val_acc: 0.9021 - val_top_5_acc: 0.9570 - val_top_10_acc: 0.9689 - lr: 1.8129e-05\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 1.7328969800494726e-05.\n",
      "learning rate: 1.73e-05, weight decay: 8.66e-07\n",
      "Epoch 110/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0029 - acc: 0.9998 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6630 - val_acc: 0.9057 - val_top_5_acc: 0.9569 - val_top_10_acc: 0.9693 - lr: 1.7329e-05\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 1.6543469682057106e-05.\n",
      "learning rate: 1.65e-05, weight decay: 8.27e-07\n",
      "Epoch 111/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0021 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6980 - val_acc: 0.9037 - val_top_5_acc: 0.9566 - val_top_10_acc: 0.9677 - lr: 1.6543e-05\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 1.5772644703565565e-05.\n",
      "learning rate: 1.58e-05, weight decay: 7.89e-07\n",
      "Epoch 112/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0020 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6450 - val_acc: 0.9100 - val_top_5_acc: 0.9618 - val_top_10_acc: 0.9715 - lr: 1.5773e-05\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 1.5016832974331724e-05.\n",
      "learning rate: 1.50e-05, weight decay: 7.51e-07\n",
      "Epoch 113/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0017 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6648 - val_acc: 0.9062 - val_top_5_acc: 0.9585 - val_top_10_acc: 0.9686 - lr: 1.5017e-05\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 1.4276366018359844e-05.\n",
      "learning rate: 1.43e-05, weight decay: 7.14e-07\n",
      "Epoch 114/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0020 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6321 - val_acc: 0.9072 - val_top_5_acc: 0.9606 - val_top_10_acc: 0.9725 - lr: 1.4276e-05\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 1.3551568628929434e-05.\n",
      "learning rate: 1.36e-05, weight decay: 6.78e-07\n",
      "Epoch 115/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0019 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6767 - val_acc: 0.9043 - val_top_5_acc: 0.9578 - val_top_10_acc: 0.9697 - lr: 1.3552e-05\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 1.2842758726130283e-05.\n",
      "learning rate: 1.28e-05, weight decay: 6.42e-07\n",
      "Epoch 116/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0020 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6652 - val_acc: 0.9044 - val_top_5_acc: 0.9597 - val_top_10_acc: 0.9704 - lr: 1.2843e-05\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 1.2150247217412186e-05.\n",
      "learning rate: 1.22e-05, weight decay: 6.08e-07\n",
      "Epoch 117/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0020 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6735 - val_acc: 0.9076 - val_top_5_acc: 0.9591 - val_top_10_acc: 0.9687 - lr: 1.2150e-05\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 1.1474337861210543e-05.\n",
      "learning rate: 1.15e-05, weight decay: 5.74e-07\n",
      "Epoch 118/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0025 - acc: 0.9998 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6658 - val_acc: 0.9056 - val_top_5_acc: 0.9581 - val_top_10_acc: 0.9709 - lr: 1.1474e-05\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 1.0815327133708015e-05.\n",
      "learning rate: 1.08e-05, weight decay: 5.41e-07\n",
      "Epoch 119/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0025 - acc: 0.9999 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6562 - val_acc: 0.9086 - val_top_5_acc: 0.9589 - val_top_10_acc: 0.9706 - lr: 1.0815e-05\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 1.0173504098790187e-05.\n",
      "learning rate: 1.02e-05, weight decay: 5.09e-07\n",
      "Epoch 120/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0020 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6713 - val_acc: 0.9059 - val_top_5_acc: 0.9590 - val_top_10_acc: 0.9701 - lr: 1.0174e-05\n",
      "\n",
      "Epoch 121: LearningRateScheduler setting learning rate to 9.549150281252633e-06.\n",
      "learning rate: 9.55e-06, weight decay: 4.77e-07\n",
      "Epoch 121/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0016 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6540 - val_acc: 0.9075 - val_top_5_acc: 0.9585 - val_top_10_acc: 0.9711 - lr: 9.5492e-06\n",
      "\n",
      "Epoch 122: LearningRateScheduler setting learning rate to 8.9425395433148e-06.\n",
      "learning rate: 8.94e-06, weight decay: 4.47e-07\n",
      "Epoch 122/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0018 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6777 - val_acc: 0.9089 - val_top_5_acc: 0.9569 - val_top_10_acc: 0.9678 - lr: 8.9425e-06\n",
      "\n",
      "Epoch 123: LearningRateScheduler setting learning rate to 8.353937964495029e-06.\n",
      "learning rate: 8.35e-06, weight decay: 4.18e-07\n",
      "Epoch 123/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0016 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6356 - val_acc: 0.9060 - val_top_5_acc: 0.9598 - val_top_10_acc: 0.9718 - lr: 8.3539e-06\n",
      "\n",
      "Epoch 124: LearningRateScheduler setting learning rate to 7.783603724899257e-06.\n",
      "learning rate: 7.78e-06, weight decay: 3.89e-07\n",
      "Epoch 124/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0015 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6769 - val_acc: 0.9044 - val_top_5_acc: 0.9580 - val_top_10_acc: 0.9680 - lr: 7.7836e-06\n",
      "\n",
      "Epoch 125: LearningRateScheduler setting learning rate to 7.2317869919746705e-06.\n",
      "learning rate: 7.23e-06, weight decay: 3.62e-07\n",
      "Epoch 125/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0014 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6388 - val_acc: 0.9095 - val_top_5_acc: 0.9596 - val_top_10_acc: 0.9714 - lr: 7.2318e-06\n",
      "\n",
      "Epoch 126: LearningRateScheduler setting learning rate to 6.698729810778065e-06.\n",
      "learning rate: 6.70e-06, weight decay: 3.35e-07\n",
      "Epoch 126/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0015 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6554 - val_acc: 0.9064 - val_top_5_acc: 0.9585 - val_top_10_acc: 0.9692 - lr: 6.6987e-06\n",
      "\n",
      "Epoch 127: LearningRateScheduler setting learning rate to 6.184665997806832e-06.\n",
      "learning rate: 6.18e-06, weight decay: 3.09e-07\n",
      "Epoch 127/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0017 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6674 - val_acc: 0.9067 - val_top_5_acc: 0.9569 - val_top_10_acc: 0.9681 - lr: 6.1847e-06\n",
      "\n",
      "Epoch 128: LearningRateScheduler setting learning rate to 5.689821038439263e-06.\n",
      "learning rate: 5.69e-06, weight decay: 2.84e-07\n",
      "Epoch 128/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0013 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6470 - val_acc: 0.9084 - val_top_5_acc: 0.9598 - val_top_10_acc: 0.9717 - lr: 5.6898e-06\n",
      "\n",
      "Epoch 129: LearningRateScheduler setting learning rate to 5.214411988029355e-06.\n",
      "learning rate: 5.21e-06, weight decay: 2.61e-07\n",
      "Epoch 129/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0012 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6541 - val_acc: 0.9070 - val_top_5_acc: 0.9590 - val_top_10_acc: 0.9700 - lr: 5.2144e-06\n",
      "\n",
      "Epoch 130: LearningRateScheduler setting learning rate to 4.758647376699032e-06.\n",
      "learning rate: 4.76e-06, weight decay: 2.38e-07\n",
      "Epoch 130/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0012 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6343 - val_acc: 0.9086 - val_top_5_acc: 0.9613 - val_top_10_acc: 0.9723 - lr: 4.7586e-06\n",
      "\n",
      "Epoch 131: LearningRateScheduler setting learning rate to 4.322727117869951e-06.\n",
      "learning rate: 4.32e-06, weight decay: 2.16e-07\n",
      "Epoch 131/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0012 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6670 - val_acc: 0.9098 - val_top_5_acc: 0.9589 - val_top_10_acc: 0.9691 - lr: 4.3227e-06\n",
      "\n",
      "Epoch 132: LearningRateScheduler setting learning rate to 3.90684242057498e-06.\n",
      "learning rate: 3.91e-06, weight decay: 1.95e-07\n",
      "Epoch 132/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0011 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6159 - val_acc: 0.9127 - val_top_5_acc: 0.9619 - val_top_10_acc: 0.9723 - lr: 3.9068e-06\n",
      "\n",
      "Epoch 133: LearningRateScheduler setting learning rate to 3.511175705587433e-06.\n",
      "learning rate: 3.51e-06, weight decay: 1.76e-07\n",
      "Epoch 133/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0012 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6844 - val_acc: 0.9055 - val_top_5_acc: 0.9594 - val_top_10_acc: 0.9699 - lr: 3.5112e-06\n",
      "\n",
      "Epoch 134: LearningRateScheduler setting learning rate to 3.1359005254054273e-06.\n",
      "learning rate: 3.14e-06, weight decay: 1.57e-07\n",
      "Epoch 134/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0012 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6135 - val_acc: 0.9102 - val_top_5_acc: 0.9635 - val_top_10_acc: 0.9739 - lr: 3.1359e-06\n",
      "\n",
      "Epoch 135: LearningRateScheduler setting learning rate to 2.7811814881259503e-06.\n",
      "learning rate: 2.78e-06, weight decay: 1.39e-07\n",
      "Epoch 135/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0012 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6669 - val_acc: 0.9079 - val_top_5_acc: 0.9601 - val_top_10_acc: 0.9698 - lr: 2.7812e-06\n",
      "\n",
      "Epoch 136: LearningRateScheduler setting learning rate to 2.4471741852423237e-06.\n",
      "learning rate: 2.45e-06, weight decay: 1.22e-07\n",
      "Epoch 136/150\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 0.0011 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6813 - val_acc: 0.9075 - val_top_5_acc: 0.9576 - val_top_10_acc: 0.9697 - lr: 2.4472e-06\n",
      "\n",
      "Epoch 137: LearningRateScheduler setting learning rate to 2.134025123396638e-06.\n",
      "learning rate: 2.13e-06, weight decay: 1.07e-07\n",
      "Epoch 137/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0011 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6576 - val_acc: 0.9086 - val_top_5_acc: 0.9609 - val_top_10_acc: 0.9717 - lr: 2.1340e-06\n",
      "\n",
      "Epoch 138: LearningRateScheduler setting learning rate to 1.841871660117095e-06.\n",
      "learning rate: 1.84e-06, weight decay: 9.21e-08\n",
      "Epoch 138/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0011 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6678 - val_acc: 0.9056 - val_top_5_acc: 0.9590 - val_top_10_acc: 0.9699 - lr: 1.8419e-06\n",
      "\n",
      "Epoch 139: LearningRateScheduler setting learning rate to 1.5708419435684462e-06.\n",
      "learning rate: 1.57e-06, weight decay: 7.85e-08\n",
      "Epoch 139/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0012 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6599 - val_acc: 0.9079 - val_top_5_acc: 0.9604 - val_top_10_acc: 0.9705 - lr: 1.5708e-06\n",
      "\n",
      "Epoch 140: LearningRateScheduler setting learning rate to 1.3210548563419856e-06.\n",
      "learning rate: 1.32e-06, weight decay: 6.61e-08\n",
      "Epoch 140/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 9.9141e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6449 - val_acc: 0.9104 - val_top_5_acc: 0.9603 - val_top_10_acc: 0.9708 - lr: 1.3211e-06\n",
      "\n",
      "Epoch 141: LearningRateScheduler setting learning rate to 1.0926199633097157e-06.\n",
      "learning rate: 1.09e-06, weight decay: 5.46e-08\n",
      "Epoch 141/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0011 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6863 - val_acc: 0.9081 - val_top_5_acc: 0.9577 - val_top_10_acc: 0.9683 - lr: 1.0926e-06\n",
      "\n",
      "Epoch 142: LearningRateScheduler setting learning rate to 8.856374635655695e-07.\n",
      "learning rate: 8.86e-07, weight decay: 4.43e-08\n",
      "Epoch 142/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 9.9442e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6368 - val_acc: 0.9100 - val_top_5_acc: 0.9598 - val_top_10_acc: 0.9718 - lr: 8.8564e-07\n",
      "\n",
      "Epoch 143: LearningRateScheduler setting learning rate to 7.001981464747565e-07.\n",
      "learning rate: 7.00e-07, weight decay: 3.50e-08\n",
      "Epoch 143/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0010 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6307 - val_acc: 0.9106 - val_top_5_acc: 0.9604 - val_top_10_acc: 0.9714 - lr: 7.0020e-07\n",
      "\n",
      "Epoch 144: LearningRateScheduler setting learning rate to 5.363833518505834e-07.\n",
      "learning rate: 5.36e-07, weight decay: 2.68e-08\n",
      "Epoch 144/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 9.6860e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6662 - val_acc: 0.9085 - val_top_5_acc: 0.9583 - val_top_10_acc: 0.9689 - lr: 5.3638e-07\n",
      "\n",
      "Epoch 145: LearningRateScheduler setting learning rate to 3.9426493427611177e-07.\n",
      "learning rate: 3.94e-07, weight decay: 1.97e-08\n",
      "Epoch 145/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 9.4263e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6162 - val_acc: 0.9142 - val_top_5_acc: 0.9626 - val_top_10_acc: 0.9726 - lr: 3.9426e-07\n",
      "\n",
      "Epoch 146: LearningRateScheduler setting learning rate to 2.7390523158633554e-07.\n",
      "learning rate: 2.74e-07, weight decay: 1.37e-08\n",
      "Epoch 146/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 9.1748e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6699 - val_acc: 0.9104 - val_top_5_acc: 0.9585 - val_top_10_acc: 0.9699 - lr: 2.7391e-07\n",
      "\n",
      "Epoch 147: LearningRateScheduler setting learning rate to 1.753570375247815e-07.\n",
      "learning rate: 1.75e-07, weight decay: 8.77e-09\n",
      "Epoch 147/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 9.7266e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6580 - val_acc: 0.9084 - val_top_5_acc: 0.9587 - val_top_10_acc: 0.9705 - lr: 1.7536e-07\n",
      "\n",
      "Epoch 148: LearningRateScheduler setting learning rate to 9.866357858642205e-08.\n",
      "learning rate: 9.87e-08, weight decay: 4.93e-09\n",
      "Epoch 148/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 9.4557e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6650 - val_acc: 0.9074 - val_top_5_acc: 0.9597 - val_top_10_acc: 0.9712 - lr: 9.8664e-08\n",
      "\n",
      "Epoch 149: LearningRateScheduler setting learning rate to 4.385849505708084e-08.\n",
      "learning rate: 4.39e-08, weight decay: 2.19e-09\n",
      "Epoch 149/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 9.8476e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6528 - val_acc: 0.9094 - val_top_5_acc: 0.9603 - val_top_10_acc: 0.9709 - lr: 4.3858e-08\n",
      "\n",
      "Epoch 150: LearningRateScheduler setting learning rate to 1.096582625772502e-08.\n",
      "learning rate: 1.10e-08, weight decay: 5.48e-10\n",
      "Epoch 150/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 9.3031e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6371 - val_acc: 0.9099 - val_top_5_acc: 0.9616 - val_top_10_acc: 0.9719 - lr: 1.0966e-08\n"
     ]
    }
   ],
   "source": [
    "# Clear all models in GPU\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Get new fresh model\n",
    "model = get_model()\n",
    "\n",
    "# Sanity Check\n",
    "model.summary()\n",
    "\n",
    "log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "# Actual Training\n",
    "history = model.fit(\n",
    "        train.batch(config['TRAIN_BATCH_SIZE']),\n",
    "        epochs=config[\"N_EPOCHS\"],\n",
    "        validation_data=validation.batch(config[\"BATCH_SIZE_VAL\"]),\n",
    "        callbacks=[\n",
    "            lr_callback,\n",
    "            WeightDecayCallback(config[\"WD_RATIO\"]),\n",
    "            tensorboard_callback\n",
    "          ],\n",
    "        verbose = VERBOSE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57044d51",
   "metadata": {
    "papermill": {
     "duration": 0.204275,
     "end_time": "2023-03-27T14:38:44.950811",
     "exception": false,
     "start_time": "2023-03-27T14:38:44.746536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save Model Weights\n",
    "model.save_weights(f'tf_models/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bba959c-57d7-4713-ad74-874445d85f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = get_model()\n",
    "# model.load_weights('tf_models/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2759c7",
   "metadata": {
    "papermill": {
     "duration": 0.065813,
     "end_time": "2023-03-27T14:38:48.284324",
     "exception": false,
     "start_time": "2023-03-27T14:38:48.218511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission\n",
    "\n",
    "Submission code loosley based on [this notebook](https://www.kaggle.com/code/dschettler8845/gislr-learn-eda-baseline#baseline) by [Darien Schettler\n",
    "](https://www.kaggle.com/dschettler8845)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8d2d0a9",
   "metadata": {
    "papermill": {
     "duration": 1.644953,
     "end_time": "2023-03-27T14:38:49.995113",
     "exception": false,
     "start_time": "2023-03-27T14:38:48.350160",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TFLite model for submission\n",
    "class TFLiteModel(tf.keras.Model):\n",
    "    def __init__(self, model):\n",
    "        super(TFLiteModel, self).__init__()\n",
    "\n",
    "        # Load the feature generation and main models\n",
    "        self.preprocess_layer = preprocess_layer\n",
    "        self.model = model\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, config[\"N_ROWS\"], config[\"N_DIMS\"]], dtype=tf.float32, name='inputs')])\n",
    "    def call(self, inputs):\n",
    "        # Preprocess Data\n",
    "        x, non_empty_frame_idxs = self.preprocess_layer(inputs)\n",
    "        # Add Batch Dimension\n",
    "        x = tf.expand_dims(x, axis=0)\n",
    "        non_empty_frame_idxs = tf.expand_dims(non_empty_frame_idxs, axis=0)\n",
    "        # Make Prediction\n",
    "        outputs = self.model({'FRAMES': x, 'NON_EMPTY_FRAME_IDXS': non_empty_frame_idxs })\n",
    "        # Squeeze Output 1x250 -> 250\n",
    "        outputs = tf.squeeze(outputs, axis=0)\n",
    "\n",
    "        # Return a dictionary with the output tensor\n",
    "        return {'outputs': outputs}\n",
    "\n",
    "# Define TF Lite Model\n",
    "tflite_keras_model = TFLiteModel(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3071a4d9",
   "metadata": {
    "papermill": {
     "duration": 32.570402,
     "end_time": "2023-03-27T14:39:22.633212",
     "exception": false,
     "start_time": "2023-03-27T14:38:50.062810",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.TFLiteModel object at 0x7f9b60233760>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.TFLiteModel object at 0x7f9b60233760>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "2023-04-17 22:10:44.065362: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.065472: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'preprocess_layer_v2_1/94535' with dtype int32 and shape [227]\n",
      "\t [[{{node preprocess_layer_v2_1/94535}}]]\n",
      "2023-04-17 22:10:44.400227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.400334: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '95252' with dtype int32 and shape [227]\n",
      "\t [[{{node 95252}}]]\n",
      "2023-04-17 22:10:44.575646: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'data' with dtype float and shape [?,543,2]\n",
      "\t [[{{node data}}]]\n",
      "2023-04-17 22:10:44.575757: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '95846' with dtype int32 and shape [227]\n",
      "\t [[{{node 95846}}]]\n",
      "2023-04-17 22:10:44.610497: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face_embedding_dense_1_input' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face_embedding_dense_1_input}}]]\n",
      "2023-04-17 22:10:44.630621: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face_embedding_dense_1_input' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face_embedding_dense_1_input}}]]\n",
      "2023-04-17 22:10:44.638310: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.644227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face_embedding_dense_1_input' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face_embedding_dense_1_input}}]]\n",
      "2023-04-17 22:10:44.650327: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.656244: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face_embedding_dense_1_input' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face_embedding_dense_1_input}}]]\n",
      "2023-04-17 22:10:44.660614: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.664890: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.671272: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.676978: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.704748: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand_embedding_dense_1_input}}]]\n",
      "2023-04-17 22:10:44.723346: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand_embedding_dense_1_input}}]]\n",
      "2023-04-17 22:10:44.730930: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.736812: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand_embedding_dense_1_input}}]]\n",
      "2023-04-17 22:10:44.742873: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.748754: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand_embedding_dense_1_input}}]]\n",
      "2023-04-17 22:10:44.753106: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.757399: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.763962: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.769403: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.798205: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand_embedding_dense_1_input}}]]\n",
      "2023-04-17 22:10:44.818393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand_embedding_dense_1_input}}]]\n",
      "2023-04-17 22:10:44.826409: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.832291: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand_embedding_dense_1_input}}]]\n",
      "2023-04-17 22:10:44.838527: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.844347: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand_embedding_dense_1_input}}]]\n",
      "2023-04-17 22:10:44.848745: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.853039: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.859374: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.864802: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.892332: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose_embedding_dense_1_input' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose_embedding_dense_1_input}}]]\n",
      "2023-04-17 22:10:44.911719: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose_embedding_dense_1_input' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose_embedding_dense_1_input}}]]\n",
      "2023-04-17 22:10:44.919300: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.925172: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose_embedding_dense_1_input' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose_embedding_dense_1_input}}]]\n",
      "2023-04-17 22:10:44.931292: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.937129: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose_embedding_dense_1_input' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose_embedding_dense_1_input}}]]\n",
      "2023-04-17 22:10:44.941319: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.945625: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.952051: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.957747: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:44.985107: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'fully_connected_1_input' with dtype float and shape [?,38,384]\n",
      "\t [[{{node fully_connected_1_input}}]]\n",
      "2023-04-17 22:10:45.003554: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'fully_connected_1_input' with dtype float and shape [?,38,384]\n",
      "\t [[{{node fully_connected_1_input}}]]\n",
      "2023-04-17 22:10:45.011057: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.016920: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'fully_connected_1_input' with dtype float and shape [?,38,384]\n",
      "\t [[{{node fully_connected_1_input}}]]\n",
      "2023-04-17 22:10:45.024437: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.030585: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'fully_connected_1_input' with dtype float and shape [?,38,384]\n",
      "\t [[{{node fully_connected_1_input}}]]\n",
      "2023-04-17 22:10:45.034944: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.039177: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.045493: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.050950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.111126: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_13_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_13_input}}]]\n",
      "2023-04-17 22:10:45.137993: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_13_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_13_input}}]]\n",
      "2023-04-17 22:10:45.149382: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.157437: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_13_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_13_input}}]]\n",
      "2023-04-17 22:10:45.164160: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.171947: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_13_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_13_input}}]]\n",
      "2023-04-17 22:10:45.176660: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.181612: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.188641: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.196543: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.202693: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.236105: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_28_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_28_input}}]]\n",
      "2023-04-17 22:10:45.263365: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_28_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_28_input}}]]\n",
      "2023-04-17 22:10:45.274660: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.282813: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_28_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_28_input}}]]\n",
      "2023-04-17 22:10:45.289595: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.297515: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_28_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_28_input}}]]\n",
      "2023-04-17 22:10:45.302273: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.306618: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.313757: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.321791: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:45.328081: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:46.734983: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'FRAMES' with dtype float and shape [?,38,454]\n",
      "\t [[{{node FRAMES}}]]\n",
      "2023-04-17 22:10:46.859307: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'FRAMES' with dtype float and shape [?,38,454]\n",
      "\t [[{{node FRAMES}}]]\n",
      "2023-04-17 22:10:46.880923: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face0' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face0}}]]\n",
      "2023-04-17 22:10:46.881015: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand0' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand0}}]]\n",
      "2023-04-17 22:10:46.881066: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand0' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand0}}]]\n",
      "2023-04-17 22:10:46.881130: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose0' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose0}}]]\n",
      "2023-04-17 22:10:46.898239: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face0' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face0}}]]\n",
      "2023-04-17 22:10:46.898325: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand0' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand0}}]]\n",
      "2023-04-17 22:10:46.898376: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand0' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand0}}]]\n",
      "2023-04-17 22:10:46.898424: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose0' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose0}}]]\n",
      "2023-04-17 22:10:46.937274: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,38,512]\n",
      "\t [[{{node x}}]]\n",
      "2023-04-17 22:10:46.982035: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,38,512]\n",
      "\t [[{{node x}}]]\n",
      "2023-04-17 22:10:46.992094: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:47.051716: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,454]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:47.106859: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,454]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:47.168010: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'data' with dtype float and shape [?,543,2]\n",
      "\t [[{{node data}}]]\n",
      "2023-04-17 22:10:47.168113: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '101708' with dtype int32 and shape [227]\n",
      "\t [[{{node 101708}}]]\n",
      "2023-04-17 22:10:47.411747: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,38,454]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-17 22:10:47.467235: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,38,454]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-17 22:10:48.635925: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face0' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face0}}]]\n",
      "2023-04-17 22:10:48.636029: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand0' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand0}}]]\n",
      "2023-04-17 22:10:48.636080: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand0' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand0}}]]\n",
      "2023-04-17 22:10:48.636129: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose0' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose0}}]]\n",
      "2023-04-17 22:10:48.652794: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face0' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face0}}]]\n",
      "2023-04-17 22:10:48.652878: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand0' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand0}}]]\n",
      "2023-04-17 22:10:48.652929: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand0' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand0}}]]\n",
      "2023-04-17 22:10:48.652998: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose0' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose0}}]]\n",
      "2023-04-17 22:10:49.608146: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,38,512]\n",
      "\t [[{{node x}}]]\n",
      "2023-04-17 22:10:49.653561: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,38,512]\n",
      "\t [[{{node x}}]]\n",
      "2023-04-17 22:10:50.499751: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:50.550762: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:50.556550: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:50.648729: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:50.654495: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:50.720619: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:50.726573: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:50.791001: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:50.796823: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:50.861754: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:50.867511: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:50.927313: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:50.948011: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:50.981285: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:50.987890: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:51.062639: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:51.069162: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:51.142904: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:51.163382: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:51.180633: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:51.200600: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:51.217850: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:51.237676: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:51.254925: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:51.274803: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:51.327980: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:51.351333: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:51.368316: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:51.386892: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:51.407491: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 22:10:51.424003: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, face_embedding_layer_call_fn, face_embedding_layer_call_and_return_conditional_losses, left_hand_embedding_layer_call_fn while saving (showing 5 of 78). These functions will not be directly callable after loading.\n",
      "2023-04-17 22:10:51.647619: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_inputs' with dtype float and shape [?,543,2]\n",
      "\t [[{{node serving_default_inputs}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpivtdi300/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpivtdi300/assets\n",
      "2023-04-17 22:10:57.814315: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_inputs' with dtype float and shape [?,543,2]\n",
      "\t [[{{node serving_default_inputs}}]]\n",
      "2023-04-17 22:10:59.332285: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_begin_values_1' with dtype int32\n",
      "\t [[{{node slice_begin_values_1}}]]\n",
      "2023-04-17 22:10:59.332422: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_size_values_1' with dtype int32\n",
      "\t [[{{node slice_size_values_1}}]]\n",
      "2023-04-17 22:10:59.333191: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_size_values_1' with dtype int32\n",
      "\t [[{{node slice_size_values_1}}]]\n",
      "2023-04-17 22:10:59.333994: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sub_1_x' with dtype int32\n",
      "\t [[{{node sub_1_x}}]]\n",
      "2023-04-17 22:10:59.334842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sub_3_x' with dtype int32\n",
      "\t [[{{node sub_3_x}}]]\n",
      "2023-04-17 22:11:00.063303: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_begin_values_1' with dtype int32\n",
      "\t [[{{node slice_begin_values_1}}]]\n",
      "2023-04-17 22:11:00.063457: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_size_values_1' with dtype int32\n",
      "\t [[{{node slice_size_values_1}}]]\n",
      "2023-04-17 22:11:00.064248: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_size_values_1' with dtype int32\n",
      "\t [[{{node slice_size_values_1}}]]\n",
      "2023-04-17 22:11:00.065047: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sub_1_x' with dtype int32\n",
      "\t [[{{node sub_1_x}}]]\n",
      "2023-04-17 22:11:00.065884: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sub_3_x' with dtype int32\n",
      "\t [[{{node sub_3_x}}]]\n",
      "2023-04-17 22:11:01.050350: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_begin_values_1' with dtype int32\n",
      "\t [[{{node slice_begin_values_1}}]]\n",
      "2023-04-17 22:11:01.050500: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_size_values_1' with dtype int32\n",
      "\t [[{{node slice_size_values_1}}]]\n",
      "2023-04-17 22:11:01.051284: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_size_values_1' with dtype int32\n",
      "\t [[{{node slice_size_values_1}}]]\n",
      "2023-04-17 22:11:01.052099: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sub_1_x' with dtype int32\n",
      "\t [[{{node sub_1_x}}]]\n",
      "2023-04-17 22:11:01.052954: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sub_3_x' with dtype int32\n",
      "\t [[{{node sub_3_x}}]]\n",
      "2023-04-17 22:11:02.030525: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-04-17 22:11:02.030580: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-04-17 22:11:02.030842: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpivtdi300\n",
      "2023-04-17 22:11:02.054869: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-04-17 22:11:02.054915: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpivtdi300\n",
      "2023-04-17 22:11:02.142329: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-04-17 22:11:02.341569: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpivtdi300\n",
      "2023-04-17 22:11:02.445505: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 414664 microseconds.\n"
     ]
    }
   ],
   "source": [
    "version = 2\n",
    "# Create Model Converter\n",
    "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflite_keras_model)\n",
    "keras_model_converter.experimental_new_converter = True\n",
    "\n",
    "# Convert Model\n",
    "tflite_model = keras_model_converter.convert()\n",
    "# Write Model\n",
    "with open(f'tflite_models/v{version}_again_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "    \n",
    "# Zip Model\n",
    "!zip submission.zip /kaggle/working/model.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848181e8-9e30-471e-bc5c-b37340640edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "demo_raw_data = load_relevant_data_subset(train['path'].values[5])\n",
    "print(f'demo_raw_data shape: {demo_raw_data.shape}, dtype: {demo_raw_data.dtype}')\n",
    "demo_output = tflite_keras_model(demo_raw_data)[\"outputs\"]\n",
    "print(f'demo_output shape: {demo_output.shape}, dtype: {demo_output.dtype}')\n",
    "demo_prediction = demo_output.numpy().argmax()\n",
    "print(f'demo_prediction: {demo_prediction}, correct: {train.iloc[0][\"sign_ord\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5493473",
   "metadata": {
    "papermill": {
     "duration": 11.438209,
     "end_time": "2023-03-27T14:39:34.137659",
     "exception": false,
     "start_time": "2023-03-27T14:39:22.699450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED :  wait [232]\n",
      "TRUE :  blow [25]\n"
     ]
    }
   ],
   "source": [
    "# Verify TFLite model can be loaded and used for prediction\n",
    "# !pip install tflite-runtime\n",
    "# import tf.lite.interpreter as tflite\n",
    "\n",
    "test_input = load_relevant_data_subset(\"w251-asl-data/raw-data/train_landmark_files/28656/1000106739.parquet\")\n",
    "\n",
    "interpreter = tf.lite.Interpreter(\"tflite_models/v2_again_model.tflite\")\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "output = prediction_fn(inputs=test_input)\n",
    "sign = output['outputs'].argmax()\n",
    "\n",
    "print(\"PRED : \", ORD2SIGN.get(sign), f'[{sign}]')\n",
    "print(\"TRUE : \", train.sign.values[0], f'[{train.sign_ord.values[0]}]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3038.388613,
   "end_time": "2023-03-27T14:39:37.370611",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-27T13:48:58.981998",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03d6f570ff764870bb73ccfb8c6887af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_49350bdfb80d4f00a698d195ad6cc3e3",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_6114b828351443dead1df1f805e5cfd7",
       "value": "100%"
      }
     },
     "07287dd36a6b457bab873107ef3a9a74": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a3cb9fa235b4d3b9fe4729d0488ab41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0b6a231f62a24aae9fa0cbc3fb92820f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0bdd95bee39a4c0fba0d526a76e11ed7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5809fb0e32f44de489c4ffd133aed91d",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_ac638cb770cd4789a3ad5944574c0685",
       "value": " 1000/1000 [00:23&lt;00:00, 37.18it/s]"
      }
     },
     "0f47d306ae4c4968ae9578b5d3f96717": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1c0862516d904ef7a8308a72e5ae9f91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28320ac6793c47f69b05122f608c2d44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d0ef2e7de83043f5a1e56b8cbfdceb42",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0b6a231f62a24aae9fa0cbc3fb92820f",
       "value": 1000
      }
     },
     "37eb2c935499475c89e659645e41c052": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3a30e5dd2b7e4e58b5f796dc56795f9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "43441f82927941c183c36d4ba42c6839": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49104b8e9766498997f1c107709166cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49350bdfb80d4f00a698d195ad6cc3e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4fb37e6c0a6849b0ae4fca96c98079d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "50b095287b764b40bc01eecfb8e226ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "549182ad731149e196c24e0c65368459": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "54d833de2b3e4368a09e8f2832ae582a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_43441f82927941c183c36d4ba42c6839",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_549182ad731149e196c24e0c65368459",
       "value": " 42/42 [00:06&lt;00:00,  6.63it/s]"
      }
     },
     "5809fb0e32f44de489c4ffd133aed91d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b6ddc597476439b98e2a8572db415ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5f60bd20e6054b8d9990b2b2804e19a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6114b828351443dead1df1f805e5cfd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7a008f4929ca442296cb2159b02d1206": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "873e173a1a48496183ab1a8b2425b3f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89aab12028bb44f0a421c39e5407e2c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a757d761f004d7faf0e86f35c7cc2ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d56ea444a554a8d86255febcfa438ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5f60bd20e6054b8d9990b2b2804e19a1",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_37eb2c935499475c89e659645e41c052",
       "value": "100%"
      }
     },
     "8e1a02523adf4a51928bd01fe6a016a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a1b2e1be36c74ff5802bee0472d05a8c",
        "IPY_MODEL_974821174ce548f7ab78f2eb280a36bc",
        "IPY_MODEL_54d833de2b3e4368a09e8f2832ae582a"
       ],
       "layout": "IPY_MODEL_49104b8e9766498997f1c107709166cd"
      }
     },
     "974821174ce548f7ab78f2eb280a36bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4fb37e6c0a6849b0ae4fca96c98079d3",
       "max": 42,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0a3cb9fa235b4d3b9fe4729d0488ab41",
       "value": 42
      }
     },
     "97ebc5f11183491097eaa468c8f8d6ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9fdf9f1a806d45d8afc6aa7674799d7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8d56ea444a554a8d86255febcfa438ef",
        "IPY_MODEL_bc93196873734683876ec5f8b4b4c62c",
        "IPY_MODEL_d34a43c029834695b633aa4d4d941930"
       ],
       "layout": "IPY_MODEL_873e173a1a48496183ab1a8b2425b3f1"
      }
     },
     "a1b2e1be36c74ff5802bee0472d05a8c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_07287dd36a6b457bab873107ef3a9a74",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_fc0e155d7357432c9976cb2ac7c68b3a",
       "value": "100%"
      }
     },
     "ac638cb770cd4789a3ad5944574c0685": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b0ba62ab3b254a6897d45bb7a753f044": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b5005dde82d843e7a0b50cdf2669d881": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d7996506467449ad9ba51cfb1e6db002",
        "IPY_MODEL_d0ff43d2109d482884de8add17da97e7",
        "IPY_MODEL_f9647d54b313481eaa72a3093a5dbc0a"
       ],
       "layout": "IPY_MODEL_1c0862516d904ef7a8308a72e5ae9f91"
      }
     },
     "bc93196873734683876ec5f8b4b4c62c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fa12da626fe2424eb7a18e996ed1fb96",
       "max": 10,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5b6ddc597476439b98e2a8572db415ee",
       "value": 10
      }
     },
     "d0ef2e7de83043f5a1e56b8cbfdceb42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0ff43d2109d482884de8add17da97e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3a30e5dd2b7e4e58b5f796dc56795f9d",
       "max": 40,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_97ebc5f11183491097eaa468c8f8d6ba",
       "value": 40
      }
     },
     "d34a43c029834695b633aa4d4d941930": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_50b095287b764b40bc01eecfb8e226ce",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_7a008f4929ca442296cb2159b02d1206",
       "value": " 10/10 [00:02&lt;00:00,  5.02it/s]"
      }
     },
     "d7996506467449ad9ba51cfb1e6db002": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e8ec2cab76c64079add86c4cd9e47463",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_0f47d306ae4c4968ae9578b5d3f96717",
       "value": "100%"
      }
     },
     "e8ec2cab76c64079add86c4cd9e47463": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "edea63966eb74395b1ccf14ba9265099": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_03d6f570ff764870bb73ccfb8c6887af",
        "IPY_MODEL_28320ac6793c47f69b05122f608c2d44",
        "IPY_MODEL_0bdd95bee39a4c0fba0d526a76e11ed7"
       ],
       "layout": "IPY_MODEL_89aab12028bb44f0a421c39e5407e2c2"
      }
     },
     "f9647d54b313481eaa72a3093a5dbc0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8a757d761f004d7faf0e86f35c7cc2ef",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_b0ba62ab3b254a6897d45bb7a753f044",
       "value": " 40/40 [00:07&lt;00:00,  4.48it/s]"
      }
     },
     "fa12da626fe2424eb7a18e996ed1fb96": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc0e155d7357432c9976cb2ac7c68b3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
